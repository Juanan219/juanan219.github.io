<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on JuananBlog</title>
        <link>https://juanan219.github.io/posts/</link>
        <description>Recent content in Posts on JuananBlog</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
        <lastBuildDate>Thu, 18 Mar 2021 00:00:00 +0000</lastBuildDate>
        <atom:link href="https://juanan219.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Apuntes de Libvirt</title>
            <link>https://juanan219.github.io/posts/2021/03/apuntes-de-libvirt/</link>
            <pubDate>Thu, 18 Mar 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/03/apuntes-de-libvirt/</guid>
            <description>Libvirt es una API de virtualizacion que se usa con KVM o Qemu KVM (el sistema de virtualización nativo de Linux).
Instalación Para instalar libvirt deberemos instalar los siguientes paquetes
sudo apt-get install qemu-kvm libvirt-daemon-system Explicación de los paquetes:
  qemu-kvm: Proporciona la virtualización para x86
  libvirt-daemon-system: Es el demonio de libvirt, el cual hace accesible la API a través de un socket UNIX (aunque se puede configurar para acceder a través de un socket TCP).</description>
            <content type="html"><![CDATA[<p><code>Libvirt</code> es una API de virtualizacion que se usa con <code>KVM</code> o <code>Qemu KVM</code> (el sistema de virtualización nativo de Linux).</p>
<h2 id="instalación">Instalación</h2>
<p>Para instalar <code>libvirt</code> deberemos instalar los siguientes paquetes</p>
<pre><code>sudo apt-get install qemu-kvm libvirt-daemon-system 
</code></pre><p>Explicación de los paquetes:</p>
<ul>
<li>
<p><strong><code>qemu-kvm</code>:</strong> Proporciona la virtualización para <code>x86</code></p>
</li>
<li>
<p><strong><code>libvirt-daemon-system</code>:</strong> Es el demonio de <code>libvirt</code>, el cual hace accesible la <code>API</code> a través de un <code>socket UNIX</code> (aunque se puede configurar para acceder a través de un <code>socket TCP</code>).</p>
</li>
</ul>
<p>Una vez que ya hemos realizado la instalación de estos dos paquetes, deberemos añadir a nuestro usuario personal (el usuario sin privilegios) al grupo de <code>libvirt</code>.</p>
<pre><code>sudo adduser usuario libvirt
</code></pre><p>Esta configuración se debe a que hay dos formas de usar esta API:</p>
<ul>
<li>
<p><strong><code>qemu:///session</code>:</strong> Sería el equivalente a usar el usuario sin privilegios del sistema, con lo cual tendríamos ciertas limitaciones al usar la <code>API</code>.</p>
</li>
<li>
<p><strong><code>qemu:///system</code>:</strong> Sería el equivalente a usar el usuario administrador o <code>root</code> del sistema.</p>
</li>
</ul>
<p>Por lo que si nuestro usuario no pertenece al grupo <code>libvirt</code>, no podríamos usar el comando <code>qemu:///system</code> con dicho usuario.</p>
<h2 id="definición-y-creación-de-redes-en-virsh">Definición y creación de redes en virsh</h2>
<p>Para crear objetos en <code>virsh</code> necesitamos crear ficheros <code>xml</code> en los que definimos dicha configuración.</p>
<p>Este es un dichero <code>xml</code> de creación de una red de ejemplo:</p>
<pre><code>&lt;network&gt;
 &lt;name&gt;default&lt;/name&gt;
 &lt;forward mode='nat'&gt;
  &lt;nat&gt;
   &lt;port start='1024' end='65535'/&gt;
  &lt;/nat&gt;
 &lt;/forward&gt;
 &lt;bridge name='virbr0' stp='on' delay='0'/&gt;
 &lt;ip address='192.168.122.1' netmask='255.255.255.0'&gt;
  &lt;dhcp&gt;
   &lt;range start='192.168.122.2' end='192.168.122.254'/&gt;
  &lt;/dhcp&gt;
 &lt;/ip&gt;
&lt;/network&gt;
</code></pre><ul>
<li>Tenemos un fichero <code>xml</code> que crea un objeto de tipo <strong><code>network</code></strong>
<ul>
<li>El nombre de esta red es <strong><code>default</code></strong>.</li>
<li>Esta red es de tipo <strong><code>nat</code></strong>, el tipo de red se indica con la etiqueda <strong><code>forward</code></strong> (Esto nos permite que esta red tenga acceso al exterior, pero si queremos tener una red aislada, deberemos eliminar esta parte)</li>
<li>El dispositivo de conexión es de tipo <strong><code>bridge</code></strong>, el cual tiene un nombre llamado <strong><code>virbr0</code></strong> con el protocolo <strong><code>stp</code></strong> habilitado y el cual va a tener una ip asignada que es la <strong><code>192.168.122.1/24</code></strong></li>
<li>En nuestra subred vamos a ejecutar un servidor <strong><code>dhcp</code></strong> con <strong><code>dnsmasq</code></strong> el cual va a tener un rango para repartir IPs desde la <strong><code>192.168.122.2</code></strong> hasta la <strong><code>192.168.122.254</code></strong></li>
</ul>
</li>
</ul>
<p>Si no estamos seguros de si al fichero xml le falta algún elemento o no está bien estructurado o tiene algún error, podemos usar el comando <code>virt-xml-validate</code> para verificar que todo está correcto.</p>
<pre><code>virt-xml-validate red1.xml
red1.xml validates
</code></pre><p>Ahora vamos a crear dicha red a partir de este fichero <code>xml</code></p>
<pre><code>virsh -c qemu:///system net-create red1.xml
</code></pre><p>Si queremos ver la red que acabamos de crear</p>
<pre><code>virsh -c qemu:///system net-list
 Name      State    Autostart   Persistent
--------------------------------------------
 default   active   no          no
</code></pre><p>Si queremos ver todas las redes definidas, aunque no esté activas</p>
<pre><code>virsh -c qemu:///system net-list --all
 Name      State    Autostart   Persistent
--------------------------------------------
 default   active   no          no
</code></pre><p>La red que hemos creado, como podemos ver en el <code>net-list</code>, dice que no es persistente, esto quiere decir que cuando reiniciemos nuestra máquina, dicha red va a desaparecer. Podemos comprobar esto <em>destruyendo</em> nuestra red y ejecutando el comando <code>net-list --all</code>, para ver que no está definida en ningún sitio.</p>
<pre><code>virsh -c qemu:///system net-destroy default
Network default destroyed

 virsh -c qemu:///system net-list --all
 Name   State   Autostart   Persistent
----------------------------------------
</code></pre><p>Para crear una red que sea persistente deberemos usar el comando <code>net-define</code></p>
<pre><code>virsh -c qemu:///system net-define red1.xml
Network default defined from red1.xml

virsh -c qemu:///system net-list
 Name   State   Autostart   Persistent
----------------------------------------
</code></pre><p>Como podemos ver, si hacemos un <code>net-define</code> y después un <code>net-list</code> la red no está activa, pero si ejecutamos un <code>net-list --all</code>, podremos ver que dicha red está definida pero inactiva</p>
<pre><code>virsh -c qemu:///system net-list --all
 Name      State      Autostart   Persistent
----------------------------------------------
 default   inactive   no          yes
</code></pre><p>Para activar dicha red, deberemos hacer un <code>net-start</code></p>
<pre><code>virsh -c qemu:///system net-start default
Network default started

 virsh -c qemu:///system net-list
 Name      State    Autostart   Persistent
--------------------------------------------
 default   active   no          yes
</code></pre><p>Si queremos eliminar una red definida debemos usar el comando <code>net-undefine</code></p>
<pre><code>virsh -c qemu:///system net-undefine default
</code></pre><p>Por otro lado, vamos a comparar el directorio <code>/etc/libvirt/qemu/networks/</code> antes y después de la definición de nuestra red, ya que antes de definir nuestra red, o solo creándola, nos damos cuenta de que en dicho directorio solo hay un directorio vacío llamado <code>autostart</code></p>
<pre><code>tree /etc/libvirt/qemu/networks/
/etc/libvirt/qemu/networks/
└── autostart

1 directory, 0 files
</code></pre><p>Mientras que si defnimos una red, dicho directorio se encontraría con nuestro fichero xml en su interior.</p>
<pre><code>tree /etc/libvirt/qemu/networks/
/etc/libvirt/qemu/networks/
├── autostart
└── default.xml

1 directory, 1 file
</code></pre><p>Si queremos que nuestra red, además de ser persistente, se arranque por defecto cada vez que nosotros arranquemos nuestra máquina, deberemos hacer un <code>net-autostart</code>, entonces la API crea un enlace simbólico del fichero xml que se ha copiado en <code>/etc/libvirt/qemu/networks/</code> hacia el directorio <code>/etc/libvirt/qemu/networks/autostart</code> ya mencionado anteriormente.</p>
<pre><code>virsh -c qemu:///system net-autostart default
Network default marked as autostarted

virsh -c qemu:///system net-list
 Name      State    Autostart   Persistent
--------------------------------------------
 default   active   yes         yes

ls -l /etc/libvirt/qemu/networks/autostart/
total 0
lrwxrwxrwx 1 root root 38 mar 10 12:04 default.xml -&gt; /etc/libvirt/qemu/networks/default.xml
</code></pre><h3 id="algunos-comandos-de-redes-interesantes">Algunos comandos de redes interesantes</h3>
<ul>
<li>Saber el <code>UUID</code> de una red a partir de su nombre:</li>
</ul>
<pre><code>virsh -c qemu:///system net-uuid default
6e0958c0-12a5-4518-b369-9feeced12d08
</code></pre><ul>
<li>Saber el nombre de una red a partir de su <code>UUID</code>:</li>
</ul>
<pre><code>virsh -c qemu:///system net-name 6e0958c0-12a5-4518-b369-9feeced12d08
default
</code></pre><ul>
<li>Información de la red</li>
</ul>
<pre><code>virsh -c qemu:///system net-info default
Name:           default
UUID:           6e0958c0-12a5-4518-b369-9feeced12d08
Active:         yes
Persistent:     yes
Autostart:      yes
Bridge:         virbr0
</code></pre><h2 id="creación-de-pool-por-defecto">Creación de pool por defecto</h2>
<p><code>Pool</code> es el término que usa <code>libvirt</code> para referirse a los sistemas de almacenamiento que podemos tener en los sistemas de virtualización.</p>
<p>Para poder definir un pool, necesitamos definir otro objeto con otro fichero xml, como por ejemplo este:</p>
<pre><code>&lt;pool type='dir'&gt;
 &lt;name&gt;default&lt;/name&gt;
 &lt;target&gt;
  &lt;path&gt;/libvirt/pool1&lt;/path&gt;
 &lt;/target&gt;
&lt;/pool&gt;
</code></pre><ul>
<li>Tenemos un fichero <code>xml</code> que crea un objeto de tipo <code>pool</code> de tipo <code>dir</code> (directorio)
<ul>
<li>El cual se llama <code>default</code></li>
<li>Y está ubicado en <code>/libvirt/pool1</code></li>
</ul>
</li>
</ul>
<p>Para listar los dispositivos de almacenamiento que tenemos tanto activos como inactivos haremos lo mismo que para listar las redes, ya que el modo de empleo es el mismo.</p>
<p>Si queremos crear un <code>pool</code> usamos el comando <code>pool-create</code>, si lo queremos definir usamos <code>pool-define</code>, si lo queremos activar usamos <code>pool-start</code> y si lo queremos activar cada vez que arranque el sistema usamos <code>pool-autostart</code>.</p>
<pre><code>virsh -c qemu:///system pool-create pool1.xml
Pool default created from pool1.xml

virsh -c qemu:///system pool-define pool1.xml
Pool default defined from pool1.xml

virsh -c qemu:///system pool-start default
Pool default started

virsh -c qemu:///system pool-autostart default
Pool default marked as autostarted
</code></pre><p>Si queremos listar los <code>pools</code> de almacenamiento activos usaremos el comando <code>pool-list</code> y si queremos listar todos los <code>pools</code>, tanto los activos como los inactivos usaremos <code>pool-list --all</code>.</p>
<pre><code>virsh -c qemu:///system pool-list
 Name      State    Autostart
-------------------------------
 default   active   yes

virsh -c qemu:///system pool-list --all
 Name      State    Autostart
-------------------------------
 default   active   yes
</code></pre><p>El directorio equivalente a <code>/etc/libvirt/qemu/networks/</code> es <code>/etc/libvirt/storage</code> en el cual se copia el fichero xml que hemos creado para definir el objeto y en el directorio <code>/etc/libvirt/storage/autostart</code> se encuentra el enlace simbólico de autoarranque del pool.</p>
<pre><code>tree /etc/libvirt/storage/
/etc/libvirt/storage/
├── autostart
│   └── default.xml -&gt; /etc/libvirt/storage/default.xml
└── default.xml

1 directory, 2 files
</code></pre><p>Cuando hemos definido un pool, a parte de poder ver el fichero xml que se ha copiado en <code>/etc/libvirt/storage</code>, podemos usar el comando <code>pool-dumpxml</code> para ver el fichero que se ha generado/copiado en dicho directorio.</p>
<pre><code>virsh -c qemu:///system pool-dumpxml default
&lt;pool type='dir'&gt;
  &lt;name&gt;default&lt;/name&gt;
  &lt;uuid&gt;12554be7-613e-4603-ab87-ffcfbc249b22&lt;/uuid&gt;
  &lt;capacity unit='bytes'&gt;107321753600&lt;/capacity&gt;
  &lt;allocation unit='bytes'&gt;140763136&lt;/allocation&gt;
  &lt;available unit='bytes'&gt;107180990464&lt;/available&gt;
  &lt;source&gt;
  &lt;/source&gt;
  &lt;target&gt;
    &lt;path&gt;/libvirt/pool1&lt;/path&gt;
    &lt;permissions&gt;
      &lt;mode&gt;0755&lt;/mode&gt;
      &lt;owner&gt;1000&lt;/owner&gt;
      &lt;group&gt;1000&lt;/group&gt;
    &lt;/permissions&gt;
  &lt;/target&gt;
&lt;/pool&gt;
</code></pre><p>Si queremos eliminar un pool definido, deberemos usar la misma opción que para las redes, el comando <code>pool-undefine</code></p>
<pre><code>virsh -c qemu:///system pool-undefine default
</code></pre><h3 id="definiendo-un-pool-con-qemusession">Definiendo un pool con qemu:///session</h3>
<p>Ahora vamos a crear un <code>pool</code> de almacenamiento con <code>qemu:///session</code>. Este es el fichero xml</p>
<pre><code>&lt;pool type='dir'&gt;
  &lt;name&gt;default&lt;/name&gt;
  &lt;target&gt;
    &lt;path&gt;/home/juanan/.config/libvirt/storage&lt;/path&gt;
  &lt;/target&gt;
&lt;/pool&gt;
</code></pre><ul>
<li>Tenemos un fichero xml que define un objeto <code>pool</code> de tipo <code>dir</code> (directorio)
<ul>
<li>Se llama <code>default</code></li>
<li>Y se almacena en el directorio predeterminado para los <code>pools</code> de <code>qemu:///session</code>, que se encuentra en un directorio oculto dentro del directorio <code>/home/usuario</code> y cuyo directorio tiene la misma estructura que tenemos en el directorio <code>/etc/libvirt</code></li>
</ul>
</li>
</ul>
<p>La manera de definir los <code>pools</code> se almacenamiento de <code>qemu:///session</code> es exactamente la misma que cuando los creamos con <code>qemu:///system</code>, pero en este caso no es necesario poner <code>qemu:///session</code>, por lo que con solo ejecutar <code>virsh pool-create [fichero_xml]</code> podemos ejecutar la instrucción.</p>
<h2 id="manejo-de-volúmenes-con-virsh">Manejo de volúmenes con virsh</h2>
<p>Anteriormente hemos creado un pool de almacenamiento en la ruta <code>/libvirt/pool1</code>, el cual es un directorio. Ahora, en dicho directorio, vamos a crear un volúmen, el cual es un fichero que no sva a servir como dispositivo de almacenamiento de una máquina virtual, para realizar esto, vamos a volver a definir otros objetos con ficheros xml:</p>
<pre><code>&lt;volume type='file'&gt;
  &lt;name&gt;vol1&lt;/name&gt;
  &lt;key&gt;/libvirt/pool1/vol1.img&lt;/key&gt;
  &lt;source&gt;
  &lt;/source&gt;
  &lt;allocation&gt;0&lt;/allocation&gt;
  &lt;capacity unit=&quot;G&quot;&gt;10&lt;/capacity&gt;
  &lt;target&gt;
    &lt;path&gt;/libvirt/pool1/vol1.img&lt;/path&gt;
    &lt;format type='qcow2'/&gt;
  &lt;/target&gt;
&lt;/volume&gt;
</code></pre><ul>
<li>En este caso tenemos un fichero xml que define un objeto de tipo <code>volumen</code>, el cual es un fichero (tipo <code>file</code>)
<ul>
<li>Su nombre es <code>vol1</code></li>
<li>Tiene una capacidad de <code>10G</code>, aunque le hemos dicho que ocupe lo menos posible en función dle formato que tenga (etiqueta <code>&lt;allocation&gt;0&lt;/allocation&gt;</code>)</li>
<li>Usaremos un tipo de fichero <code>qcow2</code>, el cual permite no ocupar los 10G de imagen en nuestro disco duro.</li>
<li>La ruta hacia el fichero que se va a crear será <code>/libvirt/pool1/vol1.img</code></li>
</ul>
</li>
</ul>
<p>Ahora que tenemos el fichero de configuración de nuestro volúmen, vamos a cerarlo, para ello deberemos tener, anteriormente, un pool creado.</p>
<pre><code>virsh -c qemu:///system vol-create default vol1.xml
Vol vol1 created from vol1.xml
</code></pre><p>Como podemos ver, si hacemos este comando con el fichero de configuración previamente creado, se nos creará nuestro columen en el pool indicado, si vemos el contenido del directorio <code>/libvirt/pool1</code>, vemos que se nos ha creado un archivo llamado <code>vol1</code> y si le preguntamos el tipo con el comando <code>file</code> nos dirá que es de tipo <code>qcow2</code></p>
<pre><code>ls pool1
vol1

sudo file pool1/vol1
pool1/vol1: QEMU QCOW Image (v2), 10737418240 bytes
</code></pre><p><code>QEMU</code> tiene un comando para describir ficheros, si lo usamos nos dará información más detallada sobre el volumen creado</p>
<pre><code>sudo qemu-img info pool1/vol1
image: pool1/vol1
file format: qcow2
virtual size: 10G (10737418240 bytes)
disk size: 196K
cluster_size: 65536
Format specific information:
    compat: 0.10
    refcount bits: 16
</code></pre><p>En la información que nos da el resultado del comando <code>qemu-img info</code> nos dice que nuestra imagen es <code>qcow2</code>, que tiene un tamaño virtual de <code>10G</code>, pero que en nuestro disco duro ocupa <code>196K</code>, ya que el <code>allocation</code> lo hemos dejado a 0. Esto tiene ciertas ventajas y desventajas:</p>
<ul>
<li>
<p><strong>Ventaja de dejar <code>allocation</code> a 0:</strong> Ocupa menos espacio en el disco, es decir, ocupa solo el tamaño que necesita.</p>
</li>
<li>
<p><strong>Desventaja de dejar <code>allocation</code> a 0:</strong> La escritura en dicho volumen es más lenta, ya que tiene que estar aumentando el tamaño cada vez que se va a escribir algo.</p>
</li>
<li>
<p><strong>Ventaja de tener un <code>allocation</code> mayor que 0:</strong> La escritura en el volumen es más rápida, ya que si parte de un tamaño inicial, las primeras escrituras no tienen que aumentar el tamaño del volúmen.</p>
</li>
<li>
<p><strong>Desventajas de tener un <code>allocation</code> mayor que 0:</strong> Ocupa inicialmente más tamaño en el disco duro estando el volumen totalmente vacío.</p>
</li>
</ul>
<p>Vamos a crear otro volumen, pero esta vez de tipo <code>raw</code>, esto es un formato que no admite el <code>allocation</code> 0, es decir, que el tamaño del fichero va a ser el tamaño que este tenga</p>
<pre><code>&lt;volume type='file'&gt;
  &lt;name&gt;vol2&lt;/name&gt;
  &lt;key&gt;/libvirt/pool1/vol2.img&lt;/key&gt;
  &lt;source&gt;
  &lt;/source&gt;
  &lt;allocation&gt;0&lt;/allocation&gt;
  &lt;capacity unit=&quot;G&quot;&gt;5&lt;/capacity&gt;
  &lt;target&gt;
    &lt;path&gt;/libvirt/pool1/vol2.img&lt;/path&gt;
    &lt;format type='raw'/&gt;
  &lt;/target&gt;
&lt;/volume&gt;
</code></pre><pre><code>virsh -c qemu:///system vol-create default vol2.xml
Vol vol2 created from vol2.xml

sudo file pool1/vol2
pool1/vol2: data

sudo qemu-img info pool1/vol2
image: pool1/vol2
file format: raw
virtual size: 5.0G (5368709120 bytes)
disk size: 0
</code></pre><p>Como podemos ver en los resultados de los comando anteriores, el volumen <code>vol2</code> ocupa los 5G que nosotros le hemos asignado aunque le hayamos puesto el <code>allocation</code> a 0, pero como hemos dicho antes, el formato <code>raw</code> no lo admite así que este lo ignora.</p>
<h3 id="redimensionar-un-volumen">Redimensionar un volumen</h3>
<p>Una vez que hemos creado un volumen, podemos cambiar su tamaño si el dispositivo de almacenamiento no se está usando, para ello usaremos el comando <code>vol-resize</code>.</p>
<pre><code>virsh -c qemu:///system vol-resize vol1 12G --pool default --shrink
Size of volume 'vol1' successfully changed to 12G
</code></pre><ul>
<li>Sintaxis: <code>vol-resize [volumen] [tamaño] --pool [pool] --shrink(comprimir el tamaño lo máximo posible)</code></li>
</ul>
<p>Si le hemos aunqmentado el tamaño,m lo podemos comprobar con el comando <code>qemu-img info</code></p>
<pre><code>sudo qemu-img info pool1/vol1
image: pool1/vol1
file format: qcow2
virtual size: 12G (12884901888 bytes)
disk size: 200K
cluster_size: 65536
Format specific information:
    compat: 0.10
    refcount bits: 16
</code></pre><p>Ahora el volumen tiene disponibles <code>12GB</code>, pero soo ocupa <code>200K</code></p>
<h3 id="comandos-interesantes-de-volúmenes">Comandos interesantes de volúmenes</h3>
<ul>
<li><strong><code>vol-clone</code>:</strong> Clonar el dispositivo de almacenamiento de una máquina virtual</li>
<li><strong><code>vol-download</code>:</strong> Descargar volúmenes desde el hipervisor</li>
<li><strong><code>vol-wipe</code>:</strong> Eliminar información sin dejar rastro de lo que pudiese haber en ese volumen.</li>
<li><strong><code>vol-list --pool [pool]</code>:</strong> Listar todos los volúemenes que pertenecen a un pool en concreto.</li>
<li><strong><code>vol-delete</code>:</strong> Eliminar un volumen.</li>
</ul>
<h2 id="definición-de-un-dominio-con-virsh">Definición de un dominio con virsh</h2>
<p>Ahora vamos a ver la creación de dominios (es como se le llaman a las máquinas virtuales) con <code>virsh</code>.</p>
<ul>
<li>Listar los dominios:</li>
</ul>
<pre><code>virsh -c qemu:///system list
 Id   Name   State
--------------------

virsh -c qemu:///system list --all
 Id   Name   State
--------------------
</code></pre><p>Para definir los dominios deberesmo crear otro fichero xml como en los anteriores casos</p>
<pre><code>&lt;domain type=&quot;kvm&quot;&gt;
  &lt;name&gt;dominio1&lt;/name&gt;
  &lt;memory unit=&quot;G&quot;&gt;1&lt;/memory&gt;
  &lt;vcpu&gt;1&lt;/vcpu&gt;
  &lt;os&gt;
    &lt;type arch=&quot;x86_64&quot;&gt;hvm&lt;/type&gt;
  &lt;/os&gt;
  &lt;devices&gt;
    &lt;emulator&gt;/usr/bin/kvm&lt;/emulator&gt;
    &lt;disk type='file' device='disk'&gt;
      &lt;source file='/libvirt/pool1/vol1'/&gt;
      &lt;target dev='vda'/&gt;
    &lt;/disk&gt;
    &lt;interface type=&quot;network&quot;&gt;
      &lt;source network=&quot;default&quot;/&gt;
      &lt;mac address=&quot;52:54:00:86:c6:a9&quot;/&gt;
    &lt;/interface&gt;
    &lt;console&gt;
      &lt;target type='serial'/&gt;
    &lt;/console&gt;
  &lt;/devices&gt;
&lt;/domain&gt;
</code></pre><ul>
<li>Tenemos un fichero xml que crea un objeto tipo dominio y que usa la virtualización de <code>kvm</code>, este se llama <code>dominio1</code>.
<ul>
<li>Tiene <code>1GB</code> de memoria RAM.</li>
<li>Tiene <code>1 core virtual</code>.</li>
<li>Se especifica que vamos a usar una arquitectura x86 y especificamos que es una <code>hvm</code> (<em>Hardware Virtual Machine</em>)</li>
<li>El emulador que usaremos como es <code>kvm</code>, especificamos la ruta hacia él (<code>/usr/bin/kvm</code>)</li>
<li>Le indicamos que el almacenamiento de la máquina va a ser un fichero (<code>file</code>), pero la máquina lo va a ver como si fuera un disco (<code>disk</code>).</li>
<li>Le indicamos también la ruta que tiene el archivo que vamos a usar como dispositivo de almacenamiento (el cual va a ser el volumen <code>vol1</code> que henmos creado anteriormente y está ubicado en <code>/libvirt/pool1/vol1</code>), peor en la máquina aparecerá dicho dispositivo de almacenamiento como un <code>vda</code>.</li>
<li>Le ponemos una interfaz de red conectada a la red llamada <code>default</code>, la cual hemos creado anteriormente y le ponemos una dirección MAC a dicha interfaz (dicha dirección MAC debe tener los 3 primeros octetos de libvirt y los demás aleatorios, es decir, <code>52:54:00:...</code>).</li>
<li>Le indicamos que tenemos una consola tipo serie.</li>
</ul>
</li>
</ul>
<p>Ahora creamos el dominio:</p>
<pre><code>virsh -c qemu:///system define dominio1.xml
Domain dominio1 defined from dominio1.xml
</code></pre><p>Cuando hayamos definido el dominio, se creará una copia del xml en <code>/etc/libvirt/qemu</code></p>
<pre><code>ls /etc/libvirt/qemu
dominio1.xml  networks
</code></pre><p>Si hacemos un <code>list</code>, el dominio que acabamos de definir no aparecerá, ya que no está activo todavía, pero lo podemos ver si hacemos un <code>list --all</code></p>
<pre><code>virsh -c qemu:///system list
 Id   Name   State
--------------------

virsh -c qemu:///system list --all
 Id   Name       State
---------------------------
 -    dominio1   shut off
</code></pre><p>Para crear imágenes para poder arrancar los dominios que creemos vamos a hacer uso de la herramienta <code>virtinst</code>.</p>
<h2 id="virtinst">Virtinst</h2>
<p>El paquete <code>virinst</code> contiene una serie de programas de más alto nivel que <code>virsh</code>, los cuales nos pueden ayudar a realizar determinadas tareas. Así que en lugar de interactuar con ficheros xml, vamos a interactuar con la API de <code>libvirt</code> a través de un comando en nuestra terminal.</p>
<h3 id="virt-install">virt-install</h3>
<p>Este programa se usa para la instalación inicial de una máquina virtual. Ejemplo:</p>
<ul>
<li>
<p><strong>Queremos una máquina virtual con las siguientes especificaciones:</strong></p>
<ul>
<li><strong>1 core virtual</strong></li>
<li><strong>1024 MiB de RAM</strong></li>
<li><strong>Que se conecte a la red <code>default</code> que anteriormente hemos creado</strong></li>
<li><strong>Que cree un volumen de 10GiB en el pool <code>default</code> que hemos creado anteriormente</strong></li>
<li><strong>Que use una imagen ISO netinst de debian 10 que hemos descargado</strong></li>
</ul>
</li>
</ul>
<pre><code>virt-install --connect qemu:///system \
--cdrom /libvirt/debian/debian-10.8.0-amd64-netinst.iso \
--disk size=10 \
--network bridge=virbr0 \
--name dominio1 \
--memory 1024 \
--vcpus 1
</code></pre><p>Si surge el error <code>ERROR    internal error: cannot load AppArmor profile 'libvirt-...'</code> deberemos de editar el fichero <code>/etc/libvirt/qemu.conf</code> y descomentamos la línea <code>416</code> y cmabiamos su valor a <code>none</code> y reiniciamos el servicio de <code>libvirt</code></p>
<pre><code>sudo nano /etc/libvirt/qemu.conf
[...]
security_driver = &quot;none&quot;
[...]
</code></pre><ul>
<li>Para ver la pantalla de un dominio</li>
</ul>
<pre><code>virt-viewer -c qemu:///system [nombre del dominio]
</code></pre><h2 id="creación-de-una-red-nat-desde-fichero-xml">Creación de una red NAT desde fichero XML</h2>
<p>Crear redes desde cero en formato xml como hemos hecho anteriormente es un poco complicado de primeras, pero si usamos las herramientas adecuadas, puede ser un poco más fácil la tarea. Para hacer una red de tipo <code>NAT</code> con un fichero xml desde cero, vamos a usar las siguientes herramientas para ayudarnos:</p>
<ul>
<li><a href="https://libvirt.org/format.html">Documentación de libvirt</a></li>
<li>Editor de texto <code>emacs</code> con el modo xml activo</li>
<li><a href="https://github.com/libvirt/libvirt.git">Repositorio de libvirt</a> con los esquemas para cargarle al editar <code>emacs</code></li>
<li><code>trang</code> para convertir ficheros</li>
</ul>
<p>Sabiendo las herramientas que vamos a usar, vamos a comenzar por instalar el editor de texto (si no lo tenemos) y a clonar el repositorio</p>
<pre><code>sudo apt-get install emacs

git clone https://github.com/libvirt/libvirt.git
</code></pre><p>En el interior del repositorio que acabamos de clonar hay una carpeta llamada <code>docs/schemas/</code> en la cual se encuentran los esquemas que hay que seguir para realizar los fichero xml de configuración. Estos archivos de esquema están en formato <code>rng</code>, pero el editor <code>emacs</code> solo admite <code>rnc</code> (un formato más comprimido que <code>rng</code>), así que convertiremos el archivo <code>network.rng</code> en <code>network.rnc</code> con la herramienta <code>trang</code></p>
<pre><code>trang -I rng -O rnc network.rng network.rnc

ls -hrtl
[...]
-rw-r--r-- 1 juanan juanan 5,6K mar 17 17:15 network.rnc
-rw-r--r-- 1 juanan juanan 2,8K mar 17 17:15 networkcommon.rnc
-rw-r--r-- 1 juanan juanan 9,0K mar 17 17:15 basictypes.rnc
</code></pre><p>Como podemos ver, se han creado tres ficheros, uno de ellos el fichero <code>network.rnc</code> y los otros dos son dependencias que necesita el fichero ya mencionado.</p>
<p>Ahora pasaremos a crear el fichero xml, para ello, como hemos dicho anteriormente, usaremos <code>emacs</code></p>
<pre><code>emacs red1.xml
</code></pre><p>Cuando tengamos nuestro editor arrancado, vamos a cargarle los esquemas necesarios, para ello nos dirigimos a <code>XML --&gt; Set Schema --&gt; File</code> y seleccionamos nuestro archivo <code>network.rnc</code></p>
<p>Otro dato es que si queremos generar un <code>UUID</code> aleatorio para crear nuestra red, lo podemos hacer de la siguiente manera</p>
<pre><code>cat /proc/sys/kernel/random/uuid
</code></pre><p>Si queremos una dirección MAC aleatoria con los tres primeros octetos del fabricante de libvirt, ejecutamos el siguiente comando</p>
<pre><code>openssl rand -hex 3 | sed 's/\(..\)\(..\)\(..\)/52:54:00:\1:\2:\3/'
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Practica VPN</title>
            <link>https://juanan219.github.io/posts/2021/03/practica-vpn/</link>
            <pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/03/practica-vpn/</guid>
            <description>Tarea1: VPN de acceso remoto con OpenVNP y certificados x509 En esta tarea vamos a montar una VPN con OpenVPN con certificados x509 generados usando la herramienta easy-rsa, para ello vamos a hacer el uso de 3 máquinas:
 Mi máquina personal (Cliente) Servidor (Servidor VPN) Máquina de la red interna (Máquina a la que nos vamos a conectar)  Instalación de las herramientas Para realizar esta tarea vamos a necesitar instalar OpenVPN tanto en mi máquina como en el servidor</description>
            <content type="html"><![CDATA[<h2 id="tarea1-vpn-de-acceso-remoto-con-openvnp-y-certificados-x509">Tarea1: VPN de acceso remoto con OpenVNP y certificados x509</h2>
<p>En esta tarea vamos a montar una <code>VPN</code> con <code>OpenVPN</code> con certificados x509 generados usando la herramienta <code>easy-rsa</code>, para ello vamos a hacer el uso de 3 máquinas:</p>
<ol>
<li>Mi máquina personal (Cliente)</li>
<li>Servidor (Servidor VPN)</li>
<li>Máquina de la red interna (Máquina a la que nos vamos a conectar)</li>
</ol>
<h3 id="instalación-de-las-herramientas">Instalación de las herramientas</h3>
<p>Para realizar esta tarea vamos a necesitar instalar <code>OpenVPN</code> tanto en mi máquina como en el servidor</p>
<pre><code>juanan@juananpc:~$ sudo apt-get install openvpn

debian@vpn-server:~$ sudo apt-get install openvpn
</code></pre><p>También necesitaremos descargar la herramienta <code>easy-rsa</code> de su <a href="https://github.com/OpenVPN/easy-rsa">repositorio oficial de github</a> para ello necesitaremos el paquete <code>git</code></p>
<pre><code>debian@vpn-server:~$ sudo apt-get install git
debian@vpn-server:~$ git clone https://github.com/OpenVPN/easy-rsa.git

juanan@juananpc:~$ sudo apt-get install git
juanan@juananpc:~/GitHub$ git clone https://github.com/OpenVPN/easy-rsa.git
</code></pre><p>Ahora que tenemos todo listo para comenzar, vamos a generar las claves tanto del servidor como del cliente.</p>
<h3 id="generación-de-claves">Generación de claves</h3>
<p>Vamos a necesitar las siguientes claves:</p>
<ul>
<li>
<p><strong>Servidor:</strong></p>
<ul>
<li>Parámetros <code>Diffie-Hellman</code></li>
<li>Clave privada de la CA</li>
<li>Certificado de la CA</li>
<li>Clave privada del servidor VPN</li>
<li>Certificado del servidor VPN</li>
</ul>
</li>
<li>
<p><strong>Cliente:</strong></p>
<ul>
<li>Certificado de la CA</li>
<li>Clave privada del cliente</li>
<li>Certificado del cliente frimado por la CA</li>
</ul>
</li>
</ul>
<h4 id="servidor">Servidor</h4>
<p>Comenzaremos generando las claves del servidor, así que para comenzar a generarlas deberemos inicializar nuestra herramienta <code>easy-rsa</code> de la siguiente manera</p>
<pre><code>debian@vpn-server:~ cd easy-rsa/easyrsa3
debian@vpn-server:~/easy-rsa/easyrsa3$ ./easyrsa init-pki
</code></pre><p>Con esta opción se nos habŕa creado un directorio llamado <code>pki</code> en el cual se van a ir añadiendo todas las claves, certificados y peticiones de estos que vayamos generando.</p>
<p>Definimos las variables, para ello copiamos el fichero <code>vars.example</code> y lo llamamos <code>vars</code> para más tarde editarlo, descomentar las siguientes líneas y lo editamos a nuestra conveniencia.</p>
<pre><code>debian@vpn-server:~/easy-rsa/easyrsa3$ cp vars.example vars

nano vars
[...]
set_var EASYRSA_REQ_COUNTRY     &quot;ES&quot;
set_var EASYRSA_REQ_PROVINCE    &quot;Sevilla&quot;
set_var EASYRSA_REQ_CITY        &quot;Dos Hermanas&quot;
set_var EASYRSA_REQ_ORG         &quot;IESGN&quot;
set_var EASYRSA_REQ_EMAIL       &quot;initiategnat9@gmail.com&quot;
set_var EASYRSA_REQ_OU          &quot;Informatica&quot;
[...]
</code></pre><p>Generamos el parámetro <code>Diffie-Hellman</code>, el cual se almacena en <code>~/easy-rsa/easyrsa3/pki/dh.pem</code></p>
<pre><code>debian@vpn-server:~/easy-rsa/easyrsa3$ ./easyrsa gen-dh
</code></pre><p>Generamos la clave y el cerficado de la CA, el certificado <code>ca.crt</code> se almacena en  <code>~/easy-rsa/easyrsa3/pki/ca.crt</code> y la clave privada <code>ca.key</code> se almacena en <code>~/easy-rsa/easyrsa3/pki/private/ca.key</code></p>
<pre><code>debian@vpn-server:~/easy-rsa/easyrsa3$ ./easyrsa build-ca nopass
</code></pre><p>Generamos la clave y la petición del certificado del servidor, la petición del certificado <code>servidor.req</code> se almacena en <code>~/easy-rsa/easyrsa3/pki/reqs/servidor.req</code> y la clave privada <code>servidor.key</code> se almacena en <code>~/easy-rsa/easyrsa3/pki/private/servidor.key</code></p>
<pre><code>debian@vpn-server:~/easy-rsa/easyrsa3$ ./easyrsa gen-req servidor nopass
</code></pre><p>Ahora vamos a generar el certificado firmando la petición del certificado, el certificado <code>servidor.crt</code> se almacena en <code>~/easy-rsa/easyrsa3/pki/issued/servidor.crt</code></p>
<pre><code>debian@vpn-server:~/easy-rsa/easyrsa3$ ./easyrsa sign-req server servidor
</code></pre><h4 id="cliente">Cliente</h4>
<p>Ahora pasamos a la generación de claves del cliente, las uales las vamos a generar de la misma forma, pero con la diferencia de que la petición del certificado se lo tendremos que hacer llegar de alguna forma a la CA.</p>
<p>Inicializamos la herramienta</p>
<pre><code>juanan@juananpc:~/GitHub/easy-rsa/easyrsa3$ ./easyrsa init-pki
</code></pre><p>Generamos la clave privada y la petición del certificado</p>
<pre><code>juanan@juananpc:~/GitHub/easy-rsa/easyrsa3$ ./easyrsa gen-req cliente nopass
</code></pre><p>Pasamos la petición del certificado al servidor, lo generamos y se lo devolvemos al cliente</p>
<pre><code>juanan@juananpc:~/GitHub/easy-rsa/easyrsa3$ scp pki/reqs/cliente.req debian@172.22.201.68:/home/debian/easy-rsa/easyrsa3/pki/reqs

debian@vpn-server:~/easy-rsa/easyrsa3$ ./easyrsa sign-req client cliente

debian@vpn-server:~$ scp easy-rsa/easyrsa3/pki/issued/cliente.crt juanan@172.22.4.124:/home/juanan/GitHub/easy-rsa/easyrsa3/pki
</code></pre><h3 id="configuración-de-las-máquinas">Configuración de las máquinas</h3>
<p>Ahora vamos a copiar las claves del servidor al directorio <code>/etc/openvpn/keys</code></p>
<pre><code>debian@vpn-server:~$ sudo mkdir /etc/openvpn/keys
debian@vpn-server:~/easy-rsa/easyrsa3$ sudo cp pki/ca.crt /etc/openvpn/keys/
debian@vpn-server:~/easy-rsa/easyrsa3$ sudo cp pki/private/ca.key /etc/openvpn/keys/
debian@vpn-server:~/easy-rsa/easyrsa3$ sudo cp pki/issued/servidor.crt /etc/openvpn/keys/
debian@vpn-server:~/easy-rsa/easyrsa3$ sudo cp pki/private/servidor.key /etc/openvpn/keys/
debian@vpn-server:~/easy-rsa/easyrsa3$ sudo cp pki/dh.pem /etc/openvpn/keys/
</code></pre><p>Pasamos las claves necesarias del servidor al cliente y realizamos el mismo proceso de copiarlas al directorio <code>/etc/openvpn/keys</code></p>
<pre><code>debian@vpn-server:~/easy-rsa/easyrsa3$ scp pki/ca.crt  juanan@172.22.4.124:/home/juanan/GitHub/easy-rsa/easyrsa3/pki
juanan@juananpc:~/GitHub/easy-rsa/easyrsa3$ sudo mkdir /etc/openvpn/keys
juanan@juananpc:~/GitHub/easy-rsa/easyrsa3$ sudo cp pki/ca.crt /etc/openvpn/keys/
juanan@juananpc:~/GitHub/easy-rsa/easyrsa3$ sudo cp pki/cliente.crt /etc/openvpn/keys/
juanan@juananpc:~/GitHub/easy-rsa/easyrsa3$ sudo cp pki/private/cliente.key /etc/openvpn/keys/
</code></pre><h4 id="configuración-del-servidor">Configuración del servidor</h4>
<p>Para configurar <code>OpenVPN</code>, deberemos crear un fichero <code>.conf</code> en el directorio <code>/etc/openvpn</code>, el cual va a contener la configuración de nuestro servidor</p>
<pre><code>debian@vpn-server:~$ sudo nano /etc/openvpn/servidor.conf

#Dispositivo de túnel
dev tun

#Direcciones IP virtuales

server 10.99.99.0 255.255.255.0

#subred local
push “route 192.168.100.0 255.255.255.0”

# Rol de servidor
tls-server

#Parámetros Diffie-Hellman
dh /etc/openvpn/keys/dh.pem

#Certificado de la CA
ca /etc/openvpn/keys/ca.crt

#Certificado local
cert /etc/openvpn/keys/server.crt

#Clave privada local
key /etc/openvpn/keys/server.key

#Activar la compresión LZO
comp-lzo

#Detectar caídas de la conexión
keepalive 10 60

#Archivo de log
log /var/log/office.log

#Nivel de información
verb 3
</code></pre><p>Podemos comprobar que ha salido bien si al arrancar el servicio de <code>openvpn</code> con la configuración actual, se nos añade una tarjeta de red <code>tun0</code></p>
<pre><code>debian@vpn-server:~$ sudo openvpn /etc/openvpn/servidor.conf

debian@vpn-server:~$ ip a
[...]
4: tun0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UNKNOWN group default qlen 100
    link/none 
    inet 10.99.99.1 peer 10.99.99.2/32 scope global tun0
       valid_lft forever preferred_lft forever
    inet6 fe80::b69e:f447:a995:44f3/64 scope link stable-privacy 
       valid_lft forever preferred_lft forever
</code></pre><h4 id="configuración-del-cliente">Configuración del cliente</h4>
<p>Creamos otro fichero de configyración llamado <code>.conf</code> en el directorio <code>/etc/openvpn</code> con nuestra configuración</p>
<pre><code>juanan@juananpc:~/GitHub/easy-rsa/easyrsa3$ sudo nano /etc/openvpn/cliente.conf

#Dispositivo de túnel
dev tun

#Direcciones remota
remote 172.22.201.68

#Aceptar directivas del extremo remoto
pull

# Rol de cliente
tls-client

#Certificado de la CA
ca /etc/openvpn/ca.crt

#Certificado local
cert /etc/openvpn/client1.crt

#Clave privada local
key /etc/openvpn/client1.key

#Activar la compresión LZO
comp-lzo

#Detectar caídas de la conexión
keepalive 10 60

#Nivel de información
verb 3
</code></pre><p>Comprobamos que tenemos conexión a nuestro cliente de la red <code>lan</code>, para ello deberemos encender los dos procesos de <code>openvpn</code>, tanto el del cliente como el del servidor</p>
<pre><code>debian@vpn-server:~$ sudo openvpn /etc/openvpn/servidor.conf

juanan@juananpc:~/GitHub/easy-rsa$ sudo openvpn /etc/openvpn/cliente.conf

juanan@juananpc:~/GitHub/easy-rsa$ ping 192.168.100.10
PING 192.168.100.10 (192.168.100.10) 56(84) bytes of data.
64 bytes from 192.168.100.10: icmp_seq=6 ttl=63 time=4.91 ms
[...]
--- 192.168.100.10 ping statistics ---
9 packets transmitted, 4 received, 55.5556% packet loss, time 81ms
rtt min/avg/max/mdev = 3.601/4.045/4.912/0.509 ms
</code></pre><p>Ahora que sabemos que tenemos conexión, vamos a conectarnos por <code>ssh</code> a dicha máquina:</p>
<pre><code>juanan@juananpc:~$ ssh debian@192.168.100.10
Linux lan 4.19.0-11-cloud-amd64 #1 SMP Debian 4.19.146-1 (2020-09-17) x86_64

The programs included with the Debian GNU/Linux system are free software;
the exact distribution terms for each program are described in the
individual files in /usr/share/doc/*/copyright.

Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent
permitted by applicable law.
Last login: Tue Mar  9 11:37:21 2021 from 10.99.99.2
debian@lan:~$
</code></pre><blockquote>
<p>El parámetro <code>Diffie-Hellman</code> usado anteriormente es una forma de hacer que las dos partes involucradas en una transacción SSL acuerden un secreto compartido en un canal inseguro.</p>
</blockquote>
<h2 id="tarea-2-vpn-de-sitio-a-sitio-con-openvpn-y-certificados-x509">Tarea 2: VPN de sitio a sitio con OpenVPN y certificados x509</h2>
<p>Configura una conexión sitio a sitio entre dos equipos del cloud:</p>
<ul>
<li>
<p>Cada equipo estará conectado a dos redes, una de ellas en común</p>
</li>
<li>
<p>Para la autenticación de los extremos se usarán obligatoriamente certificados digitales, que se generarán utilizando openssl y se almacenarán en el directorio /etc/openvpn, junto con con los parámetros Diffie-Helman y el certificado de la propia Autoridad de Certificación.</p>
</li>
<li>
<p>Se utilizarán direcciones de la red 10.99.99.0/24 para las direcciones virtuales de la VPN.</p>
</li>
<li>
<p>Tras el establecimiento de la VPN, una máquina de cada red detrás de cada servidor VPN debe ser capaz de acceder a una máquina del otro extremo.</p>
</li>
</ul>
<p>Ahora vamos a realizar una conexión sitio a sitio con <code>OpenVPN</code>, con lo cual vamos a tener 2 redes y 4 máquinas:</p>
<ul>
<li>
<p>Red 1:</p>
<ul>
<li>Server VPN 1 (conectado a red externa y red VPN 1)</li>
<li>Cliente VPN 1 (conectado a la red VPN 1)</li>
</ul>
</li>
<li>
<p>Red 2:</p>
<ul>
<li>Server VPN 2 (conectado a red externa y red VPN 2)</li>
<li>Cliente VPN 2 (conectado a la red VPN 2)</li>
</ul>
</li>
</ul>
<p>En esta configuración vamos a poner el <code>Servidor VPN 1</code> como servidor y el <code>Servidor VPN 2</code> como cliente de esta conexión.</p>
<h3 id="servidor-vpn-1">Servidor VPN 1</h3>
<ul>
<li>Instalamos <code>git</code> y <code>OpenVPN</code> y clonamos el <a href="https://github.com/OpenVPN/easy-rsa.git">repositorio de <code>easy-rsa</code></a></li>
</ul>
<pre><code>debian@vpn1:~$ sudo apt-get update

debian@vpn1:~$ sudo apt-get install git openvpn

debian@vpn1:~$ git clone https://github.com/OpenVPN/easy-rsa.git
</code></pre><ul>
<li>Configuramos las variables de entorno</li>
</ul>
<pre><code>debian@vpn1:~$ cd easy-rsa/easyrsa3/

debian@vpn1:~/easy-rsa/easyrsa3$ cp vars.example vars

debian@vpn1:~/easy-rsa/easyrsa3$ nano vars
[...]
set_var EASYRSA_REQ_COUNTRY     &quot;ES&quot;
set_var EASYRSA_REQ_PROVINCE    &quot;Sevilla&quot;
set_var EASYRSA_REQ_CITY        &quot;Dos Hermanas&quot;
set_var EASYRSA_REQ_ORG         &quot;Informatica&quot;
set_var EASYRSA_REQ_EMAIL       &quot;initiategnat9@gmail.com&quot;
set_var EASYRSA_REQ_OU          &quot;servervpn1&quot;
[...]
</code></pre><ul>
<li>Generamos las claves necesarias</li>
</ul>
<pre><code>debian@vpn1:~/easy-rsa/easyrsa3$ ./easyrsa init-pki

debian@vpn1:~/easy-rsa/easyrsa3$ ./easyrsa build-ca nopass

debian@vpn1:~/easy-rsa/easyrsa3$ ./easyrsa gen-req server nopass

debian@vpn1:~/easy-rsa/easyrsa3$ ./easyrsa sign-req server server

debian@vpn1:~/easy-rsa/easyrsa3$ ./easyrsa gen-dh
</code></pre><ul>
<li>Creamos el directorio <code>/etc/openvpn/keys</code> y copiamos todas las claves generadas anteriormente a ese directorio para simplificar la configuración que vamos a realizar posteriormente.</li>
</ul>
<pre><code>debian@vpn1:~/easy-rsa/easyrsa3$ sudo mkdir /etc/openvpn/keys
debian@vpn1:~/easy-rsa/easyrsa3$ sudo cp pki/ca.crt /etc/openvpn/keys/
debian@vpn1:~/easy-rsa/easyrsa3$ sudo cp pki/private/server.key /etc/openvpn/keys/
debian@vpn1:~/easy-rsa/easyrsa3$ sudo cp pki/dh.pem /etc/openvpn/keys/
debian@vpn1:~/easy-rsa/easyrsa3$ sudo cp pki/issued/server.crt /etc/openvpn/keys/

debian@vpn1:~/easy-rsa/easyrsa3$ ls /etc/openvpn/keys/
ca.crt  dh.pem  server.crt  server.key
</code></pre><ul>
<li>Creamos el fichero <code>/etc/openvpn/server.conf</code> y configuramos nuestra conexión VPN de punto a punto.</li>
</ul>
<pre><code>debian@vpn1:~/easy-rsa/easyrsa3$ sudo nano /etc/openvpn/server.conf

# nombre de la interfaz
dev tun

# Direcciones IP virtuales
ifconfig 10.99.99.1 10.99.99.2

# Subred eth1 de la maquina destino
route 192.168.101.0 255.255.255.0

# Rol de Servidor
tls-server

# Parámetros Diffie-Hellman
dh /etc/openvpn/keys/dh.pem

# #Certificado de la CA
ca /etc/openvpn/keys/ca.crt

# Certificado Servidor
cert /etc/openvpn/keys/server.crt

# Clave privada servidor
key /etc/openvpn/keys/server.key

# Compresión LZO
comp-lzo

# Tiempo de vida
keepalive 10 60

# Fichero de log
log /var/log/servidor.log

# Nivel de Depuración
verb 6
</code></pre><p>Ahora solo queda completar la configuración para que las máquinas de la red <code>VPN1</code> puedan acceder al exterior</p>
<pre><code>debian@vpn1:~/easy-rsa/easyrsa3$ sudo su -

root@vpn1:~# echo 1 &gt; /proc/sys/net/ipv4/ip_forward

root@vpn1:~# iptables -t nat -A POSTROUTING -o eth0 -s 192.168.100.0/24 -j MASQUERADE
</code></pre><h3 id="servidor-vpn-2">Servidor VPN 2</h3>
<p>Ahora vamos a pasar a la configuración del servidor vpn 2, el cual actuará como cliente.</p>
<ul>
<li>Realizamos la configuración necesaria para las máquinas de nuestra red se conecten con el exterior</li>
</ul>
<pre><code>debian@vpn2:~$ sudo su -

root@vpn2:~# echo 1 &gt; /proc/sys/net/ipv4/ip_forward

root@vpn2:~# iptables -t nat -A POSTROUTING -o eth0 -s 192.168.101.0/24 -j MASQUERADE
</code></pre><ul>
<li>Generamos las claves necesarias</li>
</ul>
<pre><code>debian@vpn2:~/easy-rsa/easyrsa3$ ./easyrsa init-pki

debian@vpn2:~/easy-rsa/easyrsa3$ ./easyrsa gen-req cliente nopass
</code></pre><ul>
<li>Pasamos la petición de certificado a nuestro servidor vpn <code>vpn1</code> para generar el certificado</li>
</ul>
<pre><code>debian@vpn2:~/easy-rsa/easyrsa3$ scp pki/reqs/cliente.req debian@192.168.1.62:/home/debian/easy-rsa/easyrsa3/pki/reqs/

debian@vpn1:~/easy-rsa/easyrsa3$ ./easyrsa sign-req client cliente

debian@vpn1:~/easy-rsa/easyrsa3$ scp pki/issued/cliente.crt debian@192.168.1.82:/home/debian/easy-rsa/easyrsa3/pki/cliente.crt
</code></pre><ul>
<li>Pasamos al cliente <code>vpn2</code> el certificado de nuestra CA</li>
</ul>
<pre><code>debian@vpn1:~/easy-rsa/easyrsa3$ scp pki/ca.crt debian@192.168.1.82:/home/debian/easy-rsa/easyrsa3/pki
</code></pre><ul>
<li>Copiamos las claves en el directorio <code>/etc/openvpn/keys</code></li>
</ul>
<pre><code>debian@vpn2:~/easy-rsa/easyrsa3$ sudo mkdir /etc/openvpn/keys
debian@vpn2:~/easy-rsa/easyrsa3$ sudo cp pki/ca.crt /etc/openvpn/keys/
debian@vpn2:~/easy-rsa/easyrsa3$ sudo cp pki/private/cliente.key /etc/openvpn/keys/
debian@vpn2:~/easy-rsa/easyrsa3$ sudo cp pki/cliente.crt /etc/openvpn/keys/
</code></pre><ul>
<li>Creamos el fichero de configuración para el cliente</li>
</ul>
<pre><code>debian@vpn2:~/easy-rsa/easyrsa3$ nano /etc/openvpn/cliente.conf

# nombre de la interfaz
dev tun

# Direcciones IP virtuales
ifconfig 10.99.99.2 10.99.99.1

#Ip eth0 servidor
remote 192.168.1.62

# Subred eth1 de la maquina destino
route 192.168.100.0 255.255.255.0

# Rol de Servidor
tls-client

# #Certificado de la CA
ca /etc/openvpn/keys/ca.crt

# Certificado Servidor
cert /etc/openvpn/keys/cliente.crt

# Clave privada servidor
key /etc/openvpn/keys/cliente.key

# Compresión LZO
comp-lzo

# Tiempo de vida
keepalive 10 60

# Fichero de log
log /var/log/cliente.log

# Nivel de Depuración
verb 6
</code></pre><h2 id="tarea-3-servidor-vpn-en-dulcinea">Tarea 3: Servidor VPN en Dulcinea</h2>
<p>Ahora vamos a crear un servidor VPN en nuestra máquina del cloud <code>Dulcinea</code>. Para ello vamos a realizar los mismos pasos iniciales que con las anteriores máquinas. Primero descargaremos las herramientas necesarias, después generaremos las claves necesarias tanto del servidor como del cliente y después crearemos los ficheros de configuración. Aquí están los ficheros de congfiguración tanto de dulcinea como de mi máquina cliente.</p>
<h3 id="fichero-de-configuración-de-dulcinea">Fichero de configuración de Dulcinea</h3>
<pre><code># nombre de la interfaz
dev tun

# Direcciones IP virtuales
ifconfig 10.99.99.1 10.99.99.2

# Rol de Servidor
tls-server

# Parámetros Diffie-Hellman
dh /etc/openvpn/keys/dh.pem

# Certificado de la CA
ca /etc/openvpn/keys/ca.crt

# Certificado de dulcinea
cert /etc/openvpn/keys/dulcinea.crt

# Clave de dulcinea
key /etc/openvpn/keys/dulcinea.key

# Activar la compresión LZO
comp-lzo

# Detectar caidas de la conexión
keepalive 10 60

# Archivo de log
log /var/log/openvpn/server.log

# Nivel de información
verb 3
</code></pre><h3 id="fichero-de-configuración-de-mi-máquina-cliente">Fichero de configuración de mi máquina cliente</h3>
<pre><code># Dispositivo de túnel
dev tun

# Direcciones de IP virtuales
ifconfig 10.99.99.2 10.99.99.1

# Dirección IP del servidor
remote 172.22.200.100

# Red remota
route 10.0.1.0 255.255.255.0
route 10.0.2.0 255.255.255.0

# Rol de cliente
tls-client

# Certificado de la CA
ca /etc/openvpn/keys/ca.crt

# Certificado del cliente
cert /etc/openvpn/keys/cliente.crt

# Clave privada del cliente
key /etc/openvpn/keys/cliente.key

# Activar la compresión LZO
comp-lzo

# Detectar caídas de la conexión
keepalive 10 60

# Archivo de log
log /var/log/openvpn/cliente.log

# Nivel de información
verb 3
</code></pre><h3 id="pruebas-de-funcionamiento">Pruebas de funcionamiento</h3>
<p>Ahora vamos a comprobar que esta configuración funciona, para ello vamos a hacer ping a las dos subredes que hay detrás de <code>dulcinea</code>:</p>
<ul>
<li><strong>Ping a la red 10.0.1.0/24</strong></li>
</ul>
<pre><code>juanan@juananpc:~/GitHub/easy-rsa/easyrsa3$ ping 10.0.1.5
PING 10.0.1.5 (10.0.1.5) 56(84) bytes of data.
64 bytes from 10.0.1.5: icmp_seq=1 ttl=63 time=3.76 ms
--- 10.0.1.5 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 3.756/3.756/3.756/0.000 ms
</code></pre><ul>
<li><strong>Ping a la red 10.0.2.0/24</strong></li>
</ul>
<pre><code>juanan@juananpc:~/GitHub/easy-rsa/easyrsa3$ ping 10.0.2.2
PING 10.0.2.2 (10.0.2.2) 56(84) bytes of data.
64 bytes from 10.0.2.2: icmp_seq=1 ttl=63 time=3.64 ms
64 bytes from 10.0.2.2: icmp_seq=2 ttl=63 time=3.16 ms
--- 10.0.2.2 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 3ms
rtt min/avg/max/mdev = 3.161/3.398/3.635/0.237 ms
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Implantación de aplicaciones web PHP en Docker</title>
            <link>https://juanan219.github.io/posts/2021/03/implantaci%C3%B3n-de-aplicaciones-web-php-en-docker/</link>
            <pubDate>Sun, 07 Mar 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/03/implantaci%C3%B3n-de-aplicaciones-web-php-en-docker/</guid>
            <description>Tarea 1  Crea un script con docker-compose que levante el escenario con los dos contenedores.(Usuario: admin, contraseña: admin).  Para levantar la aplicación web bookmedik necesitaremos un contenedor con la imagen de mariadb en el cual vamos a crear un usuario llamado book_user con una contraseña book_passwd, una base de datos llamada bookmedik y le vamos a volcar el contenido del fichero schema.sql del repositorio de GitHub de bookmedik, del cual, vamos a eliminar la primera línea para que no nos de conflicto a la hora de ejecutar el script.</description>
            <content type="html"><![CDATA[<h2 id="tarea-1">Tarea 1</h2>
<ul>
<li>Crea un script con docker-compose que levante el escenario con los dos contenedores.(Usuario: admin, contraseña: admin).</li>
</ul>
<p>Para levantar la aplicación web <a href="https://github.com/evilnapsis/bookmedik">bookmedik</a> necesitaremos un contenedor con la imagen de <code>mariadb</code> en el cual vamos a crear un usuario llamado <code>book_user</code> con una contraseña <code>book_passwd</code>, una base de datos llamada <code>bookmedik</code> y le vamos a volcar el contenido del fichero <code>schema.sql</code> del repositorio de GitHub de <code>bookmedik</code>, del cual, vamos a eliminar la primera línea para que no nos de conflicto a la hora de ejecutar el script. Al contenedor de <code>mariadb</code> vamos a crearle un volumen para que pueda guardar la base de datos.</p>
<pre><code>docker network create red1--subnet
docker run --name book_sql -v mysql:/var/lib/mysql --network bookmedik -e MYSQL_ROOT_PASSWORD=root -e MYSQL_USER=book_user -e MYSQL_PASSWORD=book_passwd -e MYSQL_DATABASE=bookmedik -d mariadb

docker cp GitHub/bookmedik/schema.sql book_sql:/tmp

docker exec book_sql bash -c 'mysql -u$MYSQL_USER -p$MYSQL_PASSWORD &lt; /tmp/schema.sql'
</code></pre><p>Ahora vamos a crear un <code>Dockerfile</code> para crear una imagen que nos sirva la aplicación <code>Bookmedik</code>, para ello tendremos que crear un script que cambie las variables de entorno por las nuestras y cree la imagen.</p>
<ul>
<li>Este es el script:</li>
</ul>
<pre><code>mkdir bookmedik
cd bookmedik

nano variables.sh

#!/bin/bash
sed -i &quot;s/$this-&gt;user=\&quot;root\&quot;;/$this-&gt;user=\&quot;$MYSQL_USER\&quot;;/g&quot; /var/www/html/core/controller/Database.php
sed -i &quot;s/$this-&gt;pass=\&quot;\&quot;;/$this-&gt;pass=\&quot;$MYSQL_PASSWORD\&quot;;/g&quot; /var/www/html/core/controller/Database.php
sed -i &quot;s/$this-&gt;host=\&quot;localhost\&quot;;/$this-&gt;host=\&quot;$DATABASE_SERVER\&quot;;/g&quot; /var/www/html/core/controller/Database.php
sed -i &quot;s/$this-&gt;ddbb=\&quot;bookmedik\&quot;;/$this-&gt;ddbb=\&quot;$MYSQL_DATABASE\&quot;;/g&quot; /var/www/html/core/controller/Database.php
apache2ctl -D FOREGROUND

chmod +x variables.sh
</code></pre><ul>
<li>Este es el <code>Dokerfile</code>:</li>
</ul>
<pre><code>FROM debian
MAINTAINER Juan Antonio Reifs Ramirez &quot;initiategnat9@gmail.com&quot;

RUN apt-get update &amp;&amp; apt-get install -y apache2 php php-mysql git &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*
RUN rm -r /var/www/html/* &amp;&amp; git clone https://github.com/evilnapsis/bookmedik /var/www/html

ADD variables.sh /usr/local/bin

EXPOSE 80

ENV DATABASE_SERVER=book_sql MYSQL_ROOT_PASSWORD=root MYSQL_USER=book_user MYSQL_PASSWORD=book_passwd MYSQL_DATABASE=bookmedik

CMD [&quot;variables.sh&quot;]
</code></pre><ul>
<li>
<p>Explicación del <code>Dockerfile</code>:</p>
<ul>
<li><strong><code>FROM debian</code>:</strong> Le decimos que la imagen base va a ser <code>debian:latest</code></li>
<li><strong><code>MANTEINER Juan Antonio Reifs Ramirez &quot;initiategnat9@gmail.com&quot;</code>:</strong> Metadatos para saber quién ha creado la imagen</li>
<li><strong><code>RUN apt-get update &amp;&amp; apt-get install -y apache2 php php-mysql git &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*</code>:</strong> Este primer <code>RUN</code> actualiza la lista de paquetes de la imagen para posteriormente descargar los paquetes <code>apache2</code>, <code>php</code>, <code>php-mysql</code> y <code>git</code> y limpia los residuos que dejan las instalaciones.</li>
<li><strong><code>RUN rm -r /var/www/html/* &amp;&amp; git clone https://github.com/evilnapsis/bookmedik /var/www/html</code>:</strong> Con este segundo <code>RUN</code> eliminamos todo el contenido del directorio <code>/var/www/html</code> (que es donde van a ir los archivos de <code>Bookmedik</code>) para más tarde clonar el <a href="https://github.com/evilnapsis/bookmedik">repositorio de Bookmedik</a></li>
<li><strong><code>ADD variables.sh /usr/local/bin</code>:</strong> Añadimos el script que hemos creado anteriormente a nuestra imagen en una ubicación que se encuentre en el <code>$PATH</code>, ya que después, al ejecutarla, no tendremos que poner ninguna ruta.</li>
<li><strong><code>EXPOSE 80</code>:</strong> Apartado informativo para especificar que esta imagen está escuchando en el puerto <code>80</code> de forma predeterminada.</li>
<li><strong><code>ENV DATABASE_SERVER=book_sql MYSQL_ROOT_PASSWORD=root MYSQL_USER=book_user MYSQL_PASSWORD=book_passwd MYSQL_DATABASE=bookmedik</code>:</strong> Variables de entorno predeterminadas para conectar con la base de datos.</li>
<li><strong><code>CMD [&quot;variables.sh&quot;]</code>:</strong> Le indicamos que tiene que ejecutar el script para cambiar las variables prdeterminadas de <code>Bookmedik</code></li>
</ul>
</li>
</ul>
<p>Cuando lo tengamos todo listo, solo queda crear la imagen con el comando <code>docker build</code></p>
<pre><code>docker build -t juanan219/book_debian .

docker images
REPOSITORY                    TAG                 IMAGE ID            CREATED             SIZE
juanan219/book_debian         latest              a7a19bca4040        17 minutes ago      297MB
[...]
</code></pre><p>Ahora que tenemos nuestro contenedor con la imagen de <code>mariadb</code> arrancado y nuestra imagen de <code>Bookmedik</code> creada, vamos a crear un contenedor con dicha imagen. Este contenedor va a tener un volumen que guarde los logs de <code>apache2</code> y va a estar en la misma red llamada <code>bookmedik</code> que nuestro contenedor <code>book_sql</code></p>
<pre><code>docker run --name book_debian -v apache_logs:/var/log/apache2 --network bookmedik -p 80:80 -d juanan219/book_debian
</code></pre><p>Como podemos ver, después de configurarlo todo, ya tenemos nuestro Bookmedik funcionando</p>
<p><img src="/Docker/Practica/1.png" alt="Captura 1"></p>
<p>Ahora vamos a realizar la misma operación de creación de los contenedores, pero mediante un script de <code>docker-compose</code>. Este es el procemiento que he seguido:</p>
<pre><code>nano docker-compose.yml

version: '3.1'

services:
  mariadb2:
    image: mariadb
    container_name: book_sql
    restart: always
    environment:
      [MYSQL_ROOT_PASSWORD=root,MYSQL_USER=book_user,MYSQL_PASSWORD=book_passwd,MYSQL_DATABASE=bookmedik]
    volumes:
      - ./mysql:/var/lib/mysql
  bookmedik:
    image: juanan219/book_debian
    container_name: book_debian
    restart: always
    ports:
      - 80:80
    volumes:
      - ./logs:/var/log/apache2

docker-compose run -d

cat schema.sql | docker exec -i book_sql /usr/bin/mysql -u book_user --password=book_passwd bookmedik
</code></pre><p>Ahora si nos metemos en la dirección de <code>loopback</code> (<code>127.0.0.1</code>) de nuestra máquina a través de un navegador nos aparecerá la aplicación de <code>Bookmedik</code></p>
<p><img src="/Docker/Practica/1.png" alt="Captura 1"></p>
<blockquote>
<p><a href="https://github.com/Juanan219/">Repositorio de GitHub</a></p>
</blockquote>
<h2 id="tarea-2">Tarea 2</h2>
<p>Ahora vamos a lanzar la aplicación de Bookmedik con una imagen docker de <code>PHP</code>, más concretamente, lo lanzaré con la imagen <code>php:7.4-apache</code>. Vamos a partir del ejercicio anterior, pero haciendo las modificaciones oportunas, las cuales ire enumerando mediante las hago:</p>
<ol>
<li>No usaremos el script <code>variables.sh</code>, ya que en la imagen docker de <code>php:7.4-apache</code> no podemos ejecutar ningún comando con <code>CMD</code>, por lo que eliminaremos el script del directorio <code>build_bookmedik</code> y modificaremos el fichero <code>Dockerfile</code></li>
</ol>
<pre><code>rm variables.sh

nano Dockerfile 

FROM php:7.4-apache
MAINTAINER Juan Antonio Reifs Ramirez &quot;initiategnat9@gmail.com&quot;

RUN apt-get update &amp;&amp; apt-get install -y git &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*
RUN git clone https://github.com/evilnapsis/bookmedik /var/www/html

EXPOSE 80

ENV DATABASE_SERVER=book_sql MYSQL_ROOT_PASSWORD=root MYSQL_USER=book_user MYSQL_PASSWORD=book_passwd MYSQL_DATABASE=bookmedik
</code></pre><ol start="2">
<li>Vamos a realizar otra modificación en el fichero <code>Dockerfile</code> para poder instalar el paquete <code>mysqli</code>, el cual nos va a hacer falta para usar la base de datos <code>mariadb</code> que esta aplicación necesita. Con esta imagen, las extensiones php se instalan de una forma un tanto especial, por lo que añadiremos la siguiente línea al dockerfile</li>
</ol>
<pre><code>nano Dockerfile
[...]
RUN docker-php-ext-install mysqli &amp;&amp; docker-php-ext-enable mysqli
[...]
</code></pre><ol start="3">
<li>Como ya no usamos el script para cambiar las variables, deberemos copiar el fichero <code>Database.php</code> del <a href="https://github.com/evilnapsis/bookmedik">repositorio de <code>bookmedik</code></a> y lo modificaremos para que php pueda reconocer las variables de entorno que nosotros definimos en el <code>Dockerfile</code></li>
</ol>
<pre><code>cp bookmedik/core/controller/Database.php Bookmedik-Tarea2/build_bookmedik/
nano Bookmedik-Tarea2/build_bookmedik/Database.php
[...]
$this-&gt;user=getenv(&quot;MYSQL_USER&quot;);$this-&gt;pass=getenv(&quot;MYSQL_PASSWORD&quot;);$this-&gt;host=getenv(&quot;DATABASE_SERVER&quot;);$this-&gt;ddbb=getenv(&quot;MYSQL_DATABASE&quot;);
[...]
</code></pre><ol start="4">
<li>Después de modificar el fichero <code>Database.php</code> vamos a modificar de nuevo el fichero <code>Dockerfile</code> para poder añadir un parámetro para poder agregar a nuestra imagen el fichero <code>Database.php</code> modificado y se sustituya por el original</li>
</ol>
<pre><code>nano Dockerfile
[...]
ADD Database.php /var/www/html/core/controller
[...]
</code></pre><p>El fichero <code>Dockerfile</code> deberá quedar de esta forma</p>
<pre><code>FROM php:7.4-apache
MAINTAINER Juan Antonio Reifs Ramirez &quot;initiategnat9@gmail.com&quot;

RUN apt-get update &amp;&amp; apt-get install -y git &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*
RUN git clone https://github.com/evilnapsis/bookmedik /var/www/html
RUN docker-php-ext-install mysqli &amp;&amp; docker-php-ext-enable mysqli

ADD Database.php /var/www/html/core/controller 

EXPOSE 80

ENV DATABASE_SERVER=book_sql MYSQL_ROOT_PASSWORD=root MYSQL_USER=book_user MYSQL_PASSWORD=book_passwd MYSQL_DATABASE=bookmedik
</code></pre><p>El fichero <code>Database.php</code> deberá quedar de esta forma</p>
<pre><code>&lt;?php
class Database {
        public static $db;
        public static $con;
        function Database(){
                $this-&gt;user=getenv(&quot;MYSQL_USER&quot;);$this-&gt;pass=getenv(&quot;MYSQL_PASSWORD&quot;);$this-&gt;host=getenv(&quot;DATABASE_SERVER&quot;);$this-&gt;ddbb=getenv(&quot;MYSQL_DATABASE&quot;);
        }

        function connect(){
                $con = new mysqli($this-&gt;host,$this-&gt;user,$this-&gt;pass,$this-&gt;ddbb);
                $con-&gt;query(&quot;set sql_mode=''&quot;);
                return $con;
        }

        public static function getCon(){
                if(self::$con==null &amp;&amp; self::$db==null){
                        self::$db = new Database();
                        self::$con = self::$db-&gt;connect();
                }
                return self::$con;
        }

}
?&gt;
</code></pre><p>Ahora procederemos a crear la imagen</p>
<pre><code>docker build -t juanan219/bookmedik .

docker images
REPOSITORY            TAG                 IMAGE ID            CREATED             SIZE
juanan219/bookmedik   latest              f9bd125bde93        12 seconds ago      457MB
[...]
</code></pre><p>Por último modificaremos el fichero <code>docker-compose.yml</code> para que lance tanto el contenedor de la imagen <code>mariadb</code> como el de la imagen que acabamos de crear</p>
<pre><code>version: '3.1'

services:
  mariadb:
    image: mariadb
    container_name: book_sql
    restart: always
    environment:
      [MYSQL_ROOT_PASSWORD=root,MYSQL_USER=book_user,MYSQL_PASSWORD=book_passwd,MYSQL_DATABASE=bookmedik]
    volumes:
      - ./mysql:/var/lib/mysql
  bookmedik:
    image: juanan219/bookmedik
    container_name: book_php   
    restart: always
    ports:
      - 80:80
    volumes:
      - ./logs:/var/log/apache2
</code></pre><p>Lanzamos el <code>docker-compose</code> y comprobamos si funciona nuestra aplicación</p>
<pre><code>docker-compose up -d
Creating network &quot;bookmedik-tarea2_default&quot; with the default driver
Creating book_php ... done
Creating book_sql ... done
</code></pre><p>Como podemos ver, si accedemos desde nuestra máquina anfitriona a la dirección de <code>loopback</code> (<code>127.0.0.1</code>) e introducimos el usuario y la contraseña <code>admin/admin</code> podemos acceder a nuestro <code>bookmedik</code> sobre una imagen docker <code>php:7.4-apache</code></p>
<p><img src="/Docker/Practica/2.png" alt="Captura 2"></p>
<blockquote>
<p><a href="https://github.com/Juanan219/Bookmedik-Tarea2">Repositorio de GitHub</a></p>
</blockquote>
<h3 id="tarea-3">Tarea 3</h3>
<p>Ahora vamos a usar tres contenedores diferentes para separar servicios:</p>
<ul>
<li>
<p>El primero va a tener una imagen <code>nginx</code>, el cual va a servir el contenido estático.</p>
</li>
<li>
<p>El segundo va a tener una imagen <code>php:7.4-fpm</code>, el cual se va a encargar de gestionar todo el contenido php</p>
</li>
<li>
<p>El tercero va a tener una imagen <code>mariadb</code>, el cual se va a encargar de almacenar la base de datos de nuestro <code>bookmedik</code></p>
</li>
</ul>
<ol>
<li>Vamos a crear nuestra imagen de <code>php:7.4-fpm</code> con el módulo de <code>mysqli</code> activado, ya que sino no podemos acceder a la base de datos. Para crear esta imagen he creado un directorio que contiene el siguiente fichero <code>Dockerfile</code>:</li>
</ol>
<pre><code>mkdir build_php
nano build_php/Dockerfile

FROM php:7.4-fpm

MAINTAINER Juan Antonio Reifs Ramirez &quot;initiategnat9@gmail.com&quot;

RUN docker-php-ext-install mysqli &amp;&amp; docker-php-ext-enable mysqli

ENV DATABASE_SERVER=book_sql MYSQL_ROOT_PASSWORD=root MYSQL_USER=book_user MYSQL_PASSWORD=book_passwd MYSQL_DATABASE=bookmedik
</code></pre><ol start="2">
<li>Creamos la imagen</li>
</ol>
<pre><code>docker build -t juanan219/php_mysqli

docker images
REPOSITORY             TAG                 IMAGE ID            CREATED             SIZE
juanan219/php_mysqli   latest              2725316da685        18 minutes ago      405MB
</code></pre><ol start="3">
<li>Creamos un fichero llamado <code>default.conf</code> que va a servir para que <code>nginx</code> sirva nuestra aplicación</li>
</ol>
<pre><code>nano default.conf

server {
    index index.html;
    server_name bookmedik.local;
    error_log  /var/log/nginx/error.log;
    access_log /var/log/nginx/access.log;
    root /bookmedik;

    location ~ \.php$ {
        try_files $uri =404;
        fastcgi_split_path_info ^(.+\.php)(/.+)$;
        fastcgi_pass book_php:9000;
        fastcgi_index index.php;
        include fastcgi_params;
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
        fastcgi_param PATH_INFO $fastcgi_path_info;
    }
}
</code></pre><ol start="4">
<li>Copiamos un directorio de <code>bookmedik</code> con el archivo <code>bookmedik/core/controller/Database.php</code> editado (como vimos en la práctica anterior) y generamos el siguiente docker-compose.yml</li>
</ol>
<pre><code>nano docker-compose.yml

version: '3.1'

services:
  nginx:
    image: nginx
    container_name: book_nginx
    volumes:
      - ./logs:/var/log/nginx
      - ./bookmedik:/bookmedik
      - ./default.conf:/etc/nginx/conf.d/default.conf
    ports:
      - 80:80
    restart: always
    environment:
      - DATABASE_SERVER=book_sql
      - MYSQL_ROOT_PASSWORD=root
      - MYSQL_USER=book_user
      - MYSQL_PASSWORD=book_passwd
      - MYSQL_DATABASE=bookmedik

  php-fpm:
    image: juanan219/php_mysqli
    container_name: book_php
    volumes:
      - ./bookmedik:/bookmedik
    restart: always

  mysql:
    image: mariadb
    container_name: book_sql
    volumes:
      - ./mysql:/var/lib/mysql
      - ./bookmedik/schema.sql:/opt/schema.sql
    environment:
      - MYSQL_ROOT_PASSWORD=root
      - MYSQL_USER=book_user
      - MYSQL_PASSWORD=book_passwd
      - MYSQL_DATABASE=bookmedik
    restart: always
</code></pre><ol start="5">
<li>Iniciamos el script y comprobamos que podemos entrar</li>
</ol>
<pre><code>docker-compose up -d
</code></pre><p><img src="/Docker/Practica/3.png" alt="Captura 3"></p>
<blockquote>
<p><a href="https://github.com/Juanan219/Bookmedik-Tarea3">Repositorio de GitHub</a></p>
</blockquote>
<h4 id="tarea-5">Tarea 5</h4>
<p>Por último vamos a instalar un CMS de PHP con una imagen en DockerHub creando los contenedores necesarios para instalarla. En mi caso he escogido <code>joomla</code>. He hecho un script de <code>docker-compose</code> para ejecutar los dos contenedores que necesita joomla, uno de ellos es una imagen <code>mariadb</code> y la otra es una imagen <code>joomla</code></p>
<pre><code>nano docker-compose.yml

version: '3.1'

services:
  mariadb:
    image: mariadb
    container_name: joomla_sql
    restart: always
    environment:
      - MYSQL_ROOT_PASSWORD=root
      - MYSQL_USER=joomla_user
      - MYSQL_PASSWORD=joomla_passwd
      - MYSQL_DATABASE=joomla_db
  joomla:
    image: joomla
    container_name: joomla
    restart: always
    ports:
      - 80:80
    environment:
      - JOOMLA_DB_HOST=joomla_sql
      - JOOMLA_DB_USER=joomla_user
      - JOOMLA_DB_PASSWORD=joomla_passwd
      - JOOMLA_DB_NAME=joomla_db
</code></pre><p>Ahora simplemente hacemos un <code>docker-compose up -d</code> y se crean los dos contenedores</p>
<pre><code>docker-compose up -d
Creating network &quot;cms-php-tarea5_default&quot; with the default driver
Creating joomla     ... done
Creating joomla_sql ... done
</code></pre><p>Comprobamos que podemos entrar</p>
<p><img src="/Docker/Practica/4.png" alt="Captura 4"></p>
<p>Una vez que hayamos terminado la configuración del sitio nos podemos meter en la página de administración (iniciando sesión con el usuario que hemos configurado)</p>
<p><img src="/Docker/Practica/5.png" alt="Captura 5"></p>
<p>Esta es la página de ejemplo de Joomla</p>
<p><img src="/Docker/Practica/6.png" alt="Captura 6"></p>
<blockquote>
<p><a href="https://github.com/Juanan219/CMS-PHP-Tarea5">Repositorio de GitHub</a></p>
</blockquote>
]]></content>
        </item>
        
        <item>
            <title>Creación de Imagenes Docker</title>
            <link>https://juanan219.github.io/posts/2021/02/creaci%C3%B3n-de-imagenes-docker/</link>
            <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/02/creaci%C3%B3n-de-imagenes-docker/</guid>
            <description>Hasta ahora hemos usado imágenes de Docker que han hecho otras personas, pero para crear un contenedor que sirva nuestra aplicación, deberemos crear una imagen personalidada. A esto es a lo que llamamos dockerizar una aplicación.
Creación de una imagen a partir de un contenedor La primera forma de crear nuestras propias imágenes personalizadas es crearlas a partir de un contenedor que ya está en ejecución. Para ello tenemos varias posibilidades:</description>
            <content type="html"><![CDATA[<p>Hasta ahora hemos usado imágenes de Docker que han hecho otras personas, pero para crear un contenedor que sirva nuestra aplicación, deberemos crear una imagen personalidada. A esto es a lo que llamamos <em>dockerizar</em> una aplicación.</p>
<p><img src="/Docker/Documentacion/19.png" alt="Captura 19"></p>
<h2 id="creación-de-una-imagen-a-partir-de-un-contenedor">Creación de una imagen a partir de un contenedor</h2>
<p>La primera forma de crear nuestras propias imágenes personalizadas es <strong>crearlas a partir de un contenedor</strong> que ya está en ejecución. Para ello tenemos varias posibilidades:</p>
<ol>
<li>
<p>Usar la secuencia de órdenes <code>docker commit</code> / <code>docker save</code> / <code>docker load</code>. En este caso, la distribución se producirá a partir de un fichero.</p>
</li>
<li>
<p>Utilizar la pareja de órdenes <code>docker commit</code> / <code>docker push</code>. En este caso, la distribución se producirá a partir de <strong>DockerHub</strong></p>
</li>
<li>
<p>Utilizar la pareja de órdenes <code>docker export</code> / <code>docker import</code>. En este caso, la distribución se producirá a partir de un fichero.</p>
</li>
</ol>
<p>Nosotros veremos las dos primeras formas de crear una imagen a partir de un contenedor, ya que la tercera forma se limita a copiar el sistema de archivos sin tener en cuenta la información de las imágenes de las que deriva el contenedor y, además, si tenemos algún volumen montado, esta opción lo obviará.</p>
<h3 id="distribución-a-partir-de-un-fichero">Distribución a partir de un fichero</h3>
<ol>
<li>Arranca un contenedor a partir de una imagen base</li>
</ol>
<pre><code>docker run -it --name docker_debian debian bash
</code></pre><ol start="2">
<li>Realiza modificaciones en el contenedor</li>
</ol>
<pre><code>root@b3bcf59aefc2:/# apt-get update &amp;&amp; apt-get install -y apache2
</code></pre><ol start="3">
<li>Crear una nueva imagen partiendo de ese contenedor usando <code>docker commit</code>. Con esta instrucción se creará una nueva imagen con las capas de la imagen base mas la capa propia del contenedor. Al creala no voy a poner etiqueta, por lo que será latest.</li>
</ol>
<pre><code>docker commit docker_debian juanan219/debian_prueba
sha256:fc7791340642d790bf921715c445c20b5ddfc6863d7e47ba98d7a1c73d462d1c

docker images
REPOSITORY                    TAG                 IMAGE ID            CREATED             SIZE
juanan219/debian_prueba       latest              fc7791340642        14 seconds ago      243MB
[...]
</code></pre><ol start="4">
<li>Guardar esa imagen en un archivo <code>.tar</code> usando el comando <code>docker save</code>:</li>
</ol>
<pre><code>docker save juanan219/debian_prueba &gt; debian_prueba.tar

ls
debian_prueba.tar
</code></pre><ol start="5">
<li>
<p>Distribuir el archivo <code>.tar</code></p>
</li>
<li>
<p>Si me llega un fichero <code>.tar</code> puedo añadir la imagen a mi repositorio local</p>
</li>
</ol>
<pre><code>docker rmi juanan219/debian_prueba
Untagged: juanan219/debian_prueba:latest
Deleted: sha256:fc7791340642d790bf921715c445c20b5ddfc6863d7e47ba98d7a1c73d462d1c
Deleted: sha256:ffc144c3004d5f83465eb03998204ca52530598d6388c65367484e33523991fd

docker load -i debian_prueba.tar 
b124061f7913: Loading layer [==================================================&gt;]  132.4MB/132.4MB
Loaded image: juanan219/debian_prueba:latest
</code></pre><h3 id="distribución-usando-dockerhub">Distribución usando DockerHub</h3>
<ol>
<li>Arranca un contenedor a partir de una imagen base</li>
</ol>
<pre><code>docker run -it --name debian_prueba debian bash
</code></pre><ol start="2">
<li>Realiza modificaciones en el contenedor</li>
</ol>
<pre><code>root@b3bcf59aefc2:/# apt-get update &amp;&amp; apt-get install -y apache2
</code></pre><ol start="3">
<li>Crear una nueva imagen partiendo de ese contenedor usando <code>docker commit</code>. Con esta instrucción se creará una nueva imagen con las capas de la imagen base mas la capa propia del contenedor. Al creala no voy a poner etiqueta, por lo que será latest.</li>
</ol>
<pre><code>docker commit debian_prueba juanan219/debian_prueba
sha256:fc7791340642d790bf921715c445c20b5ddfc6863d7e47ba98d7a1c73d462d1c

docker images
REPOSITORY                    TAG                 IMAGE ID            CREATED             SIZE
juanan219/debian_prueba       latest              fc7791340642        28 seconds ago      243MB
[...]
</code></pre><ol start="4">
<li>Autentificarme en Docker Hub usando el comando <code>docker login</code>.</li>
</ol>
<pre><code>docker login
Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.
Username: juanan219
Password: 
Login Succeeded
</code></pre><ol start="5">
<li>Distribuir ese fichero subiendo la nueva imagen a DockerHub mediante <code>docker push</code>.</li>
</ol>
<pre><code>docker push juanan219/debian_prueba
The push refers to repository [docker.io/juanan219/debian_prueba]
fd7d86e14e9c: Pushed 
7f03bfe4d6dc: Mounted from jenkins/jenkins 
latest: digest: sha256:29ca12fb2ecadeff4625d4cbea5a3aba92782f8b0702329e8b90134f3bde832d size: 741
</code></pre><p>Después de realizar esto, cualquier puede descargarse nuestra imagen tanto utilizándola como usando el comando <code>docker pull</code>.</p>
<h2 id="creación-de-imágenes-con-fichero-dockerfile">Creación de imágenes con fichero dockerfile</h2>
<p>Crear imágenes a partir de contenedores ya creados tiene dos inconvenientes.</p>
<ul>
<li>
<p><strong>No se puede reproducir la imagen</strong>, es decir, que si la perdemos tenemos que recordar toda la secuencia de órdenes que habíamos realizado desde que arrancamos el contenedor hasta que teníamos una versión definitiva e hicimos el <code>docker commit</code></p>
</li>
<li>
<p><strong>No podemos cambiar la imagen de base</strong>, es decir, que si ha habido alguna actualización, problemas de seguridad o algo por el estilo con la imagen base, tenemos que descargar la nueva versión, volver a crear un nuevo contenedor basado en ella y volver a ejecutar de nuevo toda la secuencia de órdenes.</p>
</li>
</ul>
<p>Por estos dos problemas, el método preferido para crear imágenes es el uso del llamado <code>dockerfile</code> y el comando <code>docker build</code>. Estos son los pasos fundamentales:</p>
<ol>
<li>
<p>Crear el fichero <code>dockerfile</code>.</p>
</li>
<li>
<p>Construir la imagen usando la definición guardada en el fichero <code>dockerfile</code> y el comando <code>docker build</code>.</p>
</li>
<li>
<p>Autentificarme en DockerHub usando el comando <code>docker login</code>.</p>
</li>
<li>
<p>Distribuir ese fichero subiendo la nueva imagen a DockerHub mediante el comando <code>docker push</code>.</p>
</li>
</ol>
<p>Con este método podemos tener ciertas ventajas:</p>
<ul>
<li>
<p><strong>Reproducir la imagen fácilmente</strong> ya que en el fichero <code>dockerfile</code> tenemos todas las instrucciones necesarias para la construcción de la imagen. Si además tenemos el <code>dockerfile</code> en un repositorio con control de versiones como <code>git</code>, podemos además asociar los cambios en el <code>dockerfile</code> a los cambios de versiones de las imágenes creadas.</p>
</li>
<li>
<p>Si queremos cambiar la imagen de base, esto es muy sencillo con el fichero <code>dockerfile</code>, ya que simplemente deberemos modificar la primera línea del fichero, como explicaremos posteriormente.</p>
</li>
</ul>
<h3 id="el-fichero-dockerfile">El fichero Dockerfile</h3>
<p>El fichero <code>dockerfile</code> es un conjunto de instrucciones que se irán ejecutando secuencialmente para construir una nueva imagen Docker. Cada una de las instrucciones que ejecutemos, creará una nueva capa en la imagen que estamos creando.</p>
<p>Hay varias instrucciones que podemos usar en la construcción de un <code>dockerfile</code>, pero la estructura fundamental de este fichero es:</p>
<ul>
<li>
<p><strong><code>FROM</code>:</strong> Aquí indicamos la imagen base</p>
</li>
<li>
<p><strong><code>MANTEINER, LABEL</code>:</strong> Metadatos</p>
</li>
<li>
<p><strong><code>RUN, COPY, ADD, WORKDIR</code>:</strong> Instrucciones de construcción</p>
</li>
<li>
<p><strong><code>USER, EXPOSE, ENV</code>:</strong> Configuración (Variables de entorno, usuarios, puertos)</p>
</li>
<li>
<p><strong><code>CMD, ENTRYPOINT</code>:</strong> Instrucciones de arranque</p>
</li>
</ul>
<p>Vamos a ver las principales instrucciones que podemos usar:</p>
<ul>
<li><strong><code>FROM</code>:</strong> Sirve para especificar la imagen sobre la que voy a construir la mía.</li>
</ul>
<pre><code>FROM: php:7.4-apache
</code></pre><ul>
<li><strong><code>LABEL</code>:</strong> Sirve para añadir metadatos a la imagen clave.</li>
</ul>
<pre><code>LABEL company=iesgn
</code></pre><ul>
<li><strong><code>COPY</code>:</strong> Sirve para copiar fichero desde mi equipo hacia la imagen. Esos ficheros deben de estar en la misma carpeta o repositorio. La sintáxis de <code>COPY</code> es:</li>
</ul>
<pre><code>COPY [--chown=&lt;usuario&gt;:&lt;grupo&gt;] src dest
</code></pre><pre><code>* Ejemplo de `COPY`:
</code></pre>
<pre><code>COPY --chown=www-data:www-data wordpress/wp /var/www/html
</code></pre><ul>
<li>
<p><strong><code>ADD</code>:</strong> Es similar a <code>COPY</code> pero tiene funcionalidades adicionales, como especificar URLs y tratar archivos comprimidos.</p>
</li>
<li>
<p><strong><code>RUN</code>:</strong> Ejecuta una orden creando una nueva capa. La sintáxis de <code>RUN</code> es:</p>
</li>
</ul>
<pre><code>RUN orden

RUN [&quot;orden&quot;,&quot;parámetro 1&quot;, &quot;parámetro 2&quot;]
</code></pre><pre><code>* Ejemplo de `RUN`:
</code></pre>
<pre><code>RUN apt-get update &amp;&amp; apt-get install -y git
</code></pre><blockquote>
<p>En este caso, es muy importante ejecutar el comando de instalación de <code>git</code> con la opción <code>-y</code>, ya que en el proceso de creación de la imagen con el <code>dockerfile</code> no puede haber interacción con el usuario.</p>
</blockquote>
<ul>
<li><strong><code>WORKDIR</code>:</strong> Establece el directorio de trabajo dentro de la imagen que estoy creando, para posteriormente usar las órdenes <code>RUN</code>, <code>COPY</code>, <code>ADD</code>, <code>CMD</code> o <code>ENTRYPOINT</code>.</li>
</ul>
<pre><code>WORKDIR /usr/local/apache/htdocs
</code></pre><ul>
<li><strong><code>EXPOSE</code>:</strong> Nos da información sobre qué puertos tendrá abiertos el contenedor cuando se cree uno en base a la imagen que estamos creando. Es meramente informativo.</li>
</ul>
<pre><code>EXPOSE 80
</code></pre><ul>
<li><strong><code>USER</code>:</strong> Para especificar meidante nombre o <code>UID</code>/<code>GID</code> el usuario de trabajo para todas las órdenes <code>RUN</code>, <code>CMD</code> y <code>ENTRYPOINT</code> posteriores.</li>
</ul>
<pre><code>USER jenkins

USER 10001:10001
</code></pre><ul>
<li><strong><code>ARG</code>:</strong> Define variables para las cuales los usuarios pueden especificar valores a la hora de hacer el proceso de <code>build</code> mediante la opción <code>--build-arg</code>. Su sintáxis es:</li>
</ul>
<pre><code>ARG nombre_variable

ARG nombre_variable=valor_por_defecto
</code></pre><pre><code>* Ejemplo de `ARG`:
</code></pre>
<pre><code>ARG usuario=www-data
</code></pre><blockquote>
<p>No se puede usar ni en <code>ENTRYPOINT</code> ni en <code>CMD</code></p>
</blockquote>
<ul>
<li><strong><code>ENV</code>:</strong> Para establecer variables de entorno dentro del contenedor. Puede ser usado posteriormente en las opciones <code>RUN</code> añadiendo <code>$</code> delante del nombre de la variable de entorno.</li>
</ul>
<pre><code>ENV WEB_DOCUMENT_ROOT=/var/www/html
</code></pre><blockquote>
<p>No se puede usar ni en <code>ENTRYPOINT</code> ni en <code>CMD</code></p>
</blockquote>
<ul>
<li><strong><code>ENTRYPOINT</code>:</strong> sirve para establecer el ejecutable que se lanza siempre que se crea un contenedor con <code>docker run</code>, salvo que se especifique algo con la opción <code>--entrypoint</code>. La sintáxis de <code>ENTRYPOINT</code> es:</li>
</ul>
<pre><code>ENTRYPOINT &lt;comando&gt;

ENTRYPOINT [&quot;ejecutable&quot;, &quot;parámetro 1&quot;, &quot;parámetro 2&quot;]
</code></pre><pre><code>* Ejemplo de `ENTRYPOINT`:
</code></pre>
<pre><code>ENTRYPOINT [&quot;/usr/sbin/apache2ctl&quot;, &quot;-D&quot;, &quot;FOREGROUND&quot;]
</code></pre><ul>
<li><strong><code>CMD</code>:</strong> Sirve para establecer un ejecutable por defecto (salvo que se sobreescriba desde la orden <code>docker run</code>) o para especificar parámetros para un <code>ENTRYPOINT</code>. Si tengo varios, sólo se ejecuta el último. La sintáxis de <code>CMD</code> es:</li>
</ul>
<pre><code>CMD parámetro1 parámetro2

CMD [&quot;parámetro 1&quot;,&quot;parámetro 2&quot;]

CMD [&quot;comando&quot;,&quot;parámetro 1&quot;]
</code></pre><pre><code>* Ejemplo de `CMD`:
</code></pre>
<pre><code>CMD [&quot;-c&quot;,&quot;/etc/nginx.conf&quot;]

ENTRYPOINT [&quot;nginx&quot;]
</code></pre><ul>
<li>
<p><strong>Ejemplo:</strong></p>
<ul>
<li>Si tenemos un fichero <code>dockerfile</code> que tiene las siguientes instrucciones</li>
</ul>
</li>
</ul>
<pre><code>ENTRYPOINT [&quot;http&quot;, &quot;-v&quot;]

CMD [&quot;-p&quot;, &quot;80&quot;]
</code></pre><pre><code>* Podemos crear un contenedor a partir de la imagen generada:

    * `docker run centos:centos7`: Se creará un contenedor con el servidor web escuchando en el puerto `80`.

    * `docker run centos:centos7 -p 8080`: Se creará un contenedor con el servidor web escuchando en el puerto `8080`
</code></pre>
<h3 id="construyendo-imágenes-con-docker-build">Construyendo imágenes con docker build</h3>
<p>El comando <code>docker build</code> construye las imágenes leyendo las instrucciones del <code>dockerfile</code> y la información de un entorno, que para nosotros va a ser un directorio (aunque también podemos gestionar la información de un repositorio <code>git</code>).</p>
<p>A la hora de crear una imagen, tenemos que tener en cuenta que cada vez que se ejecuta una instrucción se genera una imagen intermedia. Algunas imágenes intermedias se guardan en caché, otras se borran. Por lo tanto, si ejecutamos en una línea el comando <code>cd scripts/</code> y en otra línea ejecutamos <code>./install.sh</code>, no va a funcionar, ya que se ha lanzado otra imágen intermedia. Teniendo esto en cuenta, la manera correcta de ejecutar esto sería:</p>
<pre><code>cd scripts/;./install.sh
</code></pre><p>Al generar las imágenes con <code>dockerfile</code>, como hemos dicho anteriormente, las imágenes se guardan temporalmente en caché, esto quiere decir que si en el proceso de creación de la imagen ha fallado algún paso, al corregirlo y volver a intentarlo, los pasos que han salido bien no se vuelven a repetir, ya que esas imágenes intermedias están almacenadas en la caché.</p>
<h3 id="ejemplo-de-dockerfile">Ejemplo de Dockerfile</h3>
<p>Vamos a crear un directorio (el cual va a ser nuestro entorno de creación de la imagen) donde vamos a crear un <code>dockerfile</code> y un fichero <code>index.html</code>.</p>
<pre><code>mkdir pruebas_docker
cd pruebas_docker/

echo &quot;&lt;h1&gt;Esto es una prueba de Dockerfile&lt;/h1&gt;&quot; &gt; index.html

nano Dockerfile

FROM debian 
MAINTAINER Juan Antonio Reifs Ramirez &quot;initiategnat9@gmail.com&quot;
RUN apt update  &amp;&amp; apt install -y  apache2 
COPY index.html /var/www/html/index.html
ENTRYPOINT [&quot;/usr/sbin/apache2ctl&quot;, &quot;-D&quot;, &quot;FOREGROUND&quot;]

ls
Dockerfile  index.html
</code></pre><p>Cuando tenemos creado y escritas las instrucciones en nuestro fichero <code>Dockerfile</code> y nuestro <code>index.html</code> creado vamos a generar la imagen con <code>docker build</code> indicando el nombre de la nueva imagen con la opción <code>-t</code> e indicando el directorio de contexto.</p>
<pre><code>docker build -t juanan219/prueba_dockerfile .
</code></pre><p>Cuando haya terminado el proceso de generación de nuestra primera imagen, podemos verla en nuestro repositorio local</p>
<pre><code>docker images
REPOSITORY                    TAG                 IMAGE ID            CREATED             SIZE
juanan219/prueba_dockerfile   latest              67196e6920a2        53 seconds ago      243MB
[...]
</code></pre><p>Después de realizar esto, ya podemos usar la imágen como otra cualquier, a parte de poder distribuirla.</p>
<blockquote>
<p>Si usamos la opción <code>--no-cache</code> en el comando <code>docker-build</code> haríamos la construcción de la imagen sin usar las capas cacheadas.</p>
</blockquote>
<h3 id="buenas-prácticas-al-crear-un-dockerfile">Buenas prácticas al crear un Dockerfile</h3>
<ul>
<li>
<p><strong>Los contenedores deben ser efímeros:</strong> esto quiere decir que los contenedores que se creen con nuestra imagen deben tener una mímina configuración.</p>
</li>
<li>
<p><strong>Uso de ficheros <code>.dockerignore</code>:</strong> Como hemos dicho anteriormente, todos los ficheros del contexto se envían al <code>docker engine</code>, por ello es recomendable usar un directorio/repositorio vacío en el cual vamos creando los fichero que vamos a ir necesitando. Además, para aumentar el rendimiento y evitar enviar ficheros innecesarios al daemon podemos usar un fichero <code>.dockerignore</code> para excluir ficheros y directorios.</p>
</li>
<li>
<p><strong>No instalar paquetes innecesarios:</strong> Para reducir la complejidad, dependencias, tiempo de creación y tamaño de la imagen resultante, se debe evitar instalar pequetes extras o innecesarios. Si necesitamos algún paquete durante la creación de la imagen, lomejor es desinstalarlo durante el proceso.</p>
</li>
<li>
<p><strong>Minimizar el número de capas:</strong> Debemos encontrar el balance entre la legibilidad del <code>Dockerfile</code> y minimizar el número de capas que utiliza.</p>
</li>
<li>
<p><strong>Indicar las instrucciones a ejecutar múltiples tareas:</strong> Hay que organizar los argumentos de las instrucciones que contengan múltiples línes para facilitar futuros cambios. Esto evitará la duplicación de paquetes y hará que el archivo sea más fácil de leer. Por ejemplo:</p>
</li>
</ul>
<pre><code>RUN apt-get update &amp;&amp; apt-get install -y \
git \
wget \
apache2 \
php5
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Almacenamiento en Docker</title>
            <link>https://juanan219.github.io/posts/2021/02/almacenamiento-en-docker/</link>
            <pubDate>Tue, 23 Feb 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/02/almacenamiento-en-docker/</guid>
            <description>Los contenedores son efímeros Los contenedores de docker son efímeros, es decir, todo lo que generamos dentro de un contenedor resisten a las paradas de los contenedores, pero cuando eliminamos un contenedor, todo lo que hay en su interior se elimina con él. Veamos esto creando un contenedor y creando dentro de él un fichero, cuando lo eliminemos, crearemos otro contenedor para comprobar si ese archivo está
docker run --name docker_nginx -p 8080:80 -d nginx c45464659bca8dc80372f7fcbcf1fa8e2abdb7f3d68dd7eb46a22ef6d5cf824f docker exec docker_nginx bash -c &#39;echo &amp;quot;&amp;lt;h1&amp;gt;Esto es una prueba&amp;lt;/h1&amp;gt;&amp;quot; &amp;gt; /usr/share/nginx/html/index.</description>
            <content type="html"><![CDATA[<h2 id="los-contenedores-son-efímeros">Los contenedores son efímeros</h2>
<p>Los contenedores de docker <strong>son efímeros</strong>, es decir, todo lo que generamos dentro de un contenedor resisten a las paradas de los contenedores, pero cuando eliminamos un contenedor, todo lo que hay en su interior se elimina con él. Veamos esto creando un contenedor y creando dentro de él un fichero, cuando lo eliminemos, crearemos otro contenedor para comprobar si ese archivo está</p>
<pre><code>docker run --name docker_nginx -p 8080:80 -d nginx
c45464659bca8dc80372f7fcbcf1fa8e2abdb7f3d68dd7eb46a22ef6d5cf824f

docker exec docker_nginx bash -c 'echo &quot;&lt;h1&gt;Esto es una prueba&lt;/h1&gt;&quot; &gt; /usr/share/nginx/html/index.html'

curl 127.0.0.1:8080
&lt;h1&gt;Esto es una prueba&lt;/h1&gt;

docker rm -f docker_nginx
docker_nginx

docker run --name docker_nginx -p 8080:80 -d nginx
9168378ab8621adea4936a49d556ba999c8b54d29eeaf99f1eabc6d5a2c7553c

curl 127.0.0.1:8080
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
&lt;style&gt;
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
&lt;p&gt;If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.&lt;/p&gt;

&lt;p&gt;For online documentation and support please refer to
&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;
Commercial support is available at
&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre><p>Como podemos ver, el fichero que habíamos creado anteriormente como <code>index.html</code> ha desaparecido y se ha sustituido por el fichero <code>index.html</code> predeterminado de <code>nginx</code>, esto quiere decir qu enuestro ficher se ha eliminado junto con el contenedor.</p>
<ul>
<li><strong>Explicación:</strong> El comando que hemos usado para introducir el fichero contiene la opción <code>bash -c</code>, la cual nos permite ejecutar varias instrucciones de bash de forma más compleja (por ejemplo indicando ficheros dentro del sistema).</li>
</ul>
<h2 id="los-datos-de-los-contenedores">Los datos de los contenedores</h2>
<p>Ante la anterior situación, Docker nos proporciona varias formas de resolver este problema. Ahora veremos las dos soluciones más importantes, que son:</p>
<ul>
<li>
<p><strong>Volúmenes Docker:</strong> Si elegimos resolver el problema anterior usando <strong>volúmenes docker</strong> quiere decir que vamos a guardar nuestros datos en una parte del sistema la cual es gestionada por Docker y a la que debido a sus permisos, sólo Docker tendrá acceso. Se guardan en <code>/var/lib/docker/volumes</code>. Esta solución se suele usar en los siguientes casos:</p>
<ul>
<li>
<p>Para compartir datos entre contenedores, ya que simplemente deberán usar el mismo volúmen.</p>
</li>
<li>
<p>Para copias de seguridad.</p>
</li>
<li>
<p>Cuando queremos almacenar los datos de nuestros contenedores en un servidor cloud.</p>
</li>
</ul>
</li>
<li>
<p><strong>Bind Mount:</strong> Al usar esta solución, lo que estamos haciendo es <em>mapear</em> (o montar) una parte de mi sistema de ficheros (de la que normalmente tenemos el control) con una parte del sistema de ficheros del contenedor. De esta forma conseguimos:</p>
<ul>
<li>
<p>Compartir ficheros entre el <em>anfitrión</em> y el <em>contenedor</em></p>
</li>
<li>
<p>Que otras aplicaciones que no sean docker tengan acceso a esos ficheros, ya sean código, ficheros, etc&hellip;</p>
</li>
</ul>
</li>
</ul>
<h2 id="gestionando-volúmenes">Gestionando volúmenes</h2>
<p>Algunos de los comandos más útiles para trabajas con volúmenes docker son:</p>
<ul>
<li>
<p><strong><code>docker volume create</code>:</strong> Crea un volumen con el nombre indicado.</p>
</li>
<li>
<p><strong><code>docker volume rm</code>:</strong> Elimina el volumen indicado.</p>
</li>
<li>
<p><strong><code>docker volume prune</code>:</strong> Elimina los volúmenes que no están siendo usados por ningún contenedor</p>
</li>
<li>
<p><strong><code>docker volume ls</code>:</strong> Lista los volúmenes y proporciona algo de información adicional.</p>
</li>
<li>
<p><strong><code>docker volume inspect</code>:</strong> También lista los volúmenes pero de forma mucho más detallada que <code>volume ls</code>.</p>
</li>
</ul>
<h2 id="asociando-almacenamiento-a-los-contenedores">Asociando almacenamiento a los contenedores</h2>
<p>Para usar tanto los <strong>volúemenes docker</strong> como los <strong>bind mount</strong> necesitaremos usar dos <em>flags</em> (u opciones) para usar cualquiera de los dos métodos de almacenamiento:</p>
<ul>
<li>
<p><code>--volume</code> o <code>-v</code></p>
</li>
<li>
<p><code>--mount</code></p>
</li>
</ul>
<p>Es importante que tengamos en cuenta dos cosas importantes para realizar estas dos operaciones:</p>
<ul>
<li>
<p>Si existe el directorio donde vamos a montar tanto los <strong>volúmenes docker</strong> como los <strong>bind mount</strong>, este se sobreescribirá, por lo que toda la información de dicho directorio (repito, si existe) se eliminará.</p>
</li>
<li>
<p>Si nuestra carpeta donde hemos indicado el montaje no existe y hacemos un <strong>bind mount</strong> esta carpeta se creará y tendremos un directorio vacío como almacenamiento.</p>
</li>
<li>
<p>Si usamos imágenes de DockerHub, debemos prestar atención ala información de su página, ya que ahí nos dice cómo persistir los datos de dicha imagen.</p>
</li>
</ul>
<h2 id="ejemplo-usando-volúmenes-docker">Ejemplo usando Volúmenes Docker</h2>
<pre><code>docker volume create prueba
prueba

docker run --name docker_nginx --mount type=volume,src=prueba,dst=/usr/share/nginx/html/ -p 8080:80 -d nginx
c0b5f88eb32bcb96b0285b345d41e77d01f42a768ec09484cf4d1f2f0b79a3d0

docker exec docker_nginx bash -c 'echo &quot;&lt;h1&gt;Esto es una prueba de almacenamiento&lt;/h1&gt;&quot; &gt; /usr/share/nginx/html/index.html'

curl 127.0.0.1:8080
&lt;h1&gt;Esto es una prueba de almacenamiento&lt;/h1&gt;

docker rm -f docker_nginx
docker_nginx

docker run --name docker_nginx2 -v prueba:/usr/share/nginx/html/ -p 8080:80 -d nginx
bfff1f83504544106dd916db40ca4e566e508ca9bb95b387d7efe9422660176d

curl 127.0.0.1:8080
&lt;h1&gt;Esto es una prueba de almacenamiento&lt;/h1&gt;
</code></pre><p>Como podemos ver arriba, hemos creado un volumen llamado <code>prueba</code>, después hemos creado un contenedor y hemos montado el volumen que hemos creado en la ruta <code>/usr/share/nginx/html/</code>, la cual es la que usa <code>nginx</code> por defecto para servir su página de ejemplo, hemos usado el comando <code>exec</code> de docker y hemos sustituido el fichero <code>inde.html</code> predeterminado por uno modificado por mí, para después eliminar el contenedor y crear uno nuevo con el volumen <code>prueba</code> ya montado y como podemos ver, la información del fichero <code>index.html</code> modificado la seguimos teniendo.</p>
<p>Si ubiesemos usado la opción <code>--mount</code> de esta forma <code>--mount type=volume,dst=/usr/share/nginx/html/</code> se hubiese creado un nuevo volumen, ya que no hemos indicado ninguno que pueda usar.</p>
<p>Si usamos la opción <code>-v</code> e indicamos un nombre, se creará un nuevo volumen docker</p>
<pre><code>docker run --name docker_nginx2 -v prueba2:/usr/share/nginx/html/ -p 8080:80 -d nginx
bab32cc75f4f2fea0fa51c4b4244cc942ea90e0220c7a5f105276b4be3c7ebd8

docker volume ls
DRIVER              VOLUME NAME
local               prueba
local               prueba2
</code></pre><h2 id="ejemplo-usando-bind-mount">Ejemplo usando bind mount</h2>
<p>En este caso vamos a crear un dicrectorio en el sistema de archivos del anfitrión y dentro de dicho directorio vamos a crear un archivo <code>index.html</code></p>
<pre><code>mkdir prueba

echo &quot;&lt;h1&gt;Esto es una prueba de bind mount&lt;/h1&gt;&quot; &gt; prueba/index.html

docker run --name docker_nginx -v /home/juanan/prueba:/usr/share/nginx/html/ -p 8080:80 -d nginx
98115c4a68a25f3b3ecedf3c81dbae1de5f3017ac84edf1c3ecc47636de0c993

curl 127.0.0.1:8080
&lt;h1&gt;Esto es una prueba de bind mount&lt;/h1&gt;

docker rm -f docker_nginx
docker_nginx

docker run --name docker_nginx2 --mount type=bind,src=https://juanan219.github.io/home/juanan/prueba,dst=/usr/share/nginx/html/ -p 8080:80 -d nginx
b231eaf659b738d74e4e119165666db0de61cee862af7d9c8b56f4b9e62dacdb

curl 127.0.0.1:8080
&lt;h1&gt;Esto es una prueba de bind mount&lt;/h1&gt;
</code></pre><p>En este ejemplo hemos hecho lo mismo que con los volúmenes, pero con la diferencia que en lugar de crear un volúmen hemos usado un <strong>bind mount</strong>, es decir, hemos creado un directorio que tiene en su interior un archivo <code>index.html</code>.</p>
<p>Como podemos comprobar, también podemos modificar el ficheor aunque el contenedor esté activo</p>
<pre><code>echo &quot;&lt;h1&gt;Este archivo se ha modificado&lt;/h1&gt;&quot; &gt; prueba/index.html

curl 127.0.0.1:8080
&lt;h1&gt;Este archivo se ha modificado&lt;/h1&gt;
</code></pre><h2 id="ejercicio-contenedor-mariadb-con-almacenamiento-persistente">Ejercicio: Contenedor mariadb con almacenamiento persistente</h2>
<p>En la <a href="https://hub.docker.com/_/mariadb">documentación de mariadb</a> en DockerHub nos dice que podemos crear un contenedor co almacenamiento persistente de la siguiente manera</p>
<pre><code>docker run --name some-mariadb -v /home/usuario/datadir:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mariadb
</code></pre><p>Esto quiere decir que se va a crear un directorio en <code>/home/usuario/datadir</code>, en el cual se va a guardar la información de la base de datos. Si tenemos que crear un nuevo contenedor, indicaremos ese directorio como <strong>bind mount</strong> y volveremos a tener accesible dicha información.</p>
<pre><code>docker run --name docker_mariadb -v /home/juanan/datadir:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root -d mariadb
1f6d378308ff18e795969319bc48e4ae170f45ce3f6c5b6b60b4b7b3ee474a4c

ls datadir/
aria_log.00000001  aria_log_control  ib_buffer_pool  ibdata1  ib_logfile0  ibtmp1  multi-master.info  mysql  performance_schema

docker rm -f docker_mariadb
docker_mariadb

docker run --name docker_mariadb --mount type=bind,src=https://juanan219.github.io/home/juanan/datadir,dst=/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root -d mariadb
12d8638feb79eac951036bcc80e3bf98885ca491b84d561d4f57d16f6056e0f9

docker exec -it docker_mariadb bash -c 'mysql -u root -p$MYSQL_ROOT_PASSWORD'
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 3
Server version: 10.5.8-MariaDB-1:10.5.8+maria~focal mariadb.org binary distribution

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
+--------------------+
3 rows in set (0.000 sec)
</code></pre><h2 id="qué-información-tenemos-que-guardar">¿Qué información tenemos que guardar?</h2>
<p>Para terminar: ¿Qué debemos guardar de forma persistente en un contenedor?</p>
<ul>
<li>
<p>Datos de una aplicación</p>
</li>
<li>
<p>Logs del servicio</p>
</li>
<li>
<p>Configuración del servicio: En este caso podemos añadir la configuración a la imagen, pero será necesaria la creación de una nueva imagen si cambiamos la configuración. Si la guardamos en un volumen hay que tener en cuenta de tener ese fichero en el entrono de producción (puede ser bueno, porque las configuraciones de los distintos entornos pueden variar).</p>
</li>
</ul>
<h1 id="ejercicios">Ejercicios</h1>
<ol>
<li>
<p><strong>Vamos a trabajar con volúmenes docker:</strong></p>
<ul>
<li><strong>Crea un volumen que se llame <code>miweb</code></strong></li>
</ul>
</li>
</ol>
<pre><code>docker volume create miweb
miweb
</code></pre><pre><code>* **Crea un contenedor desde la imagen `php:7.4-apache` donde montes en el directorio `/var/www/html` (que sabemos que es el `documentroot` del servidor que nos ofrece esa imagen) el volumen docker que has creado**
</code></pre>
<pre><code>docker run --name apache_php --mount type=volume,src=miweb,dst=/var/www/html -p 8080:80 -d php:7.4-apache
2cd22b7170868556cfb8f3bc3dc599186bb5880bf903455f0175a9203f7c22dc
</code></pre><pre><code>* **Utiliza el comando `docker cp` para copiar un fichero `info.php` en el directorio `/var/www/html`**
</code></pre>
<pre><code>echo &quot;&lt;?php phpinfo(); ?&gt;&quot; &gt; info.php
docker cp info.php apache_php:/var/www/html
</code></pre><pre><code>* **Accede al contenedor desde el navegador para ver la información ofrecida por el fichero `php.info`**
</code></pre>
<p><img src="/Docker/Documentacion/8.png" alt="Captura 8"></p>
<pre><code>* **Borra el contenedor**
</code></pre>
<pre><code>docker rm -f apache_php
apache_php
</code></pre><pre><code>* **Crea un nuevo contenedor y monta el mismo volumen como en el ejercicio anterior**
</code></pre>
<pre><code>docker run --name apache_php --mount type=volume,src=miweb,dst=/var/www/html -p 8080:80 -d php:7.4-apache
6a6735f1bfb70eecbeb60769dbf20dd4539211d60832294f1961101a52b53564
</code></pre><pre><code>* **Accede al contenedor desde el navegador para ver la información ofrecida por el fichero `info.php`. ¿Seguía existiendo ese fichero?**
</code></pre>
<p><img src="/Docker/Documentacion/8.png" alt="Captura 8"></p>
<p>Sí, sigue existiendo el fichero, ya que está almacenado en el volumen.</p>
<ol start="2">
<li>
<p><strong>Vamos a trabajar con <code>bind mount</code></strong></p>
<ul>
<li><strong>Crea un directorio en tu host y dentro crea el fichero <code>index.html</code></strong></li>
</ul>
</li>
</ol>
<pre><code>mkdir miweb

echo &quot;&lt;h1&gt;Esto es una prueba de Bind Mount&lt;/h1&gt;&quot; &gt; miweb/index.html
</code></pre><pre><code>* **Crea un contenedor desde la imagen `php:7.4-apache` donde montes en el directorio `/var/www/html` el directorio que has creado por medio de `bind mount`**
</code></pre>
<pre><code>docker run --name apache_php -v /home/juanan/miweb:/var/www/html -p 8080:80 -d php:7.4-apache
93b868e418f4713d450f8fec76848a57ab7bcff7887bf3f294fa04d029a66192
</code></pre><pre><code>* **Accede al contenedor desde el navegador para ver la información ofrecida por el fichero `index.html`**
</code></pre>
<p><img src="/Docker/Documentacion/9.png" alt="Captura 9"></p>
<pre><code>* **Modifica el fichero `index.html` en tu host y comprueba que al refrescar la página ofrecida por el contenedor, el contenido ha cambiado**
</code></pre>
<pre><code>echo &quot;&lt;h1&gt;Esto es la segunda prueba de Bind Mount&lt;/h1&gt;&quot; &gt; miweb/index.html
</code></pre><p><img src="/Docker/Documentacion/10.png" alt="Captura 10"></p>
<pre><code>* **Borra el contenedor**
</code></pre>
<pre><code>docker rm -f apache_php
apache_php
</code></pre><pre><code>* **Crea un nuevo contenedor y monta el mismo directorio como en el ejercicio anterior**
</code></pre>
<pre><code>docker run --name apache_php -v /home/juanan/miweb:/var/www/html -p 8080:80 -d php:7.4-apache
122bcc07c2a88f0d685c5d09eaa02e144c57408a0e8dee8e2079d778381e0314
</code></pre><pre><code>* **Accede al contenedor desde el navegador para ver la información ofrecida por el fichero `index.html`. ¿Se sigue viendo el mismo contenido?**
</code></pre>
<p><img src="/Docker/Documentacion/10.png" alt="Captura 10"></p>
<p>Sí, se sigue visualizando el mismo contenido, ya que el fichero <code>index.html</code> está almacenado en el directorio que usamos como <strong>bind mount</strong>.</p>
<ol start="3">
<li>
<p><strong>Contenedores con almacenamiento persistente</strong></p>
<ul>
<li><strong>Crea un contenedor de la imagen <code>nextcloud</code> (usando <code>sqlite</code>) configurando un almacenamiento como nos muestra la <a href="https://hub.docker.com/_/nextcloud">documentación de la imagen</a> en DockerHub (pero utilizando <code>bind mount</code>). Sube algún fichero.</strong></li>
</ul>
</li>
</ol>
<pre><code>docker run --name docker_nextcloud -v /home/juanan/nextcloud:/var/www/html -p 8080:80 -d nextcloud
ffe4a54d5410245278ebe2e23ce9afec5c6dcece6f8ae3f52660337ff9ab0047

echo &quot;Esto es un fichero de prueba&quot; &gt; prueba.txt
</code></pre><p><img src="/Docker/Documentacion/11.png" alt="Captura 11"></p>
<p>He subido el archivo llamado <code>prueba.txt</code></p>
<pre><code>* **Elimina el contenedor**
</code></pre>
<pre><code>docker rm -f docker_nextcloud
docker_nextcloud
</code></pre><pre><code>* **Crea un contenedor nuevo con la misma configuración de volúmenes. Comprueba que la información que teníamos (ficheros, usuarios, etc...) sigue existiendo**
</code></pre>
<pre><code>docker run --name docker_nextcloud -v /home/juanan/nextcloud:/var/www/html -p 8080:80 -d nextcloud
967f37669b512c53d4bf5b235bd53a8970c04b748517a1a27358617cb633911d

ls nextcloud/
3rdparty  AUTHORS  console.php  core      custom_apps  index.html  lib  ocm-provider  ocs-provider  remote.php  robots.txt  themes
apps      config   COPYING      cron.php  data         index.php   occ  ocs           public.php    resources   status.php  version.php
</code></pre><pre><code>* **Comprueba el contenido del directorio que se ha creado en el host**
</code></pre>
<p><img src="/Docker/Documentacion/12.png" alt="Captura 12"></p>
<p>Como podemos comprobar, después de haber eliminado el contenedor y habiendo hecho uno nuevo, como los archivos de <code>nextcloud</code> se encontraban en el directorio <code>/home/juanan/nextcloud</code>, siguen estando ahí, por lo que ni los usuarios, ni los datos que hemos subido se han eliminado.</p>
]]></content>
        </item>
        
        <item>
            <title>Creando escenarios multicontenedor con docker-compose</title>
            <link>https://juanan219.github.io/posts/2021/02/creando-escenarios-multicontenedor-con-docker-compose/</link>
            <pubDate>Tue, 23 Feb 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/02/creando-escenarios-multicontenedor-con-docker-compose/</guid>
            <description>En ocasiones, es necesario disponer de múltiples contenedores, como por ejemplo:
  Cuando necesitamos varios servicios para que la aplicación funcione, como por ejemplo con Wordpress, necesitaríamos un contenedor para la propia aplicación web y otro contenedor para el servidor de bases de datos MySQL.
  Si tenemos nuestra aplicación construida con microservicios, de los cuales, cada microservicio se ejecutará en un contenedor independiente.
  Cuando trabajamos en escenarios en los que necesitamos varios contenedores, podemos usar docker-compose para gestionarlos.</description>
            <content type="html"><![CDATA[<p>En ocasiones, es necesario disponer de múltiples contenedores, como por ejemplo:</p>
<ul>
<li>
<p>Cuando necesitamos varios servicios para que la aplicación funcione, como por ejemplo con <code>Wordpress</code>, necesitaríamos un contenedor para la propia aplicación web y otro contenedor para el servidor de bases de datos <code>MySQL</code>.</p>
</li>
<li>
<p>Si tenemos nuestra aplicación construida con microservicios, de los cuales, cada microservicio se ejecutará en un contenedor independiente.</p>
</li>
</ul>
<p>Cuando trabajamos en escenarios en los que necesitamos varios contenedores, podemos usar <code>docker-compose</code> para gestionarlos.</p>
<p>Vamos a definir el escenario con un fchero llamado <code>docker-compose.yml</code> y vamos a gestionar el tiempo de vida de las aplicaciones y de todos los componentes que necesitamos con la utilidad <code>docker-compose</code>.</p>
<h2 id="ventajas-de-usar-doker-compose">Ventajas de usar doker-compose</h2>
<ul>
<li>
<p>Hacer todo de manera declarativa para no tener que repetir el proceso una vez que se construye el escenario.</p>
</li>
<li>
<p>Poner en marcha todos los contenedores que necesita mi aplicación de una sola vez y correctamente configurados.</p>
</li>
<li>
<p>Garantizar que los contenedores se arrancan en el orden adecuado. Por ejemplo: Si mi aplicación no puede funcionar debidamente hasta que el servidor de bases de datos esté en marcha, configuraré el fichero para que se arranque antes el contenedor de la base de datos que el de la aplicación que depende de ella.</p>
</li>
<li>
<p>Asegurarnos de que hay comunicación entre los contenedores que pertenecen a la aplicación.</p>
</li>
</ul>
<h2 id="instalación-de-docker-compose">Instalación de docker-compose</h2>
<ul>
<li>Para instalarlo desde repositorios de debian</li>
</ul>
<pre><code>sudo apt-get install docker-compose
</code></pre><ul>
<li>Para instalarlo con <code>pip</code> desde un entorno virtual:</li>
</ul>
<pre><code>python3 -m venv docker-compose
source docker-compose/bin/activate
(docker-compose) ~# pip install docker-compose
</code></pre><h2 id="el-fichero-docker-composeyml">El fichero docker-compose.yml</h2>
<p>Con el fichero <code>docker-compose.yml</code> definimos el escenario. El programa <code>docker-compose</code> se tiene que ejecutar en el directorio en el cual esté este fichero. Por ejemplo, para la ejecución de un <code>wordpress</code> persistente deberíamos tener un fichero con el siguiente contenido:</p>
<pre><code>version: '3.1'

services:

	wordpress:
		container_name: docker_wp
		image: wordpress
		restart: always
		environment:
			WORDPRESS_DB_HOST: maria_wp
			WORDPRESS_DB_USER: wordpress_user
			WORDPRESS_DB_PASSWORD: wordpress_passwd
			WORDPRESS_DB_NAME: wp_db
		volumes:
			- /home/juanan/wordpress/wp:/var/www/html

	db:
		container_name: maria_wp
		image: mariadb
		restart: always
		environment:
			MYSQL_DATABASE: wp_db
			MYSQL_USER: wordpress_user
			MYSQL_PASSWORD: wordpress_passwd
			MYSQL_ROOT_PASSWORD: root
		volumes:
			- /home/juanan/wordpress/mariadb:/var/lib/mysql
</code></pre><p>Puedes encontrar todos los parámetros que se pueden definir en la <a href="https://docs.docker.com/compose/compose-file/compose-file-v3/">documentación oficial</a>.</p>
<p>Algunos parámetros interesantes:</p>
<ul>
<li>
<p><strong><code>restart: always</code>:</strong> Indicamos la política de reinicio del contenedor, ya que si por algún motivo falla, esta se reinicia en lugar de quedarse apagada.</p>
</li>
<li>
<p><strong><code>depend: on</code>:</strong> Indica la dependencia entre contenedores. No va a iniciar un contenedor hasta que otro esté funcionando.</p>
</li>
</ul>
<p>Cuando creamos un escenario con el comando <code>docker-compose</code> se crea una nueva red definida por el usuario <code>docker</code>, en la cual se conectan los contenedores, por lo que tenemos resolución de nombres por DNS que resuelve tanto por el nombre (por ejemplo <code>servidor_mysql</code>) como por el alias (por ejemplo <code>maria_wp</code>).</p>
<ul>
<li>Para crear un escenario</li>
</ul>
<pre><code>docker compose up -d
</code></pre><ul>
<li>Para listar los contenedores</li>
</ul>
<pre><code>docker-compose ps
</code></pre><ul>
<li>Para parar los contenedores</li>
</ul>
<pre><code>docker-compose stop
</code></pre><ul>
<li>Para borrar los contenedores</li>
</ul>
<pre><code>docker-compose rm
</code></pre><h2 id="el-comando-docker-compose">El comando docker-compose</h2>
<p>Una vez que hemos creado el archivo <code>docker-compose.yml</code> tenemos que empezar a crear los contenedores que se describen en su contenido. Esto lo haremos ejecutando el comando <code>docker-compose</code> en el directorio en el que se encuentra el fichero de configuración.</p>
<p>Los subcomandos más usados son:</p>
<ul>
<li>
<p><strong><code>docker-compose up</code>:</strong> Crea los contenedores (servicios) que están definidos en el <code>docker-compose.yml</code></p>
</li>
<li>
<p><strong><code>docker-compose up -d</code>:</strong> Crea en modo <code>detach</code> los contenedores (servicios) que están descritos en el <code>docker-compose.yml</code></p>
</li>
<li>
<p><strong><code>docker-compose stop</code>:</strong> Detiene los contenedores que se han lanzado con <code>docker-compose up</code></p>
</li>
<li>
<p><strong><code>docker-compose run</code>:</strong> Inicia los contenedores definidos en el <code>docker-compose.yml</code> que estén preparados</p>
</li>
<li>
<p><strong><code>docker-compose rm</code>:</strong> Borra los contenedores preparados del escenario. Con la opción <code>-f</code> borra también los que se estén ejecutando</p>
</li>
<li>
<p><strong><code>docker-compose pause</code>:</strong> Pausa los contenedores que se han lanzado con <code>docker-compose up</code></p>
</li>
<li>
<p><strong><code>docker-compose unpause</code>:</strong> Reaunda los contenedores que están pausados</p>
</li>
<li>
<p><strong><code>docker-compose restart</code>:</strong> Reinicia los contenedores. Este comando es ideal para reiniciar servicios con nuevas configuraciones.</p>
</li>
<li>
<p><strong><code>docker-compose down</code>:</strong> Para los contenedores, los borra y con ellos borra las redes que se han creado con <code>docker-compose up</code> (en el caso de haberse creado)</p>
</li>
<li>
<p><strong><code>docker-compose down -v</code>:</strong> Para los contenedores, los elimina, elimina sus redes y sus volúmenes.</p>
</li>
<li>
<p><strong><code>docker-compose logs servicio1</code>:</strong> Muestra los logs del servicio llamado <code>servicio1</code> que estaba descrito en el <code>docker-compose.yml</code></p>
</li>
<li>
<p><strong><code>docker-compose exec servicio1 /bin/bash</code>:</strong> Ejecuta una orden, en este caso, <code>/bin/bash</code> en el contenedor llamado <code>servicio1</code> que estaba descrito en el <code>docker-compose.yml</code></p>
</li>
<li>
<p><strong><code>docker-compose build</code>:</strong> Ejecuta, si está indicado, el proceso de construcción de una imagen que va a ser usada en el <code>docker-compose.yml</code> a partir de los ficheros <code>dockerfile</code> que se indican.</p>
</li>
<li>
<p><strong><code>docker-compose top</code>:</strong> Muestra los procesos que están ejecutándose en cada uno de los contenedores de los servicios.</p>
</li>
</ul>
<h1 id="ejercicios">Ejercicios</h1>
<ol>
<li><strong>Instala <code>docker-compose</code> en tu ordenador. Copia el fichero <code>docker-compose.yml</code> de la <a href="https://hub.docker.com/_/wordpress">documentación</a> de la imagen oficial de <code>wordpress</code></strong></li>
</ol>
<pre><code>sudo apt-get install docker-compose

sudo mkdir docker-compose

cd docker-compose/

nano docker-compose.yml

version: '3.1'

services:

  wordpress:
    image: wordpress
    restart: always
    ports:
      - 8080:80
    environment:
      WORDPRESS_DB_HOST: db
      WORDPRESS_DB_USER: exampleuser
      WORDPRESS_DB_PASSWORD: examplepass
      WORDPRESS_DB_NAME: exampledb
    volumes:
      - wordpress:/var/www/html

  db:
    image: mysql:5.7
    restart: always
    environment:
      MYSQL_DATABASE: exampledb
      MYSQL_USER: exampleuser
      MYSQL_PASSWORD: examplepass
      MYSQL_RANDOM_ROOT_PASSWORD: '1'
    volumes:
      - db:/var/lib/mysql

volumes:
  wordpress:
  db:
</code></pre><ol start="2">
<li><strong>Modifica el <code>docker-compose.yml</code> para que use el puerto <code>8001</code></strong></li>
</ol>
<pre><code>services:
	wordpress:
[...]
		ports:
			- 8080:8001
[...]
</code></pre><ol start="3">
<li><strong>Modifica el <code>docker-compose.yml</code> para que la base de datos se llame <code>db_wordpress</code></strong></li>
</ol>
<pre><code>services:
	wordpress:
[...]
		environment:
[...]
			WORDPRESS_DB_NAME: db_wordpress
[...]
		db:
[...]
			environment:
				MYSQL_DATABASE: db_wordpress
[...]
</code></pre><ol start="4">
<li><strong>Modifica el <code>docker-compose.yml</code> para usar <code>bind mount</code> en lugar de volúmenes</strong></li>
</ol>
<pre><code>services:
	wordpress:
[...]
		volumes:
			- /home/juanan/wordpress/wp:/var/www/html
[...]
	db:
[...]
		volumes:
			- /home/juanan/wordpress/mariadb:/var/lib/mysql
</code></pre><ol start="5">
<li><strong>Levanta el escenario con <code>docker-compose</code></strong></li>
</ol>
<pre><code>docker-compose up -d
</code></pre><ol start="6">
<li><strong>Muestra los contenedores con <code>docker-compose</code></strong></li>
</ol>
<pre><code>docker-compose ps
       Name                     Command               State               Ports             
--------------------------------------------------------------------------------------------
juanan_db_1          docker-entrypoint.sh mysqld      Up      3306/tcp, 33060/tcp           
juanan_wordpress_1   docker-entrypoint.sh apach ...   Up      80/tcp, 0.0.0.0:8080-&gt;8001/tcp
</code></pre><ol start="7">
<li><strong>Accede a la aplicación y comprueba que funciona</strong></li>
</ol>
<p><img src="/Docker/Documentacion/18.png" alt="Captura 18"></p>
<ol start="8">
<li><strong>Comprueba el almacenamiento que has definido y que se ha creado una red de tipo <code>bridge</code></strong></li>
</ol>
<pre><code>docker network ls
[...]
NETWORK ID          NAME                DRIVER              SCOPE
64f74f4b8685        juanan_default      bridge              local
[...]
</code></pre><ol start="9">
<li><strong>Borra el escenario con <code>docker-compose</code></strong></li>
</ol>
<pre><code>docker-compose down
Stopping juanan_wordpress_1 ... done
Stopping juanan_db_1        ... done
Removing juanan_wordpress_1 ... done
Removing juanan_db_1        ... done
Removing network juanan_default
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Uso de las Imagenes Docker</title>
            <link>https://juanan219.github.io/posts/2021/02/uso-de-las-imagenes-docker/</link>
            <pubDate>Tue, 23 Feb 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/02/uso-de-las-imagenes-docker/</guid>
            <description>Registros de Imágenes: DockerHub Las imágenes de Docker son plantillas de solo lectura, es decir, una imagen que contiene archivos de un sistema operativo como Debian, solo nos permitirá crear contenedores basados en dicha imagen, pero los cambios que hagamos en el contenedor, una vez que se ha detenido, no se verán reflejados en la imagen.
El nombre de una imágen suele estar formado por tres partes:
usuario/nombre:etiqueta   usuario: El nombre del usuario que ha generado la imagen.</description>
            <content type="html"><![CDATA[<h2 id="registros-de-imágenes-dockerhub">Registros de Imágenes: DockerHub</h2>
<p><img src="/Docker/Documentacion/3.png" alt="Captura 3"></p>
<p>Las imágenes de Docker son plantillas de solo lectura, es decir, una imagen que contiene archivos de un sistema operativo como Debian, solo nos permitirá crear contenedores basados en dicha imagen, pero los cambios que hagamos en el contenedor, una vez que se ha detenido, no se verán reflejados en la imagen.</p>
<p>El nombre de una imágen suele estar formado por tres partes:</p>
<pre><code>usuario/nombre:etiqueta
</code></pre><ul>
<li>
<p><strong><code>usuario</code>:</strong> El nombre del usuario que ha generado la imagen. Si la subimos a DockerHub, este nombre debe de ser el mismo con el que nos hemos dado de alta en la plataforma. Las <strong>imágenes oficiales</strong> en DockerHub no tienen nombre de usuario, sino que se llaman igual que la imagen. Por ejemplo, la imagen de debian se llamaría <code>debian/debian</code></p>
</li>
<li>
<p><strong><code>nombre</code>:</strong> Nombre significativo de la imagen.</p>
</li>
<li>
<p><strong><code>etiqueta</code>:</strong> Nos permite versionar las imágenes. De esta manera podemos controlar los cambios que vamos haciendo en ellas. Si al descargar una imagen no le ponemos etiqueta, por defecto se descargará la versión <code>latest</code>, por lo que la mayoría de las imágenes tienen una versión con ese nombre.</p>
</li>
</ul>
<h2 id="gestión-de-imágenes">Gestión de imágenes</h2>
<p>Para crear un contenedor, es necesario crearlo con una imagen que tengamos descargada en nuestro registro local. Por lo tanto al ejecutar <code>docker run</code> se comprueba si tenemos la versión indicada de la imagen, si no es así, se procede a descargarla.</p>
<p>Las principales instrucciones para trabajar con imágenes son:</p>
<ul>
<li>
<p><strong><code>docker images</code>:</strong> Muestra las imágenes que tenemos en nuestro registro local.</p>
</li>
<li>
<p><strong><code>docker pull</code>:</strong> Nos permite descargar la última versión de la imagen indicada.</p>
</li>
<li>
<p><strong><code>docker rmi</code>:</strong> Nos permite eliminar imágenes (No podemos eliminar una imagen si tenemos un contenedor usándola).</p>
</li>
<li>
<p><strong><code>docker search</code>:</strong> Busca imágenes en DockerHub.</p>
</li>
<li>
<p><strong><code>docker inspect</code>:</strong> No da información sobre la imagen indicada:</p>
<ul>
<li>
<p><code>ID</code> y <code>checksum</code> de la imagen.</p>
</li>
<li>
<p>Los puertos abiertos</p>
</li>
<li>
<p>La arquitectura y el sistema operativo de la imagen</p>
</li>
<li>
<p>El tamaño de la imagen</p>
</li>
<li>
<p>Los volúmenes</p>
</li>
<li>
<p>El ENTRYPOINT (es lo que ejecuta el comando <code>docker run</code>)</p>
</li>
<li>
<p>Las capas</p>
</li>
<li>
<p>Etc&hellip;</p>
</li>
</ul>
</li>
</ul>
<h2 id="cómo-se-organizan-las-imágenes">¿Cómo se organizan las imágenes?</h2>
<p>Las imágenes están hechas de <strong>capas ordenadas</strong>. Las capas son un conjunto de cambios en el sistema de archivos. Cuando tomas todas las capas y las apilas obtienes una nueva imagen que tiene todos los cambios acumulados.</p>
<p>Si tienes varias imágenes que tienen capas en común, estas capas se almacenarán sólo una vez.</p>
<p><img src="/Docker/Documentacion/4.png" alt="Captura 4"></p>
<p>Cuando se crea un nuevo contenedor, todas las capas de la imagen son de sólo lectura, pero se le agrega encima una pequeña capa de lectura-escritura, con lo cual, todos los cambios realizados en dicho contenedor son almacenados en esa capa que se le ha añadido.</p>
<p>El propio contenedor no puede modificar la imágen (ya que es de sólo lectura), por lo que creará una copia del fichero en su capa superior y desde ahí en adelante, cualquiera que trate de acceder al archivo, obtendrá la capa superior.</p>
<p><img src="/Docker/Documentacion/5.png" alt="Captura 5"></p>
<p>Cuando creamos un contenedor, éste ocupa muy poco espacio en el disco, esto se debe a que las capas de la imagen desde la que se ha creado dicho contenedor, se comparten entre otros contenedores.</p>
<p>Este es el tamaño de la imagen <code>debian</code> que hemos usado en la documentación anterior:</p>
<pre><code>juanan@juananpc:~$ docker images
REPOSITORY                    TAG                 IMAGE ID            CREATED             SIZE
[...]
debian                        latest              5890f8ba95f6        2 weeks ago         114MB
[...]
</code></pre><p>Vamos a crear un contenedor interactivo y después visualizamos los contenedores con la opción <code>-s</code> (size o tamaño en español) para ver cuánto ocupan</p>
<pre><code>juanan@juananpc:~$ docker run -it --name contenedor_debian debian /bin/bash
root@3f284a03c3d9:/# exit

juanan@juananpc:~$ docker ps -a -s
CONTAINER ID      IMAGE            COMMAND           CREATED           STATUS                     PORTS        NAMES               SIZE
3f284a03c3d9      debian           &quot;/bin/bash&quot;       8 seconds ago     Exited (0) 5 seconds ago                contenedor_debian   0B (virtual 114MB)
</code></pre><p>Podemos ver que el tamaño del contenedor es de <code>0B</code> y el tamaño virtual es de <code>114MB</code>, que es el tamaño de la imagen <code>debian</code>, pero si volvemos a arrancar el contenedor, nos conectamos y creamos un fichero, podemos ver que el tamaño cambia</p>
<pre><code>juanan@juananpc:~$ docker start contenedor_debian
contenedor_debian

juanan@juananpc:~$ docker attach contenedor_debian
root@3f284a03c3d9:/# echo 'Hola, esto es un fichero de prueba' &gt; fichero.txt
root@3f284a03c3d9:/# exit

juanan@juananpc:~$ docker ps -a -s
CONTAINER ID      IMAGE             COMMAND           CREATED           STATUS                     PORTS          NAMES               SIZE
3f284a03c3d9      debian            &quot;/bin/bash&quot;       4 minutes ago     Exited (0) 6 seconds ago                  contenedor_debian   91B (virtual 114MB)
</code></pre><p>Por último, si solicitamos información sobre una imagen podemos ver información sobre las capas:</p>
<pre><code>docker inspect debian
[...]
&quot;RootFS&quot;: {
            &quot;Type&quot;: &quot;layers&quot;,
            &quot;Layers&quot;: [
                &quot;sha256:7f03bfe4d6dc12155877f0d2e8b3429090bad1af7b005f75b7b3a874f386fd5a&quot;
            ]
        },
[...]
</code></pre><h2 id="creación-de-instancias-desde-imágenes">Creación de instancias desde imágenes</h2>
<p>Hay dos tipos de imágenes en los repositorios y se dividen según la utilidad que nos ofrecen:</p>
<ul>
<li>
<p>Imágenes para ejecutar contenedores de diferentes sistemas operativos (Ubuntu, CentOS, Debian, etc&hellip;)</p>
</li>
<li>
<p>Imágenes para ejecutar servicios asociados (Apache, MySQL, Tomcat, etc&hellip;)</p>
</li>
</ul>
<p>Todas las imágenes tienen un proceso que se ejecuta por defecto, pero nosotros, al crear un contenedor, podemos indicarle el proceso que queremos que realice al crear dicho contenedor.</p>
<p>Por ejemplo, en la imagen <code>ubuntu</code>, el proceso por defecto es <code>bash</code>, por lo que podemos ejecutar:</p>
<pre><code>docker run -it --name contenedor_ubuntu ubuntu
</code></pre><p>Pero podemos indicar el comando que queremos ejecutar en la creación del contenedor</p>
<pre><code>docker run -it --name contenedor_ubuntu ubuntu /bin/echo 'Hola mundo'
</code></pre><p>Otro ejemplo: la imagen <code>httpd:2.4</code> ejecuta un servidor web por defecto, por lo tanto podemos crear el contenedor de la siguiente forma:</p>
<pre><code>docker run -d --name contenedor_apache -p 8080:80 httpd:2.4
</code></pre><h1 id="ejercicios">Ejercicios</h1>
<ol>
<li><strong>Descarga las siguientes imágenes: <code>ubuntu:18.04</code>, <code>httpd</code>, <code>tomcat:9.0.39-jdk11</code>, <code>jenkins/jenkins:lts</code>, <code>php:7.4-apache</code></strong></li>
</ol>
<ul>
<li><code>ubuntu:18.04</code>:</li>
</ul>
<pre><code>docker pull ubuntu:18.04
</code></pre><ul>
<li><code>httpd</code>:</li>
</ul>
<pre><code>docker pull httpd
</code></pre><ul>
<li><code>tomcat:9.0.39-jdk11</code>:</li>
</ul>
<pre><code>docker pull tomcat:9.0.39-jdk11
</code></pre><ul>
<li><code>jenkins/jenkins:lts</code></li>
</ul>
<pre><code>docker pull jenkins/jenkins
</code></pre><ul>
<li><code>php:7.4-apache</code>:</li>
</ul>
<pre><code>docker pull php:7.4-apache
</code></pre><ol start="2">
<li><strong>Muestra las imágenes que tienes descargadas</strong></li>
</ol>
<pre><code>docker images
</code></pre><ol start="3">
<li><strong>Crea un contenedor demonio con la imagen <code>php:7.4-apache</code></strong></li>
</ol>
<pre><code>docker run --name php_apache -p 8080:80 -d php:7.4-apache
371dba835efa5e4739efbf9d2bdc59f66c79d636dbc20f80e9388b83724adb7e

docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                  NAMES
371dba835efa        php:7.4-apache      &quot;docker-php-entrypoi…&quot;   8 seconds ago       Up 7 seconds        0.0.0.0:8080-&gt;80/tcp   php_apache
</code></pre><ol start="4">
<li><strong>Comprueba el tamaño del contenedor en el disco duro</strong></li>
</ol>
<pre><code>docker ps -s
CONTAINER ID     IMAGE             COMMAND                  CREATED              STATUS              PORTS                  NAMES          SIZE
371dba835efa     php:7.4-apache    &quot;docker-php-entrypoi…&quot;   About a minute ago   Up About a minute   0.0.0.0:8080-&gt;80/tcp   php_apache     2B (virtual 414MB)
</code></pre><p>El tamaño del contenedor es de <code>2B</code></p>
<ol start="5">
<li><strong>Con la opción <code>docker cp</code> podemos copiar ficheros desde o hacia un contenedor. Copia el fichero <code>info.php</code> al directorio <code>/var/www/html</code> del contenedor</strong></li>
</ol>
<pre><code>echo '&lt;?php phpinfo(); ?&gt;' &gt; info.php

docker cp info.php php_apache:/var/www/html
</code></pre><p>Ahora el contenedor ocupa <code>22B</code></p>
<ol start="6">
<li><strong>Vuelve a comprobar el espacio del contenedor</strong></li>
</ol>
<pre><code>docker ps -s
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                  NAMES          SIZE
371dba835efa        php:7.4-apache      &quot;docker-php-entrypoi…&quot;   5 minutes ago       Up 5 minutes        0.0.0.0:8080-&gt;80/tcp   php_apache     22B (virtual 414MB)
</code></pre><ol start="7">
<li><strong>Accede al fichero <code>info.php</code> desde un navegador</strong></li>
</ol>
<p><img src="/Docker/Documentacion/6.png" alt="Captura 6"></p>
]]></content>
        </item>
        
        <item>
            <title>Redes en Docker</title>
            <link>https://juanan219.github.io/posts/2021/02/redes-en-docker/</link>
            <pubDate>Tue, 23 Feb 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/02/redes-en-docker/</guid>
            <description>Introducción a las redes en Docker Cada vez que creamos un contenedor en Docker, éste se conecta a una red virtual y docker hace una configuración del sistema (usando interfaces puente e iptables para que la máquina tenga una ip interna, tenga acceso al exterior, podamos mapear puertos (DNAT), etc&amp;hellip;)
Podemos ver el comando ip si ejecutamos un contenedor con este comando.
docker run -it --rm --name docker_debian debian bash -c &#39;ip a&#39; 1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.</description>
            <content type="html"><![CDATA[<h2 id="introducción-a-las-redes-en-docker">Introducción a las redes en Docker</h2>
<p>Cada vez que creamos un contenedor en Docker, éste se conecta a una red virtual y docker hace una configuración del sistema (usando interfaces puente e iptables para que la máquina tenga una ip interna, tenga acceso al exterior, podamos mapear puertos (DNAT), etc&hellip;)</p>
<p>Podemos ver el comando ip si ejecutamos un contenedor con este comando.</p>
<pre><code>docker run -it --rm --name docker_debian debian bash -c 'ip a'
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
56: eth0@if57: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default 
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
</code></pre><blockquote>
<p><strong>Nota:</strong> Si usamos la opción <code>--rm</code> el contenedor se elimina nada más que termina de hacer el proceso que se le ha encargado.</p>
</blockquote>
<p>Como podemos ver arriba, a nuestro contenedor se le ha asignado la ip <code>172.17.0.2/16</code> y se ha creado una interfaz tipo <code>bridge</code> en la máquina anfitriona, a la cual se conectan los contenedores.</p>
<pre><code>ip a
[...]
6: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default 
    link/ether 02:42:65💿e3:5c brd ff:ff:ff:ff:ff:ff
    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
       valid_lft forever preferred_lft forever
    inet6 fe80::42:65ff:fecd:e35c/64 scope link 
       valid_lft forever preferred_lft forever
[...]
</code></pre><p>Además de que se han generado ciertas reglas en el cortafuegos para gestionar las conexiones de los contenedores. Podemos ejecutar <code>iptables -nL</code> e <code>iptables -t nat -nL</code> para comprobar estas reglas.</p>
<h2 id="tipos-de-redes-en-docker">Tipos de redes en Docker</h2>
<p>Cuando instalamos docker tenemos las siguientes redes predefinidas:</p>
<pre><code>docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
09540af8449f        bridge              bridge              local
2e4b519fab3b        host                host                local
0ac9f5f0f96b        none                null                local
</code></pre><ul>
<li>Si creamos cualquier contenedor, por defecto se va a conectar a la red llamada <code>bridge</code>, cuyo direccionamiento predeterminado es 172.17.0.0/16. Los contenedores conectados a esta red que quieren exponer algún puerto al exterior tienen que usar el parámetro <code>-p</code> para mapear puertos.</li>
</ul>
<p>Este tipo de red nos permite:</p>
<pre><code>* Aislar los contenedores que tengo en distintas subredes docker, de tal manera de que los contenedores de esa subred puedan acceder exclusivamente a contenedores de su misma subred.

* Aislar los contenedores del acceso exterior.

* Publicar servicios que tengamos en los contenedores mediante redirecciones que docker implementará con las reglas iptables necesarias.
</code></pre>
<p><img src="/Docker/Documentacion/13.png" alt="Captura 13"></p>
<ul>
<li>Si conectamos un contenedor a la red <strong>host</strong>, el contenedor estaría en la misma red que nuestra máquina anfitriona, por lo que cogerá direccionamiento IP de nuestro DHCP, además de que los puertos son accesibles directamente desde el host. Si queremos conectar un contenedor que vamos a crear a una red en concreto, deberemos hacer:</li>
</ul>
<pre><code>docker run --name docker_nginx --network host -d nginx
720ea83dafd587b86799717b5a9fe072245526aa85ca60ec910b7656decc769d

docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
b1f6a0f81813        nginx               &quot;/docker-entrypoint.…&quot;   7 seconds ago       Up 6 seconds                            docker_nginx
</code></pre><p>Ahora podremos acceder a la página de <code>nginx</code> directamente desde el puerto 80</p>
<p><img src="/Docker/Documentacion/14.png" alt="Captura 14"></p>
<ul>
<li>La red <strong>none</strong> no configurará ninguna IP para el contenedor y no tiene acceso a ningún tipo de red ni equipos. Tiene una dirección <code>loopback</code> y se suele usar para ejecutar trabajos por lotes.</li>
</ul>
<h2 id="gestionando-las-redes-en-docker">Gestionando las redes en Docker</h2>
<p>Tenemos que hacer una diferenciación entre dos tipos de redes <strong>bridged</strong>:</p>
<ul>
<li>
<p>La red creada por defecto por Docker para que funcionen todos los contenedores.</p>
</li>
<li>
<p>Y las redes <code>bridged</code> definidas por el usuario.</p>
</li>
</ul>
<p>Las redes <code>bridged</code> que usan por defecto los contenedores se diferencian en varios aspectos de las redes <code>bridged</code> creadas por nosotros. Estos aspectos son los siguientes:</p>
<ul>
<li>
<p>Las redes que definimos proporcionan <strong>resolución DNS</strong> entre los contenedores, cosa que no hace la red por defecto a no ser que usemos opciones que ya se consideran <code>deprecated</code> (como la opción <code>--link</code>).</p>
</li>
<li>
<p>Puedo conectar en caliente los contenedores a redes <code>bridged</code> definidas por nosotros, mientras que si uso la red por defecto, tengo que parar previamente el contenedor.</p>
</li>
<li>
<p>Me permite gestionar de manera más segura el aislamiento de los contenedores, ya que si no indico una red, al crear el contenedor, éste se conecta a la red por defecto, en la cual puede haber otros contenedores con servicios que no tienen nada que ver con él.</p>
</li>
<li>
<p>Tengo más control sobre las redes si las defino yo, ya que los contenedores de una red por defecto comparten todos la misma configuración de red (MTU, reglas iptables, etc&hellip;)</p>
</li>
<li>
<p>Los contenedores de la red por defecto comparten ciertas variables de entorno, por lo que pueden generar algunos conflictos.</p>
</li>
</ul>
<p>Por todo esto, es muy importante que los contenedores que tenemos en producción se estén ejecutando en redes definidas por nosotros.</p>
<p>Para gestionar las redes definidas por el usuario:</p>
<ul>
<li>
<p><strong><code>docker network ls</code>:</strong> Lista las redes.</p>
</li>
<li>
<p><strong><code>docker network create</code>:</strong> Crea redes, por ejemplo</p>
</li>
</ul>
<pre><code>docker network create red1

docker netwprk create -d bridge --subnet 172.24.0.0/16 --gateway 172.24.0.1 red2
</code></pre><ul>
<li>
<p><strong><code>docker network prune</code>:</strong> Elimina las redes que no se están usando</p>
</li>
<li>
<p><strong><code>docker network rm</code>:</strong> Elimina la red o redes que le indiquemos, teniendo en cuenta siempre que no podemos eliminar una red mientras se está usando, por lo que deberemos eliminar o desconectar de dicha red el contenedor que la está usando.</p>
</li>
<li>
<p><strong><code>docker network inspect</code>:</strong> Nos da información sobre la red</p>
</li>
</ul>
<p>Cada red que creamos crea un puente de red específico para que podamos ver cada red definida con el comando <code>ip a</code> desde la máquina anfitriona.</p>
<p><img src="/Docker/Documentacion/15.png" alt="Captura 15"></p>
<h2 id="asociación-de-redes-a-los-contenedores">Asociación de redes a los contenedores</h2>
<p>Tenemos dos redes creadas por el usuario</p>
<pre><code>docker network create --subnet 172.28.0.0/16 --gateway 172.28.0.1 red1
8ea35d168034d65ea8acc8b51af61467db3ef172efd1cb7130617903c27b61b1

docker network create red2
692f9cc348f7486e26f63f49f8184f94743160ebd88da65bed057f0508e5ce97

docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
[...]
8ea35d168034        red1                bridge              local
692f9cc348f7        red2                bridge              local
</code></pre><p>Vamos a crear dos contenedores conectados a la <code>red1</code>, el primer contenedor va a tener ls imagen <code>nginx</code> y el segundo va a tener la imagen <code>debian</code>, desde la cual vamos a realizar un dig hacia el servidor web nginx</p>
<pre><code>docker run --name docker_nginx --network red1 -d nginx
4decc4259730743ca45883fe2540bddc9289211fe37dd011143b8899094ce7b1

docker run -it --name docker_debian --network red1 debian bash

root@d701cdcce43d:/# apt-get update

root@d701cdcce43d:/# apt-get install dnsutils

root@d701cdcce43d:/# dig docker_nginx

; &lt;&lt;&gt;&gt; DiG 9.11.5-P4-5.1+deb10u3-Debian &lt;&lt;&gt;&gt; docker_nginx
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 64571
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;docker_nginx.      IN  A

;; ANSWER SECTION:
docker_nginx.   600 IN  A 172.28.0.2

;; Query time: 0 msec
;; SERVER: 127.0.0.11#53(127.0.0.11)
;; WHEN: Tue Feb 23 13:10:26 UTC 2021
;; MSG SIZE  rcvd: 58
</code></pre><ul>
<li>
<p><strong><code>docker network connect</code>:</strong> Conectar contenedor a una red</p>
</li>
<li>
<p><strong><code>docker network disconnect</code>:</strong> Desconectar contenedor de una red</p>
</li>
</ul>
<p>Vamos a conectar el contenedor que está ejecutando la imagen de <code>nginx</code> a la <code>red2</code></p>
<pre><code>docker network connect red2 docker_nginx
</code></pre><p>Ahora lo vamos a desconectar</p>
<pre><code>docker network disconnect red2 docker_nginx
</code></pre><p>Tanto al crear un contenedor con la opción <code>--network</code> como al usar el comando <code>docker network connect</code> podemos usar diferentes opciones:</p>
<ul>
<li>
<p><strong><code>--dns</code>:</strong> Para establecer servidores DNS predeterminados</p>
</li>
<li>
<p><strong><code>--ip6</code>:</strong> Para establecer la dirección IPv6</p>
</li>
<li>
<p><strong><code>--hostname</code> o <code>-h</code>:</strong> Para establecer el nombre de host del contenedor. Si no establecemos el <code>hostname</code> con esta opción, éste será el nombre del propio contenedor.</p>
</li>
</ul>
<h2 id="ejercicio-instalación-de-wordpress">Ejercicio: Instalación de Wordpress</h2>
<p>Para la instalación de Workdpress necesitaremos dos contenedores:</p>
<ul>
<li>
<p>La base de datos (imagen <code>mariadb</code>)</p>
</li>
<li>
<p>El servidor web con la aplicación (imagen <code>workpress</code>)</p>
</li>
</ul>
<p>Los dos contenedores tienen que estar en la misma red y deben de tener acceso por nombres (resolución DNS) ya que de principio, no sabemos que IP tiene cada contenedor. Por lo tanto vamos a crear los contenedores en la misma red:</p>
<pre><code>docker network create --subnet 172.10.0.0/16 --gateway 172.10.0.1 red_wp
2aa05c8085811dced11f38777f286d1e37f1a47654120a86f82026fd316847bf

mkdir -p wordpress/mariadb wordpress/wp

docker run --name maria_wp --network red_wp -v /home/juanan/wordpress/mariadb:/var/lib/mysql -e MYSQL_DATABASE=wp_db -e MYSQL_USER=usuario_wp -e MYSQL_PASSWORD=passwd_wp -e MYSQL_ROOT_PASSWORD=root -d mariadb
346f6aeb93f65f97e26e592922dc7d947d597da5f32d36caae74edb16b44240e

docker run --name docker_wp --network red_wp -v /home/juanan/wordpress/wp:/var/www/html/wp-content -e WORDPRESS_DB_HOST=maria_wp -e WORDPRESS_DB_USER=usuario_wp -e WORDPRESS_DB_PASSWORD=passwd_wp -e WORDPRESS_DB_NAME=wp_db -p 80:80 -d wordpress
aad713617b33eac4d316080fd0319516faea84d2719677ffee1a335426e17571

docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                NAMES
aad713617b33        wordpress           &quot;docker-entrypoint.s…&quot;   19 seconds ago      Up 17 seconds       0.0.0.0:80-&gt;80/tcp   docker_wp
346f6aeb93f6        mariadb             &quot;docker-entrypoint.s…&quot;   4 minutes ago       Up 4 minutes        3306/tcp             maria_wp
</code></pre><p><img src="/Docker/Documentacion/16.png" alt="Captura 16"></p>
<h1 id="ejercicios">Ejercicios</h1>
<ol>
<li><strong>Ejecuta una instrucción docker para visualizar el contenido del fichero <code>wp-config.php</code> y verifica que los parámetros de conexión a la base de datos son los mismos que los que indicamos en las variables de entorno</strong></li>
</ol>
<pre><code>docker exec docker_wp bash -c 'cat /var/www/html/wp-config.php'
[...]
define( 'DB_NAME', 'wp_db');

/** MySQL database username */
define( 'DB_USER', 'usuario_wp');

/** MySQL database password */
define( 'DB_PASSWORD', 'passwd_wp');

/** MySQL hostname */
define( 'DB_HOST', 'maria_wp');
[...]
</code></pre><ol start="2">
<li><strong>Ejecuta una instrucción docker para comprobar que desde el servidor <code>docker_wp</code> podemos hacer un ping usando el nombre <code>maria_wp</code> (Tendrás que instalar el paquete <code>iputils-ping</code> en dicho contenedor)</strong></li>
</ol>
<ul>
<li>Actualizamos la lista de paquetes e instalamos el paquete <code>iputils-ping</code></li>
</ul>
<pre><code>docker exec docker_wp bash -c 'apt-get update &amp;&amp; apt-get install -y iputils-ping &amp;&amp; ping maria_wp'
[...]
PING maria_wp (172.10.0.2) 56(84) bytes of data.
64 bytes from maria_wp.red_wp (172.10.0.2): icmp_seq=1 ttl=64 time=0.156 ms
64 bytes from maria_wp.red_wp (172.10.0.2): icmp_seq=2 ttl=64 time=0.118 ms
64 bytes from maria_wp.red_wp (172.10.0.2): icmp_seq=3 ttl=64 time=0.122 ms
</code></pre><ol start="3">
<li><strong>Visualiza el fichero <code>/etc/mysql/mariadb.conf.d/50-server.cnf</code> del contenedor de la base de datos y comprueba cómo está configurado el parámetro <code>bind-address</code></strong></li>
</ol>
<pre><code>docker exec maria_wp bash -c 'cat /etc/mysql/mariadb.conf.d/50-server.cnf | grep &quot;bind-address&quot;'
#bind-address            = 127.0.0.1
</code></pre><p>El parámetro <code>bind-address</code> está comentado</p>
<ol start="4">
<li><strong>Instala otro CMS PHP siguiendo la documentación de DockerHub de la aplicación seleccionada</strong></li>
</ol>
<pre><code>docker network create red_joomla
b19cc1d0fedb6a59b52b7dab3c99390b4cb9c1aa3a84bb84374dc18826d1bd56

docker run --name my_joomla --network red_joomla -e MYSQL_ROOT_PASSWORD=root -e MYSQL_DATABASE=joomla_db -e MYSQL_USER=joomla_user -e MYSQL_PASSWORD=joomla_passwd -d mariadb
938ec4c9b3beb8b4229b9d54e1bc327e6d6c09f1530ff451935750890d0c2d2a

docker run --name docker_joomla --network red_joomla -e JOOMLA_DB_HOST=my_joomla -e JOOMLA_DB_USER=joomla_user -e JOOMLA_DB_PASSWORD=joomla_passwd -e JOOMLA_DB_NAME=joomla_db -p 80:80 -d joomla
3815c6e2843428eb2a62d595365e8f868afcd3cfe0415b38f911d95132041768
</code></pre><p><img src="/Docker/Documentacion/17.png" alt="Captura 17"></p>
]]></content>
        </item>
        
        <item>
            <title>Introduccion a Docker</title>
            <link>https://juanan219.github.io/posts/2021/02/introduccion-a-docker/</link>
            <pubDate>Mon, 22 Feb 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/02/introduccion-a-docker/</guid>
            <description>Introducción a Docker El objetivo de Docker es el despliegue de aplicaciones en capsuladas en contenedores, en lugar de desplegar las aplicaciones en máquinas virtuales.
Docker está formado por varios componentes:
  Docker Engine: Es un demonio de cualquier distribución Linux, el cual tiene una API para gestionar las imágenes y contenedores. Sirve para crear imágenes, subirlas y bajarlas de un registro docker, ejecutar y gestionar contenedores.
  Docker Client: Este es el CLI (Command Line Interface) que nos permite controlar Docker Engine.</description>
            <content type="html"><![CDATA[<h2 id="introducción-a-docker">Introducción a Docker</h2>
<p>El objetivo de <strong>Docker</strong> es el despliegue de aplicaciones en capsuladas en contenedores, en lugar de desplegar las aplicaciones en máquinas virtuales.</p>
<p><strong>Docker</strong> está formado por varios componentes:</p>
<ul>
<li>
<p><strong>Docker Engine:</strong> Es un demonio de cualquier distribución Linux, el cual tiene una API para gestionar las imágenes y contenedores. Sirve para crear imágenes, subirlas y bajarlas de un registro docker, ejecutar y gestionar contenedores.</p>
</li>
<li>
<p><strong>Docker Client:</strong> Este es el CLI (Command Line Interface) que nos permite controlar <code>Docker Engine</code>. Este cliente se puede configurar tanto local como remoto permitiéndonos gestionar nuestro entorno de desarrollo local como nuestro entorno de producción remoto.</p>
</li>
<li>
<p><strong>Docker Registry:</strong> Almacena las imágenes gestionadas por <code>Docker Engine</code>. Este apartado de docker es totalmente fundamental, ya que es el que se encarga de distribuir nuestras aplicaciones. Se puede instalar en cualquier servidor y de manera totalmente independiente, pero el proyecto docker nos ofrece <strong>Docker Hub</strong>.</p>
</li>
</ul>
<h2 id="instalación-de-docker">Instalación de Docker</h2>
<ul>
<li>Instalación de la comunidad</li>
</ul>
<pre><code>sudo apt-get install docker.io
</code></pre><ul>
<li>Si queremos usar docker con el usuario sin privilegios</li>
</ul>
<pre><code>sudo usermod -aG docker usuario
</code></pre><h2 id="el-hola-mundo-de-docker">El &ldquo;Hola Mundo&rdquo; de Docker</h2>
<p>Comprobaremos que todo esto funciona ejecutando nuestro primer contenedor llamado <code>hello-world</code>.</p>
<pre><code>docker run hello-world
</code></pre><ul>
<li>
<p>¿Qué es lo que ocurre cuando ejecutamos <code>docker run hello-world</code>?</p>
<ul>
<li>
<p>Al ser la primera vez que ejecuto un contenedor basado en la imagen <code>hello-world</code>, esta se descarga desde el repositorio que se encuentra en el registro que vamos a usar, en nuestro caso es <code>DockerHub</code>.</p>
</li>
<li>
<p>Después de descargarse muestra el mensaje de bienvenida, consecuencia de crear y arrancar un contenedor basado en la imagen <code>hello-world</code>.</p>
</li>
</ul>
</li>
</ul>
<p><strong>Otro ejemplo:</strong></p>
<pre><code>docker run ubuntu /bin/echo 'Hello world'
</code></pre><p>Con el comando <code>run</code> vamos a ejecutar un contenedor en el que vamos a ejecutar un comando, en este caso, hemos creado un contenedor con una imagen basada en <code>ubuntu</code>. Como es la primera vez que ejecutamos un contenedor basado en esta imagen, se descargará de <code>DockerHub</code>, si no es así, esta no se descargará y simplemente se ejecutará el contenedor.</p>
<p>Después podemos comprobar que se ha ejecutado con el comando <code>ps -a</code>, de esta forma podemos ver todos los contenedores que hemos ejecutado</p>
<pre><code>docker ps -a
</code></pre><h2 id="comandos-de-docker">Comandos de Docker</h2>
<ul>
<li>Listar los contenedores que se están ejecutando</li>
</ul>
<pre><code>docker ps
</code></pre><ul>
<li>Listar todos los contenedores</li>
</ul>
<pre><code>docker ps -a
</code></pre><ul>
<li>Eliminar un contenedor identificando su <code>ID</code></li>
</ul>
<pre><code>docker rm [ID]
</code></pre><ul>
<li>Eliminar un contenedor por su nombre</li>
</ul>
<pre><code>docker rm [nombre]
</code></pre><ul>
<li>Ver todas las imágenes que tenemos descargadas:</li>
</ul>
<pre><code>docker images
</code></pre><ul>
<li>Iniciar un contenedor</li>
</ul>
<pre><code>docker start [nombre]
</code></pre><ul>
<li>Conectarse a un contenedor</li>
</ul>
<pre><code>docker attach [nombre]
</code></pre><ul>
<li>Ver lo que está haciendo un contenedor</li>
</ul>
<pre><code>docker logs [nombre]
</code></pre><ul>
<li>Parar un contenedor</li>
</ul>
<pre><code>docker stop [nombre]
</code></pre><ul>
<li>Eliminar un contenedor</li>
</ul>
<pre><code>docker rm [nombre]
</code></pre><h2 id="ejecutando-un-contenedor-interactivo">Ejecutando un contenedor interactivo</h2>
<p>Para abrir una sesión interactiva deberemos ejecutar el parámetro <code>-i</code> y con la opción <code>-t</code> nos permite usar un pseudo-terminal que nos permite interactuar con el contenedor ejecutado. También le podemos indicar un nombre con la opción <code>--name</code> y después acompañamos a este comando con el nombre de la imágen que vamos a usar, en este caso <code>ubuntu</code> y por último, ponemos el comando que vamos a ejecutar, el cual será <code>/bin/bash</code>, el cual lanzará una <code>bash</code> desde el contenedor.</p>
<pre><code>docker run -it --name contenedor1 ubuntu /bin/bash
</code></pre><ul>
<li>
<p>Resumen del comando:</p>
<ul>
<li><strong>-i:</strong> Abrir una sesión de forma interactiva</li>
<li><strong>-t:</strong> Usar una terminal</li>
<li><strong>&ndash;name [nombre]:</strong> Definimos el nombre que queremos que tenga el contenedor que vamos a ejecutar</li>
<li><strong>ubuntu:</strong> Es el nombre de la imagen que vamos a usar en este contenedor</li>
<li><strong>/bin/bash:</strong> Es el comando que va a ejecutar el contenedor cuando éste se ejecute.</li>
</ul>
</li>
</ul>
<p>Los conetedores son efímeros, es decir, nada más que el contenedor termine su trabajo, éste se para. Si queremos volver a usar un contenedor que ya hemos ejecutado con anterioridad usaremos el comando <code>start</code> y si nos queremos conectar a él usamos la opción <code>attach</code></p>
<pre><code>docker start contenedor1
docker attach contenedor1
</code></pre><p>Si el contenedor ya se está ejecutando, podemos ejecutar comandos en él con el comando <code>exec</code></p>
<pre><code>docker exec contenedor1 ls -l
</code></pre><p>Si lo que queremos es reiniciar el contenedor, solo deberemos usar el comando <code>restart</code></p>
<pre><code>docker restart contenedor1
</code></pre><p>Para ver información del contenedor</p>
<pre><code>docker inspect contenedor1
</code></pre><p>En realidad, todas las <code>imágenes docker</code> tienen definidas un proceso que se ejecuta. En la imagen <code>ubuntu</code>, por ejemplo, el proceso por defecto que se ejecuta es <code>bash</code>, por lo que podríamos haber ejecutado</p>
<pre><code>docker run -it --name contenedor1 ubuntu
</code></pre><p>Esto quiere decir que no era necesario acompañar a dicho comando con el comando del final <code>/bin/bash</code>, ya que la imagen lo ejecuta por defecto.</p>
<h2 id="creando-un-contenedor-demonio">Creando un contenedor demonio</h2>
<p>Podemos crear un contenedor demonio con la opción <code>-d</code> del comando <code>run</code>, para que el contenedor se quede corriendo en segundo plano.</p>
<pre><code>docker run -d --name contenedor2 ubuntu /bin/sh -c &quot;yes hello world&quot;
</code></pre><p>Vamos a comprobar que se está ejecutando</p>
<pre><code>docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
32d7577b9a6c        ubuntu              &quot;/bin/sh -c 'yes hel…&quot;   26 seconds ago      Up 25 seconds                           contenedor2
</code></pre><p>Podemos comprobar qué es lo que está haciendo dicho contenedor con el comando</p>
<pre><code>docker logs contenedor2
</code></pre><p>Para parar un contenedor y eliminarlo</p>
<pre><code>docker stop contenedor2
docker rm contenedor2
</code></pre><p>Comprobamos que se ha eliminado</p>
<pre><code>docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
</code></pre><p>Como no se puede eliminar un contenedor que está en ejecución , podemos forzar su eliminación con el comando</p>
<pre><code>docker rm -f contenedor2
</code></pre><h2 id="creando-un-contenedor-con-un-servidor-web">Creando un contenedor con un servidor web</h2>
<p>Tenemos muchas imágenes en el repositorio público de <strong>DockerHub</strong>. Si queremos crear un contenedor con un servidor <code>apache 2.4</code></p>
<pre><code>docker run -d --name my-apache-app -p 8080:80 httpd:2.4
</code></pre><ul>
<li><strong>-p 8080:80:</strong> Con esta opción mapeamos un puerto del equipo donde tenemos instalado <code>docker</code> con un puerto del contenedor. Para comprobar que esto funciona, podemos entrar desde nuestro navegador a la <code>IP del contenedor</code> y al <code>puerto 8080</code></li>
</ul>
<p>Podemos ver lo que está haciendo <code>apache</code> mirando los logs con el comando que hemos visto antes, pero si le añadimos la opción <code>-f</code> podremos ver los logs e3n tiempo real</p>
<pre><code>docker logs -f my-apache-app
</code></pre><h2 id="configuración-de-contenedores-con-variables-de-entorno">Configuración de contenedores con variables de entorno</h2>
<p>Ahora veremos que al crear un contenedor, dependiendo de lo que queramos hacer, requiere una configuración específica, así que crearemos variables de entorno para poder configurarlo. Para crear las variables de entorno usaremos la opción <code>-e</code> o <code>--env</code></p>
<pre><code>docker run -it --name prueba -e USUARIO=prueba ubuntu bash
root@18edc1b5414e:/# echo $USUARIO
prueba
</code></pre><p>En algunas ocasiones, es necesario inicializar alguna variable de entorno para que el contenedor pueda ser ejecutado. Si miramos la <a href="https://hub.docker.com/_/mariadb">documentación</a> en DockerHub de la imagen de <code>mariadb</code>, vemos que podemos definir algunas variables de entorno como pueden ser: <code>MYSQL_DATABASE</code>, <code>MYSQL_USER</code>, <code>MYSQL_PASSWORD</code>, etc&hellip; pero una de ellas hay que indicarlas de manera obligatoria para poder ejecutar dicho contenedor y esa variable es la contraseña del usuario <code>root</code> (<code>MYSQL_ROOT_PASSWORD</code>), por lo tanto, el comando de ejecución del contenedor con la imagen de <code>mariadb</code> es</p>
<pre><code>docker run --name contenedor_mariadb -e MYSQL_ROOT_PASSWORD=root -d mariadb
</code></pre><p>Podemos verificar que está funcionando</p>
<pre><code>docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
0922f9029852        mariadb             &quot;docker-entrypoint.s…&quot;   6 seconds ago       Up 4 seconds        3306/tcp            contenedor_mariadb
</code></pre><p>Entre todas las veriables de entorno que tiene definidas por defecto la imagen de <code>mariadb</code>, podemos encontrar la variable <code>MYSQL_ROOT_PASSWORD</code> con el valor <code>root</code> que le hemos definido. Para ver todas las variables de entorno de un contenedor podemos ejecutar el siguiente comando</p>
<pre><code>docker exec -it contenedor_mariadb env
[...]
MYSQL_ROOT_PASSWORD=root
[...]
</code></pre><p>Y si queremos acceder a dicha máquina para comprobar que podemos acceder a la base de datos con esa contraseña, podemos ejecutar</p>
<pre><code>root@0922f9029852:/# mysql -u root -p$MYSQL_ROOT_PASSWORD
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 4
Server version: 10.5.8-MariaDB-1:10.5.8+maria~focal mariadb.org binary distribution

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]&gt;
</code></pre><h1 id="ejercicios">Ejercicios</h1>
<ol>
<li><strong>Instala un docker en una máquina y configúralo para que se pueda acceder sin privilegios</strong></li>
</ol>
<ul>
<li>Instalación</li>
</ul>
<pre><code>sudo apt-get install docker.io
</code></pre><ul>
<li>Configuración para acceder sin privilegios</li>
</ul>
<pre><code>sudo usermod -aG docker juanan
</code></pre><ol start="2">
<li><strong>Crea un contenedor interactivo desde una imagen debian. Instala un paquete (por ejemplo <code>nano</code>). Sal de la terminal, ¿sigue el contenedor corriendo?¿Por qué? Vuelve a iniciar el contenedor y accede de nuevo a él de forma interactiva. ¿Sigue instalado el <code>nano</code>? Sal del contenedor y bórralo. Crea un nuevo contenedor interactivo desde la misma imagen. ¿Tiene el <code>nano</code> instalado?</strong></li>
</ol>
<ul>
<li>Creo un contenedor interactivo con la imagen <code>debian</code></li>
</ul>
<pre><code>docker run -it --name contenedor_debian debian /bin/bash
</code></pre><ul>
<li>Instalo <code>nano</code> en el contenedor</li>
</ul>
<pre><code>root@e0e5f5265ae7:/# apt-get update
root@e0e5f5265ae7:/# apt-get install nano
</code></pre><ul>
<li>Salgo de la terminal y compruebo si el contenedor sigue corriendo</li>
</ul>
<pre><code>root@e0e5f5265ae7:/# exit
exit
juanan@juananpc:~$ docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
</code></pre><pre><code>* El `contenedor` no sigue corriendo porque los `contenedores docker` son efímeros y cuando terminan su función principal, estos se paran y se quedan guardados, pero parados. Podemos ver los contenedores que están creados, pero parados con el comando `ps -a`
</code></pre>
<pre><code>juanan@juananpc:~$ docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                          PORTS               NAMES
e0e5f5265ae7        debian              &quot;/bin/bash&quot;         3 minutes ago       Exited (0) About a minute ago                       contenedor_debian
</code></pre><ul>
<li>Vuelvo a iniciar el contenedor y accedo a él de forma interactiva</li>
</ul>
<pre><code>juanan@juananpc:~$ docker start contenedor_debian
contenedor_debian
juanan@juananpc:~$ docker attach contenedor_debian
root@e0e5f5265ae7:/# whereis nano
nano: /bin/nano /usr/share/nano /usr/share/man/man1/nano.1.gz /usr/share/info/nano.info.gz
</code></pre><pre><code>* Al volver a iniciar el contenedor sí que sigue teniendo instalado `nano`
</code></pre>
<ul>
<li>Salgo del contenedor, lo borro, vuelvo a crear un nuevo contenedor con la misma imagen y compruebo si tiene <code>nano</code> instalado</li>
</ul>
<pre><code>root@e0e5f5265ae7:/# exit
exit
juanan@juananpc:~$ docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
juanan@juananpc:~$ docker rm contenedor_debian
contenedor_debian
juanan@juananpc:~$ docker run -it --name contenedor_debian2 debian /bin/bash
root@cc6520b717b2:/# whereis nano
nano:
</code></pre><pre><code>* No tiene `nano` instalado, ya que hemos eliminado el contenedor entero y éste no tenía ningún dispositivo de almacenamiento.
</code></pre>
<ol start="3">
<li><strong>Crea un contenedor demonio con un servidor <code>nginx</code>. Al crear el contenedor, ¿has tenido que indicar algún comando para que lo ejecute? Accede al navegador web y comprueba que el servidor está funcionando. Muestra los logs del contenedor.</strong></li>
</ol>
<ul>
<li>Creo un contenedor demonio con una imagen de nginx</li>
</ul>
<pre><code>docker run -p 8080:80 --name docker_nginx -d nginx
</code></pre><pre><code>* No, no he tenido que ejecutar ningún comando para que el contenedor ejecute el servicio de `nginx` al ser creado.
</code></pre>
<ul>
<li>
<p>Accedo a mi navegador web y compruebo que está ejecutando el servicio de <code>nginx</code>. A esta página web podemos acceder de tres formas:</p>
<ul>
<li>A través de la ip del contenedor, para ello deberemos averiguarla con el siguiente comando</li>
</ul>
</li>
</ul>
<pre><code>docker inspect docker_nginx
[...]
&quot;IPAddress&quot;: &quot;172.17.0.2&quot;,
[...]
</code></pre><pre><code>* A través de nuestra ip de la tarjeta de red y poniendo al final `:8080`

* A través de nuestra ip de `loopback` y el puerto `:8080` (`127.0.0.1:8080`)
</code></pre>
<p><img src="/Docker/Documentacion/1.png" alt="Captura 1"></p>
<ul>
<li>Muestro los logs del contenedor</li>
</ul>
<pre><code>juanan@juananpc:~$ docker logs docker_nginx
/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
172.17.0.1 - - [22/Feb/2021:20:29:17 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36&quot; &quot;-&quot;
172.17.0.1 - - [22/Feb/2021:20:29:17 +0000] &quot;GET /favicon.ico HTTP/1.1&quot; 404 555 &quot;http://192.168.1.112:8080/&quot; &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36&quot; &quot;-&quot;
2021/02/22 20:29:17 [error] 30#30: *2 open() &quot;/usr/share/nginx/html/favicon.ico&quot; failed (2: No such file or directory), client: 172.17.0.1, server: localhost, request: &quot;GET /favicon.ico HTTP/1.1&quot;, host: &quot;192.168.1.112:8080&quot;, referrer: &quot;http://192.168.1.112:8080/&quot;
172.17.0.1 - - [22/Feb/2021:20:29:22 +0000] &quot;GET / HTTP/1.1&quot; 200 612 &quot;-&quot; &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36&quot; &quot;-&quot;
2021/02/22 20:29:22 [error] 30#30: *4 open() &quot;/usr/share/nginx/html/favicon.ico&quot; failed (2: No such file or directory), client: 172.17.0.1, server: localhost, request: &quot;GET /favicon.ico HTTP/1.1&quot;, host: &quot;127.0.0.1:8080&quot;, referrer: &quot;http://127.0.0.1:8080/&quot;
172.17.0.1 - - [22/Feb/2021:20:29:22 +0000] &quot;GET /favicon.ico HTTP/1.1&quot; 404 555 &quot;http://127.0.0.1:8080/&quot; &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36&quot; &quot;-&quot;
</code></pre><ol start="4">
<li><strong>Crea un contenedor con la aplicación <code>Nextcloud</code>, mirando la documentación de DockerHub, para personalizar el nombre de la base de datos sqlite que va a utilizar</strong></li>
</ol>
<ul>
<li>Creo un contenedor con la imagen de <code>Nextcloud</code> con la variable de entorno <code>SQLITE_DATABASE</code> cuyo nombre va a ser <code>juanan_db</code></li>
</ul>
<pre><code>docker run -p 8080:80 --name docker_nextcloud -e SQLITE_DATABASE=juanan_db -d nextcloud
</code></pre><ul>
<li>Comprobamos que funciona
<img src="/Docker/Documentacion/2.png" alt="Captura 2"></li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Configuración de VPN con clave secreta</title>
            <link>https://juanan219.github.io/posts/2021/02/configuraci%C3%B3n-de-vpn-con-clave-secreta/</link>
            <pubDate>Mon, 22 Feb 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/02/configuraci%C3%B3n-de-vpn-con-clave-secreta/</guid>
            <description>Configuración de openVPN de acceso remoto con clave estática compartida Vamos a levantar un escenario en OpenStack con una receta de heat. En este ejercico, vamos a configurar una VPN basada en SSL/TLS usando OpenVPN.
Configuración Tenemos dos máquinas debian, una que va a actuar como Router llamada vpn_server y la otra como cliente, llamada lan. Para comenzar a realizar el ejercicio, vamos a activar el bit de forward para que nuestra máquina lan pueda acceder a internet a través de vpn_server, para ello cambiamos el valor 0 por el valor 1 del fichero /proc/sys/net/ipv4/ip_forward y creamos una regla NAT en iptables</description>
            <content type="html"><![CDATA[<h2 id="configuración-de-openvpn-de-acceso-remoto-con-clave-estática-compartida">Configuración de openVPN de acceso remoto con clave estática compartida</h2>
<p>Vamos a levantar un escenario en OpenStack con una <a href="https://fp.josedomingo.org/seguridadgs/u04/escenario_vpn.yaml">receta de heat</a>. En este ejercico, vamos a configurar una VPN basada en SSL/TLS usando OpenVPN.</p>
<h2 id="configuración">Configuración</h2>
<p>Tenemos dos máquinas debian, una que va a actuar como Router llamada <code>vpn_server</code> y la otra como cliente, llamada <code>lan</code>. Para comenzar a realizar el ejercicio, vamos a activar el bit de forward para que nuestra máquina <code>lan</code> pueda acceder a internet a través de <code>vpn_server</code>, para ello cambiamos el valor <code>0</code> por el valor <code>1</code> del fichero <code>/proc/sys/net/ipv4/ip_forward</code> y creamos una regla <code>NAT</code> en <code>iptables</code></p>
<pre><code>sudo nano /proc/sys/net/ipv4/ip_forward

1

sudo iptables -t nat -A POSTROUTING -s 192.168.100.0/24 -j MASQUERADE
</code></pre><p>Por último nos conectamos a <code>lan</code> y comprobamos que tiene conexión con el exterior</p>
<pre><code>ssh 192.168.100.10

ping www.google.es
PING www.google.es (216.58.209.67) 56(84) bytes of data.
64 bytes from waw02s06-in-f67.1e100.net (216.58.209.67): icmp_seq=1 ttl=112 time=180 ms
--- www.google.es ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 180.366/180.366/180.366/0.000 ms
</code></pre><p>Ahora que tenemos nuestro escenario funcionando, vamos a comenzar a montar nuestra <code>VPN</code>, así que para empezar vamos a instalar <code>OpenVPN</code> en nuestra máquina como el <code>vpn_server</code></p>
<pre><code>sudo apt-get install openvpn
</code></pre><p>El siguiente paso sería decidir cómo se va a realizar la autenticación de los extremos y el cifrado. En este ejercicio realizaremos la forma más sencilla, que es usar una <strong>clave compartida (pre-shared key)</strong>, aunque el uso de certificados es más seguro.</p>
<h2 id="generación-de-la-clave">Generación de la clave</h2>
<p>Generamos la clave</p>
<pre><code>sudo openvpn --genkey --secret clave.key
</code></pre><h2 id="configuración-del-servidor">Configuración del servidor</h2>
<p>Movemos la clave generada al directorio <code>/etc/openvpn</code> y creamos el archivo <code>/etc/openvpn/server.conf</code></p>
<pre><code>mv clave.key /etc/openvpn

sudo nano /etc/openvpn/server.conf

dev tun
ifconfig 10.10.10.1 10.10.10.2
secret clave.key
</code></pre><h2 id="configuración-del-cliente">Configuración del cliente</h2>
<p>Ahora vamos a pasar a la confgiuración del cliente y lo primero que haremos será instalar <code>openvpn</code> y copiar en el directorio <code>/etc/openvpn</code> del cliente la clave generada anteriormente.</p>
<pre><code>debian@lan:~$ sudo apt-get install openvpn

debian@vpn-server:~$ scp clave.key debian@192.168.100.10:/home/debian

debian@lan:~$ sudo cp clave.key /etc/openvpn/
</code></pre><p>Ahora que tenemos todo preparado, vamos a crear un fichero de configuración en el cliente en la ruta <code>/etc/openvpn</code> llamado <code>client.conf</code> y le introducimos la siguiente configuración</p>
<pre><code>sudo nano /etc/openvpn/client.conf

remote 172.22.201.64
dev tun
ifconfig 10.10.10.2 10.10.10.1
route 192.168.100.0 255.255.255.0
secret clave.key
</code></pre><ul>
<li><strong>remote:</strong> Aquí introducimos la IP de la interfaz de red que accede a internet del servidor VPN (en mi caso sería la 172.22.201.64).</li>
<li><strong>ifconfig:</strong> Introducimos las IP de las interfaces de túnel. No tienen que coincidir con las IP de nuetra red. (En este caso les he puesto la 10.10.10.1 y 10.10.10.2)</li>
<li><strong>route:</strong> Añade a la tabla de encaminamiento del cliente una entrada que permita acceder a los recursos de la red local remota (En este ejemplo nuestra red es la <code>192.168.100.0/24</code>).</li>
</ul>
<h2 id="establecimiento-de-la-vpn">Establecimiento de la VPN</h2>
<p>Para establecer la <code>VPN</code> hay que arrancar <code>OpenVPN</code> en ambos extremos y configuramos <code>OpenVPN</code> para que lea los archivos <code>*.conf</code> del directorio <code>/etc/openvpn</code>, así que para configurar esto deberemos editar el fichero <code>/etc/default/openvpn</code> y descomentamops la línea <code>AUTOSTART=&quot;all&quot;</code> y reiniciamos los siguientes servicios</p>
<pre><code>debian@vpn-server:~$ sudo nano /etc/default/openvpn
[...]
AUTOSTART=&quot;all&quot;
[...]
debian@vpn-server:~$ sudo systemctl daemon-reload
debian@vpn-server:~$ sudo systemctl start openvpn

debian@lan:~$ sudo nano /etc/default/openvpn
[...]
AUTOSTART=&quot;all&quot;
[...]
debian@lan:~$ sudo systemctl daemon-reload
debian@lan:~$ sudo systemctl start openvpn
</code></pre><p>Cuando se haya establecido la VPN se habrá creado una interfaz de tipo túnel en ambas máquinas que simulan un enlace PPP. Vamos a compro bar que se han creado las interfaces de red de tipo túnel.</p>
<pre><code>debian@vpn-server:~$ ip a
[...]
4: tun0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UNKNOWN group default qlen 100
    link/none 
    inet 10.10.10.1 peer 10.10.10.2/32 scope global tun0
       valid_lft forever preferred_lft forever
    inet6 fe80::8894:d8a4:ed6a:37a3/64 scope link stable-privacy 
       valid_lft forever preferred_lft forever

debian@lan:~$ ip a
[...]
3: tun0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UNKNOWN group default qlen 100
    link/none 
    inet 10.10.10.2 peer 10.10.10.1/32 scope global tun0
       valid_lft forever preferred_lft forever
    inet6 fe80::e3cb:45d6:17ab:7fb3/64 scope link stable-privacy 
       valid_lft forever preferred_lft forever
</code></pre><p>A parte de las interfaces de red, se han creado también las reglas en la tabla de encaminamiento, que permiten el tráfico con la máquina <code>10.10.10.1</code> y con la red remota <code>192.168.100.0/24</code></p>
<pre><code>debian@vpn-server:~$ sudo ip r
default via 10.0.0.1 dev eth0 
10.0.0.0/24 dev eth0 proto kernel scope link src 10.0.0.7 
10.10.10.2 dev tun0 proto kernel scope link src 10.10.10.1 
169.254.169.254 via 10.0.0.1 dev eth0 
192.168.100.0/24 dev eth1 proto kernel scope link src 192.168.100.2

debian@lan:~$ sudo ip r
default via 192.168.100.2 dev eth0 
10.10.10.1 dev tun0 proto kernel scope link src 10.10.10.2 
169.254.169.254 via 192.168.100.1 dev eth0 
192.168.100.0/24 dev eth0 proto kernel scope link src 192.168.100.10
</code></pre><p>A partir de este momento el cliente podría usar todos los recursos de nuestra red local de forma segura, ya que todo el tráfico que pase por ahí irá cifrado a través del túnel.</p>
]]></content>
        </item>
        
        <item>
            <title>Apuntes de Proxy, Proxy Inverso y Balanceador de carga</title>
            <link>https://juanan219.github.io/posts/2021/02/apuntes-de-proxy-proxy-inverso-y-balanceador-de-carga/</link>
            <pubDate>Fri, 19 Feb 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/02/apuntes-de-proxy-proxy-inverso-y-balanceador-de-carga/</guid>
            <description>Proxy/Caché   Proxy: Proporcionaconexión a internet cuando no tenemos enrutadores / NAT. Por lo tanto gestiona la comunicación HTTP y la podemos filtrar.
  Caché: Guarda ficheros de internet para que las futuras búsquedas de esos ficheros en la red no sea necesario volver a descargarlos de internet, sino descargarlosn directamente desde el proxy.
  Herramientas   DansGuardian: es un software de filtro de contenido, diseñado para controlar el acceso a sitios web.</description>
            <content type="html"><![CDATA[<h2 id="proxycaché">Proxy/Caché</h2>
<ul>
<li>
<p><strong>Proxy:</strong> Proporcionaconexión a internet cuando no tenemos enrutadores / NAT. Por lo tanto gestiona la comunicación HTTP y la podemos filtrar.</p>
</li>
<li>
<p><strong>Caché:</strong> Guarda ficheros de internet para que las futuras búsquedas de esos ficheros en la red no sea necesario volver a descargarlos de internet, sino descargarlosn directamente desde el proxy.</p>
</li>
</ul>
<h3 id="herramientas">Herramientas</h3>
<ul>
<li>
<p><strong>DansGuardian:</strong> es un software de filtro de contenido, diseñado para controlar el acceso a sitios web.</p>
</li>
<li>
<p><strong>Sarg (Squid Analysis Report Generator):</strong> es una herramienta que permite a los administradores de sistemas ver de una manera sencilla y amigable qué sitios de Internet visitan los usuarios de la red local usando los logs de Squid.</p>
</li>
</ul>
<h2 id="proxy-inverso">Proxy inverso</h2>
<ul>
<li>
<p>Un proxy inverso es un tipo de servidor proxy que recupera los recursos en nombre de un cliente desde uno o más servidores. Por lo tanto el cliente hace la petición al puerto 80 del proxy y éste es el que hace la petición al servidor web que normalmente está en una red interna no accesible desde el cliente.</p>
</li>
<li>
<p>Un proxy inverso también  puede teer funciones de <strong>caché</strong> cuando es capaz de guardar informaiṕon de los servidores internos y ofrecerla en las próximas peticiones.</p>
</li>
<li>
<p>Teienen proxy inverso <code>apache2</code>, <code>nginx</code>, <code>varnish</code>, <code>traefikck</code>, etc&hellip;</p>
</li>
</ul>
<h2 id="balanceador-de-varga">Balanceador de varga</h2>
<ul>
<li>Un <strong>Balanceador de carga</strong> fundamentalmente es un dispositivo de hardware o software que se pone al frente de un conjunto de servidores que atienden a una aplicación y tal como su nombre lo indica, asigna o balancea las solicitudes que llegan de los clientes a los servidores usando algún algoritmo.</li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Rendimiento de servidor Web con caché Varnish</title>
            <link>https://juanan219.github.io/posts/2021/02/rendimiento-de-servidor-web-con-cach%C3%A9-varnish/</link>
            <pubDate>Fri, 19 Feb 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/02/rendimiento-de-servidor-web-con-cach%C3%A9-varnish/</guid>
            <description>Según las pruebas de rendimiento que se han realizado con el comando ab a varias configuraciones de servidores webs sirviendo un Wordpress, la mejor configuración para este tipo de escenarios es PHP-FPM (Socket Unix) + NGINX.
El comando usado para las pruebas es el siguiente:
ab -t 10 -c 200 -k http://172.22.x.x/wordpress/index.phpAumento de rendimiento en la ejecución de scripts PHP  Tarea 1:  Vamos a configurar una máquina con la configuración ganadora: PHP-FPM (Socket Unix) + NGINX.</description>
            <content type="html"><![CDATA[<p>Según las pruebas de rendimiento que se han realizado con el comando <code>ab</code> a varias configuraciones de servidores webs sirviendo un Wordpress, la mejor configuración para este tipo de escenarios es <code>PHP-FPM (Socket Unix) + NGINX</code>.</p>
<p>El comando usado para las pruebas es el siguiente:</p>
<pre><code>ab -t 10 -c 200 -k http://172.22.x.x/wordpress/index.php
</code></pre><h2 id="aumento-de-rendimiento-en-la-ejecución-de-scripts-php">Aumento de rendimiento en la ejecución de scripts PHP</h2>
<ul>
<li><strong>Tarea 1:</strong></li>
</ul>
<p>Vamos a configurar una máquina con la configuración ganadora: <code>PHP-FPM (Socket Unix) + NGINX</code>. Para ello vamos a ejecutar una <a href="https://github.com/josedom24/ansible_nginx_fpm_php">receta de ansible</a> y vamos a terminar la configuración del sitio.</p>
<p>Primero instalamos <code>ansible</code> y <code>git</code></p>
<pre><code>sudo apt-get update
sudo apt-get install ansible
sudo apt-get install git
</code></pre><p>Clonamos el repositorio</p>
<pre><code>mkdir GitHub
cd GitHub/
git clone https://github.com/josedom24/ansible_nginx_fpm_php
</code></pre><p>He creado una máquina en <code>vagrant</code> con la ip <code>192.168.1.113</code> y he modificado el fichero hosts del repositorio que acabo de clonar y he cambiadp la IP que trae configurada, por la ip de mi máquina</p>
<pre><code>nano hosts

[servidores_web]
nodo1 ansible_ssh_host=172.22.201.58 ansible_python_interpreter=/usr/bin/python3
</code></pre><p>También he cambiado el usuario remoto y he añadido la clave de vagrant a <code>ssh-agent</code></p>
<pre><code>nano ansible.cfg

[defaults]
inventory = hosts
remote_user = vagrant
host_key_checking = False

ssh-add .vagrant/machines/server/virtualbox/private_key
</code></pre><p>ab -t 10 -c 200 -k http:/127.0.0.1/wordpress/index.php
Ejecutamos el playbook y esperamos a que termine todo el proceso</p>
<pre><code>ansible-playbook site.yaml
</code></pre><p>Esta es la configuración de wordpress
<a href="https://www.youtube.com/watch?v=W3i6eIJQ89M"><img src="https://i.ytimg.com/vi/W3i6eIJQ89M/maxresdefault.jpg" alt="Vídeo"></a></p>
<ul>
<li><strong>Tarea 2:</strong></li>
</ul>
<p>Ahora vamos a realizar las pruebas de rendimiento desde la misma máquina, es decir, vamos a ejecutar instrucciones similares a:</p>
<pre><code>ab -t 10 -c 200 -k http:/127.0.0.1/wordpress/index.php
</code></pre><p>Pero antes de usar ese comando deberemos instalar el paquete en el que se encuentra, en este caso es <code>apache2-utils</code></p>
<pre><code>sudo apt-get install apache2-utils
</code></pre><ul>
<li>
<p>Vamos a realizar dicha prueba con diferentes valores de concurrencia:</p>
<ul>
<li><strong>50:</strong></li>
</ul>
</li>
</ul>
<pre><code>ab -t 10 -c 50 -k http:/127.0.0.1/wordpress/index.php
[...]
Requests per second:    115.25 [#/sec] (mean)
[...]
</code></pre><pre><code>* **100:**
</code></pre>
<pre><code>ab -t 10 -c 100 -k http://127.0.0.1/wordpress/index.php
[...]
Requests per second:    127.95 [#/sec] (mean)
[...]
</code></pre><pre><code>* **200:**
</code></pre>
<pre><code>ab -t 10 -c 200 -k http://127.0.0.1/wordpress/index.php
[...]
Requests per second:    9519.44 [#/sec] (mean)
[...]
</code></pre><pre><code>* **250:**
</code></pre>
<pre><code>ab -t 10 -c 250 -k http://127.0.0.1/wordpress/index.php
[...]
Requests per second:    8189.23 [#/sec] (mean)
[...]
</code></pre><pre><code>* **500:**
</code></pre>
<pre><code>ab -t 10 -c 500 -k http://127.0.0.1/wordpress/index.php
[...]
Requests per second:    9385.39 [#/sec] (mean)
[...]
</code></pre><p>La media de las respuestas por segundo es de 5444,402.</p>
<ul>
<li><strong>Tarea 3:</strong></li>
</ul>
<p>Ahora vamos a configurar la <code>caché Varnish</code>, la cual es un proxy inverso que estará escuchando en el puerto 80 y se va a comunicar con el servidor web por el puerto 8080. Para instalar <code>Varnish</code> simplemente lo podemos hacer con apt</p>
<pre><code>sudo apt-get install varnish
</code></pre><p>Una vez instalado <code>varnish</code> en nuestra máquina, editaremos el fichero <code>/etc/default/varnish</code> para configurar el demonio y que escuche desde el puerto 80 por la interfaz pública del servidor.</p>
<pre><code>sudo nano /etc/default/varnish
[...]
DAEMON_OPTS=&quot;-a :80 \
             -T localhost:6082 \
             -f /etc/varnish/default.vcl \
             -S /etc/varnish/secret \
             -s malloc,1G&quot;
[...]
</code></pre><p>Ahora modificaremos la unidad de <code>systemd</code> para que <code>varnish</code> arranque en el puerto 80, para ello vamos a editar el fichero <code>/lib/systemd/system/varnish.service</code> y modificamos al siguiente línea:</p>
<pre><code>ExecStart=/usr/sbin/varnishd -j unix,user=vcache -F -a :80 -T localhost:6082 -f /etc/varnish/default.vcl -S /etc/varnish/secret -s malloc,1G
</code></pre><p>Por último modificamos el fichero <code>/etc/varnish/default.vcl</code> para que este coja el <code>puerto 8080</code>, en el cual vamos a poner a escucha a nuestro servidor <code>nginx</code></p>
<pre><code>sudo nano /etc/varnish/default.vcl
[...]
backend default {
    .host = &quot;127.0.0.1&quot;;
    .port = &quot;8080&quot;;
}
[...]
</code></pre><p>Y reiniciamos tanto <code>varnish</code> como <code>systemd</code></p>
<pre><code>sudo systemctl daemon-reload
sudo systemctl restart varnish
</code></pre><p>Ahora vamos a modificar nuestro virtualhost, lo pondremos a escuchar en el <code>puerto 8080</code> y recargamos el servicio</p>
<pre><code>sudo nano /etc/nginx/sites-available/default
server {
        listen 8080 ;
[...]

sudo systemctl restart nginx.service
</code></pre><p>Comprobamos que varnish está escuchando en el <code>puerto 80</code> y nginx está en el <code>puerto 8080</code></p>
<pre><code>sudo netstat -putan
[...]
tcp        0      0 0.0.0.0:8080            0.0.0.0:*               LISTEN      700/nginx: master p 
tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      378/varnishd
[...]
</code></pre><p>Ahora que lo tenemos todo funcionando, vamos a volver a realizar las mismas pruebas de concurrencia de antes y vamos a comparar los resultados</p>
<ul>
<li><strong>50:</strong></li>
</ul>
<pre><code>ab -t 10 -c 50 -k http://127.0.0.1/
[...]
Requests per second:    17403.75 [#/sec] (mean)
[...]
</code></pre><ul>
<li><strong>100:</strong></li>
</ul>
<pre><code>ab -t 10 -c 100 -k http://127.0.0.1/
[...]
Requests per second:    16256.04 [#/sec] (mean)
[...]
</code></pre><ul>
<li><strong>200:</strong></li>
</ul>
<pre><code>ab -t 10 -c 200 -k http://127.0.0.1/
[...]
Requests per second:    14731.21 [#/sec] (mean)
[...]
</code></pre><ul>
<li><strong>250:</strong></li>
</ul>
<pre><code>ab -t 10 -c 250 -k http://127.0.0.1/
[...]
Requests per second:    15370.86 [#/sec] (mean)
[...]
</code></pre><p>La media de peticiones con <code>varnish</code> es de 15940,465 peticiones por segundo, mientras que sin él la media era de 5444,402 peticiones por segundo.</p>
<p>Si comprobamos el fichero <code>/var/log/nginx/access.log</code> podemos ver que sólo se registra en el log la primera petición, ya que las siguientes peticiones las gestiona varnish.</p>
<pre><code>sudo tail /var/log/nginx/access.log
[...]
127.0.0.1 - - [19/Feb/2021:09:39:27 +0000] &quot;GET /wordpress/index.php HTTP/1.1&quot; 301 5 &quot;-&quot; &quot;ApacheBench/2.3&quot;
127.0.0.1 - - [19/Feb/2021:09:39:36 +0000] &quot;GET / HTTP/1.1&quot; 200 3488 &quot;-&quot; &quot;ApacheBench/2.3&quot;
127.0.0.1 - - [19/Feb/2021:09:41:49 +0000] &quot;GET / HTTP/1.1&quot; 200 3488 &quot;-&quot; &quot;ApacheBench/2.3&quot;
127.0.0.1 - - [19/Feb/2021:09:46:56 +0000] &quot;GET / HTTP/1.1&quot; 200 3488 &quot;-&quot; &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36&quot;
127.0.0.1 - - [19/Feb/2021:09:47:06 +0000] &quot;GET /favicon.ico HTTP/1.1&quot; 404 199 &quot;http://www.juanan.es/&quot; &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36&quot;
</code></pre><p>Los registros de <code>varnish</code> se guardan en el fichero <code>/var/log/varnish/varnishncsa.log</code></p>
<pre><code>sudo tail /var/log/varnish/varnishncsa.log
127.0.0.1 - - [19/Feb/2021:09:42:55 +0000] &quot;GET http://127.0.0.1/ HTTP/1.0&quot; 200 8667 &quot;-&quot; &quot;ApacheBench/2.3&quot;
127.0.0.1 - - [19/Feb/2021:09:42:55 +0000] &quot;GET http://127.0.0.1/ HTTP/1.0&quot; 200 8667 &quot;-&quot; &quot;ApacheBench/2.3&quot;
127.0.0.1 - - [19/Feb/2021:09:42:55 +0000] &quot;GET http://127.0.0.1/ HTTP/1.0&quot; 200 8667 &quot;-&quot; &quot;ApacheBench/2.3&quot;
127.0.0.1 - - [19/Feb/2021:09:42:55 +0000] &quot;GET http://127.0.0.1/ HTTP/1.0&quot; 200 8667 &quot;-&quot; &quot;ApacheBench/2.3&quot;
127.0.0.1 - - [19/Feb/2021:09:42:55 +0000] &quot;GET http://127.0.0.1/ HTTP/1.0&quot; 200 8667 &quot;-&quot; &quot;ApacheBench/2.3&quot;
127.0.0.1 - - [19/Feb/2021:09:42:55 +0000] &quot;GET http://127.0.0.1/ HTTP/1.0&quot; 200 8667 &quot;-&quot; &quot;ApacheBench/2.3&quot;
127.0.0.1 - - [19/Feb/2021:09:42:55 +0000] &quot;GET http://127.0.0.1/ HTTP/1.0&quot; 200 8667 &quot;-&quot; &quot;ApacheBench/2.3&quot;
172.22.4.124 - - [19/Feb/2021:09:46:56 +0000] &quot;GET http://www.juanan.es/ HTTP/1.1&quot; 200 3476 &quot;-&quot; &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36&quot;
172.22.4.124 - - [19/Feb/2021:09:47:06 +0000] &quot;GET http://www.juanan.es/favicon.ico HTTP/1.1&quot; 404 188 &quot;http://www.juanan.es/&quot; &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36&quot;
172.22.4.124 - - [19/Feb/2021:09:47:40 +0000] &quot;GET http://www.juanan.es/ HTTP/1.1&quot; 200 3476 &quot;-&quot; &quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36&quot;
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Practica iSCSI</title>
            <link>https://juanan219.github.io/posts/2021/02/practica-iscsi/</link>
            <pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/02/practica-iscsi/</guid>
            <description>Creación de targets en Linux Primero vamos a crear un target con una LUN, para ello primero vamos a instalar el paquete tgt en el servidor
sudo apt-get install tgt Ahora vamos a definir dos targets, uno para un cliente Linux y otro para un cliente Windows. Para definirlos de forma persistente, deberemos editar el fichero /etc/tgt/targets.conf y reiniciamos el servicio tgt
sudo nano etc/tgt/targets.conf [...] &amp;lt;target iqn.2021-02.es.juanan:target1&amp;gt; backing-store /dev/sdb &amp;lt;/target&amp;gt; &amp;lt;target iqn.</description>
            <content type="html"><![CDATA[<h2 id="creación-de-targets-en-linux">Creación de targets en Linux</h2>
<p>Primero vamos a crear un target con una LUN, para ello primero vamos a instalar el paquete <code>tgt</code> en el servidor</p>
<pre><code>sudo apt-get install tgt
</code></pre><p>Ahora vamos a definir dos targets, uno para un cliente Linux y otro para un cliente Windows. Para definirlos de forma persistente, deberemos editar el fichero <code>/etc/tgt/targets.conf</code> y reiniciamos el servicio <code>tgt</code></p>
<pre><code>sudo nano etc/tgt/targets.conf
[...]
&lt;target iqn.2021-02.es.juanan:target1&gt;
        backing-store /dev/sdb
&lt;/target&gt;
&lt;target iqn.2021-02.es.juanan:target2&gt;
        backing-store /dev/sdc
&lt;/target&gt;

sudo systemctl restart tgt
</code></pre><p>Podemos ver los targets con el siguiente comando</p>
<pre><code>sudo tgtadm --lld iscsi --op show  --mode target

Target 1: iqn.2021-02.es.juanan:target1
    System information:
        Driver: iscsi
        State: ready
    I_T nexus information:
    LUN information:
        LUN: 0
            Type: controller
            SCSI ID: IET     00010000
            SCSI SN: beaf10
            Size: 0 MB, Block size: 1
            Online: Yes
            Removable media: No
            Prevent removal: No
            Readonly: No
            SWP: No
            Thin-provisioning: No
            Backing store type: null
            Backing store path: None
            Backing store flags: 
        LUN: 1
            Type: disk
            SCSI ID: IET     00010001
            SCSI SN: beaf11
            Size: 1074 MB, Block size: 512
            Online: Yes
            Removable media: No
            Prevent removal: No
            Readonly: No
            SWP: No
            Thin-provisioning: No
            Backing store type: rdwr
            Backing store path: /dev/sdb
            Backing store flags: 
    Account information:
    ACL information:
        ALL
Target 2: iqn.2021-02.es.juanan:target2
    System information:
        Driver: iscsi
        State: ready
    I_T nexus information:
    LUN information:
        LUN: 0
            Type: controller
            SCSI ID: IET     00020000
            SCSI SN: beaf20
            Size: 0 MB, Block size: 1
            Online: Yes
            Removable media: No
            Prevent removal: No
            Readonly: No
            SWP: No
            Thin-provisioning: No
            Backing store type: null
            Backing store path: None
            Backing store flags: 
        LUN: 1
            Type: disk
            SCSI ID: IET     00020001
            SCSI SN: beaf21
            Size: 1074 MB, Block size: 512
            Online: Yes
            Removable media: No
            Prevent removal: No
            Readonly: No
            SWP: No
            Thin-provisioning: No
            Backing store type: rdwr
            Backing store path: /dev/sdc
            Backing store flags: 
    Account information:
    ACL information:
        ALL
</code></pre><p>Ahora nos vamos a conectar al cliente Linux e instalaremos la herramienta <code>open-iscsi</code></p>
<pre><code>sudo apt-get install open-iscsi
</code></pre><p>Como podemos ver, esta máquina tiene solo 1 disco duro</p>
<pre><code>lsblk -f
NAME   FSTYPE LABEL UUID                                 FSAVAIL FSUSE% MOUNTPOINT
sda                                                                     
├─sda1 ext4         983742b1-65a8-49d1-a148-a3865ea09e24   16.1G     7% /
├─sda2                                                                  
└─sda5 swap         04559374-06db-46f1-aa31-e7a4e6ec3286                [SWAP]
</code></pre><p>Vamos a buscar los targets disponibles</p>
<pre><code>sudo iscsiadm --mode discovery --type sendtargets --portal server
192.168.1.113:3260,1 iqn.2021-02.es.juanan:target1
192.168.1.113:3260,1 iqn.2021-02.es.juanan:target2
</code></pre><p>Cuando sepamos los targets que tiene el servidor <code>server</code> disponibles, podemos conectarnos, ya que no tienen autenticación, de momento</p>
<pre><code>sudo iscsiadm --mode node -T iqn.2021-02.es.juanan:target1 --portal server --login
</code></pre><p>Después del comando anterior, esta es la nueva salida de <code>lsblk -f</code></p>
<pre><code>lsblk -f
NAME   FSTYPE LABEL UUID                                 FSAVAIL FSUSE% MOUNTPOINT
sda                                                                     
├─sda1 ext4         983742b1-65a8-49d1-a148-a3865ea09e24   16.1G     7% /
├─sda2                                                                  
└─sda5 swap         04559374-06db-46f1-aa31-e7a4e6ec3286                [SWAP]
sdb
</code></pre><p>Le damos formato y lo montamos</p>
<pre><code>sudo mkfs.ext4 /dev/sdb
mke2fs 1.44.5 (15-Dec-2018)
Creating filesystem with 262144 4k blocks and 65536 inodes
Filesystem UUID: 97ec7dd7-1a01-4ab9-8572-4607066b6f2b
Superblock backups stored on blocks: 
	32768, 98304, 163840, 229376

Allocating group tables: done                            
Writing inode tables: done                            
Creating journal (8192 blocks): done
Writing superblocks and filesystem accounting information: done

sudo mount /dev/sdb /mnt

lsblk -f
NAME   FSTYPE LABEL UUID                                 FSAVAIL FSUSE% MOUNTPOINT
sda                                                                     
├─sda1 ext4         983742b1-65a8-49d1-a148-a3865ea09e24   16.1G     7% /
├─sda2                                                                  
└─sda5 swap         04559374-06db-46f1-aa31-e7a4e6ec3286                [SWAP]
sdb    ext4         97ec7dd7-1a01-4ab9-8572-4607066b6f2b  906.2M     0% /mnt
</code></pre><h2 id="montar-targets-de-forma-autmática-con-systemd-mount">Montar targets de forma autmática con systemd mount</h2>
<p>Para montar los discos duros de iSCSI de forma permanente en unestro cliente Linux vamos a usar <code>systemd mount</code>, para ello modificaremos el fichero <code>/etc/iscsi/iscsid.conf</code>, comentamos la línea 43 y descomentamos la 40</p>
<pre><code>sudo nano /etc/iscsi/iscsid.conf
[...]
node.startup = automatic
[...]
# node.startup = manual
[...]

sudo systemctl restart iscsi
</code></pre><p>Ahora creamos la unidad en <code>systemctl</code>, para ello creamos un fichero en la ruta <code>/etc/systemd/system</code></p>
<pre><code>sudo nano discored1.mount

[Unit]
Description= Se monta el target1 de iscsi

[Mount]
What=/dev/sdb
Where=/discored1
Type=ext4
Options=_netdev

[Install]
WantedBy=multi-user.target
</code></pre><p>Ahora reiniciamos los servicios, montamos el disco y creamos un enlace simbólico para que se monte automáticamente en el arranque, para realizar todo esto, el disco que queremos tiene que estar montado</p>
<pre><code>sudo systemctl daemon-reload
sudo iscsiadm --mode node -T iqn.2021-02.es.juanan:target1 --portal server --login
sudo systemctl start discored1.mount
sudo systemctl enable discored1.mount
</code></pre><p>Comprobamos si se han realizado los cambios</p>
<pre><code>lsblk -f
NAME   FSTYPE LABEL UUID                                 FSAVAIL FSUSE% MOUNTPOINT
sda                                                                     
├─sda1 ext4         983742b1-65a8-49d1-a148-a3865ea09e24   16.1G     7% /
├─sda2                                                                  
└─sda5 swap         04559374-06db-46f1-aa31-e7a4e6ec3286                [SWAP]
sdb    ext4         97ec7dd7-1a01-4ab9-8572-4607066b6f2b  906.2M     0% /discored1
</code></pre><p>Ahora reiniciamos y volveremos a comprobar</p>
<pre><code>sudo reboot

lsblk -f
NAME   FSTYPE LABEL UUID                                 FSAVAIL FSUSE% MOUNTPOINT
sda                                                                     
├─sda1 ext4         983742b1-65a8-49d1-a148-a3865ea09e24   16.1G     7% /
├─sda2                                                                  
└─sda5 swap         04559374-06db-46f1-aa31-e7a4e6ec3286                [SWAP]
sdb    ext4         97ec7dd7-1a01-4ab9-8572-4607066b6f2b  906.2M     0% /discored1
sdc
</code></pre><h2 id="montar-target-en-windows-con-autenticación-chap">Montar target en Windows con autenticación CHAP</h2>
<p>Primero vamos a modificar de nuevo el fichero <code>/etc/tgt/targets.conf</code> en el server de iSCSI para introducir el usuario y la contraseña del target. Cuando hagamos las modificaciones, reiniciamos el servicio</p>
<pre><code>sudo nano /etc/tgt/targets.conf
[...]
&lt;target iqn.2021-02.es.juanan:target2&gt;
        backing-store /dev/sdc
        incominguser juanan juanan_usuario
&lt;/target&gt;

sudo systemctl restart tgt.service 
</code></pre><p>Ahora vamos a montar el disco <code>sdc</code> en windows, para ello nos abrimos el <code>Panel de control</code> &gt; <code>Sistema y Seguridad</code> &gt; <code>Herramientas Administrativas</code> &gt; <code>Iniciador iSCSI</code>. Cuando estemos en este punto, Windows nos preguntará si queremos iniciar el servicio <code>iSCSI</code> y le tendremos que decir que sí.</p>
<p><img src="/iSCSI/2.png" alt="Captura 2"></p>
<p>Ahora simplemente en la sección <code>Destinos</code> escribimos el nombre de nuestro server en el cuadro llamado <code>Destino</code> y le damos al botón llamado <code>Conexión Rápida...</code></p>
<p><img src="/iSCSI/3.png" alt="Captura 3"></p>
<p>Ahora que nuestro Window ha detectado a nuestro servidor, vamos a conectar el disco duro sdc, para ello seleccionamos el target al que nos queremos conectar y le damos al botón <code>Conectar</code>. Si nos intentamos conectar, sin más, nos va a aparecer un error de autenticación</p>
<p><img src="/iSCSI/4.png" alt="Captura 4"></p>
<p>Para iniciar sesión con los parámetros que le hemos configurado anteriormente en el server, nos intentamos conectar igual que antes, pero con la diferencia de que deberemos pulsar el botón de <code>Opciones Avanzadas...</code> &gt; <code>Habilitar inicio de sesión CHAP</code> y escribimos las credenciales correctas.</p>
<p><img src="/iSCSI/5.png" alt="Captura 5"></p>
<p>Como podemos ver, ha cambiado el estado del <code>target2</code>, el cual ha pasado de estar <code>Inactivo</code> a estar <code>Conectado</code></p>
<p><img src="/iSCSI/6.png" alt="Captura 6"></p>
<p>Ahora vamos a comprobar que tenemos ese disco duro montado, para ello nos dirigimos a <code>Crear y  formatear particiones del disco duro</code> y lo primero que nos aparecerá es una ventana avisándonos de que tenemos un disco duro nuevo, pero que no tiene ninguna partición ni formato</p>
<p><img src="/iSCSI/7.png" alt="Captura 7"></p>
<p>Para cpmprobar que podemos hacer cambios en el disco, he creado una partición</p>
<p><img src="/iSCSI/8.png" alt="Captura 8"></p>
]]></content>
        </item>
        
        <item>
            <title>Apuntes iSCSI</title>
            <link>https://juanan219.github.io/posts/2021/02/apuntes-iscsi/</link>
            <pubDate>Fri, 12 Feb 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/02/apuntes-iscsi/</guid>
            <description>Storage Area Network (SAN) Redes de almacenamiento   Es una red de almacenamiento que proporciona dispositivos de bloques a los servidores, esta red es una red infependiente a la red local de nuestra organización.
  Los elementos típicos de una SAN son:
  Red de alta velocidad (cobre o fibra óptica)
  Equipos o servidores que proporcionan el almacenamiento
  Servidores que usan los dispositivos de bloques</description>
            <content type="html"><![CDATA[<h2 id="storage-area-network-san">Storage Area Network (SAN)</h2>
<h3 id="redes-de-almacenamiento">Redes de almacenamiento</h3>
<ul>
<li>
<p>Es una red de almacenamiento que proporciona dispositivos de bloques a los servidores, esta red es una red infependiente a la red local de nuestra organización.</p>
</li>
<li>
<p>Los elementos típicos de una SAN son:</p>
<ul>
<li>
<p>Red de alta velocidad (cobre o fibra óptica)</p>
</li>
<li>
<p>Equipos o servidores que proporcionan el almacenamiento</p>
</li>
<li>
<p>Servidores que usan los dispositivos de bloques</p>
</li>
</ul>
</li>
<li>
<p>Los protocolos más usados en este tipo de redes son:</p>
<ul>
<li>
<p>iSCSI</p>
</li>
<li>
<p>Fibre Channel Protocol (FCP)</p>
</li>
</ul>
</li>
</ul>
<h4 id="esquema-de-ejemplo-de-una-san">Esquema de ejemplo de una SAN</h4>
<p><img src="/iSCSI/1.png" alt="Captura 1"></p>
<h2 id="iscsi">iSCSI</h2>
<ul>
<li>
<p>Es un protocolo que se usa sobre todo en redes de almacenamiento (aunque para usar iSCSI no es imprescindible tener una SAN, sería lo recomendable, ya que la SAN nos proporciona un mecanismo de aislamiento adecuado para que podamos usar dispositivos de bloques de una forma más segura), pero también se puede usar en una red local.</p>
</li>
<li>
<p>Nos proporciona acceso a dispositivos de bloques sobre TCP/IP</p>
</li>
<li>
<p>Alternativa económica a FCP</p>
</li>
<li>
<p>Usado habitualmente en redes con velocidades de 1 Gbps o 10 Gbps</p>
</li>
</ul>
<h3 id="elementos-iscsi">Elementos iSCSI</h3>
<ul>
<li>
<p><strong>Unidad Lógica (LUN):</strong> Es un dispositivo de bloques a compartir por el servidor iSCSI (Por ejemplo 3 discos duros que hay en el servidor iSCSI)</p>
</li>
<li>
<p><strong>Target:</strong> Recurso a compartir desde el servidor. Un target incluye uno o varios LUN. (Explicación: El target contiene los 3 discos duros del servidor para cuando el cliente se conecte, use dicho target, por lo que el cliente tiene 3 discos duros adicionales en su sistema operativo a través de una sola conexión. De forma alternativa, podemos plantear que cada una de las conexiones tenga su dispositivo de forma independiente, por lo que en este caso, el cliente tendría 3 targets con 3 conexiones independientes)</p>
</li>
<li>
<p><strong>Initiator:</strong> Cliente iSCSI</p>
</li>
<li>
<p><strong>Multipath:</strong> Varias rutas entre initiator y servidor para garantizar la disponibilidad de la conexión, es decir, si tenemos varias formas de conectar el cliente con el servidor, se haría uso de esta característica, ya que si no está disponible la conexión por una ruta, se usa la ruta alternativa.</p>
</li>
<li>
<p>IQN es el formato más extendido para la descripción de los recursos. Por ejemplo: <code>iqn.2020-01.es.tinaja:sdb4</code> (iqn.[fecha significativa].[nombre a la inversa del dominio o servidor]:[LUN])</p>
</li>
<li>
<p><strong>iSNS:</strong> Protocolo que permite gestionar recursos de iSCSI como si fuera FCP</p>
</li>
</ul>
<h3 id="implementaciones-de-iscsi">Implementaciones de iSCSI</h3>
<ul>
<li>
<p>iSCSI tiene soporte en la mayoría de sistemas operativos</p>
</li>
<li>
<p>En Linux usamos <code>open-iscsi</code> como initiator</p>
</li>
<li>
<p>Existen algunas opciones en Linux para el servidor iSCSI:</p>
<ul>
<li>
<p>Linux-IO (LIO) (Versión implementada en el kérnel de Linux)</p>
</li>
<li>
<p>tgt (Es la más usada)</p>
</li>
<li>
<p>scst</p>
</li>
<li>
<p>istgt</p>
</li>
</ul>
</li>
</ul>
<h2 id="demo-iscsi">Demo iSCSI</h2>
<ul>
<li>Instalamos <code>tgt</code></li>
</ul>
<pre><code>sudo apt-get install tgt
</code></pre><ul>
<li>
<p>Hay dos formas de usar este software:</p>
<ul>
<li>
<p>Podemos dirigirnos al directorio <code>/etc/tgt/</code> y definir ahí la configuración modificando los ficheros que sean oportunos. De esta manera la configuración es permanente, es decir, se guardan los cambios.</p>
</li>
<li>
<p>Desde la línea de comandos, por lo que al no estar definida la configuración en ningún sitio, sino hecha &ldquo;en caliente&rdquo;, no se guardan los cambios a la hora de reiniciar la máquina. (Esta es la forma que usaremos en esta demo)</p>
</li>
</ul>
</li>
<li>
<p>Definimos un target:</p>
<ul>
<li><strong>&ndash;lld:</strong> El controlador, en este caso sera <code>iscsi</code> (<code>--lld iscsi</code>)</li>
<li><strong>&ndash;op:</strong> La operación que deseamos hacer, en este caso será crear un nuevo target, por lo que el valor será <code>new</code> (<code>--op new</code>)</li>
<li><strong>&ndash;mode:</strong> Lo que queremos crear, en este caso es un target, por lo que el valor es <code>target</code> (<code>--mode target</code>)</li>
<li><strong>&ndash;tid:</strong> El ID de nuestro nuevo target, en este caso le vamos a asignar el id <code>1</code> (<code>--tid 1</code>)</li>
<li><strong>-T:</strong> El nombre del target que vamos a definir, en este caso será <code>iqn.&quot;año-mes de creación.dominio:nombre_target&quot;</code> (<code>--T iqn.2021-02.es.juanan:target1</code>)</li>
</ul>
</li>
</ul>
<pre><code>sudo tgtadm --lld iscsi --op new --mode target --tid 1 -T iqn.2021-02.es.juanan:target1
</code></pre><pre><code>* Si queremos eliminar un target, simplemente ejecutamos el siguiente comando
</code></pre>
<pre><code>sudo tgtadm --lld iscsi --op delete --mode target --tid 1
</code></pre><ul>
<li>
<p>Le añadimos un dispositivo de bloques:</p>
<ul>
<li><strong>&ndash;mode logicalunit:</strong> Le decimos que queremos añadir una unidad lógica</li>
<li><strong>&ndash;lun 1:</strong> El ID de la unidad lógica que vamos a añadir</li>
<li><strong>-b /dev/sdb:</strong> Ruta hacia el dispositivo de bloques que vamos a añadir</li>
</ul>
</li>
</ul>
<pre><code>sudo tgtadm --lld iscsi --op new --mode logicalunit --tid 1 --lun 1 -b /dev/sdb
</code></pre><ul>
<li>Le añadimos un segundo y tercer dispositivo de bloques</li>
</ul>
<pre><code>sudo tgtadm --lld iscsi --op new --mode logicalunit --tid 1 --lun 2 -b /dev/sdc
sudo tgtadm --lld iscsi --op new --mode logicalunit --tid 1 --lun 3 -b /dev/sdd
</code></pre><pre><code>* Si queremos eliminar alguna de las unidades lógicas que hemos añadido, ejecutamos el siguiente comando:
</code></pre>
<pre><code>sudo tgtadm --lld iscsi --op delete --mode logicalunit --tid 1 --lun 2
</code></pre><ul>
<li>Comprobamos que el target está bien definido</li>
</ul>
<pre><code>sudo tgtadm --lld iscsi --op show --mode target
</code></pre><pre><code>* Salida del comando anterior
</code></pre>
<pre><code>sudo tgtadm --lld iscsi --op show --mode target
Target 1: iqn.2021-02.es.juanan:target1
    System information:
        Driver: iscsi
        State: ready
    I_T nexus information:
    LUN information:
        LUN: 0
            Type: controller
            SCSI ID: IET     00010000
            SCSI SN: beaf10
            Size: 0 MB, Block size: 1
            Online: Yes
            Removable media: No
            Prevent removal: No
            Readonly: No
            SWP: No
            Thin-provisioning: No
            Backing store type: null
            Backing store path: None
            Backing store flags: 
        LUN: 1
            Type: disk
            SCSI ID: IET     00010001
            SCSI SN: beaf11
            Size: 1074 MB, Block size: 512
            Online: Yes
            Removable media: No
            Prevent removal: No
            Readonly: No
            SWP: No
            Thin-provisioning: No
            Backing store type: rdwr
            Backing store path: /dev/sdb
            Backing store flags: 
        LUN: 2
            Type: disk
            SCSI ID: IET     00010002
            SCSI SN: beaf12
            Size: 1074 MB, Block size: 512
            Online: Yes
            Removable media: No
            Prevent removal: No
            Readonly: No
            SWP: No
            Thin-provisioning: No
            Backing store type: rdwr
            Backing store path: /dev/sdc
            Backing store flags: 
        LUN: 3
            Type: disk
            SCSI ID: IET     00010003
            SCSI SN: beaf13
            Size: 1074 MB, Block size: 512
            Online: Yes
            Removable media: No
            Prevent removal: No
            Readonly: No
            SWP: No
            Thin-provisioning: No
            Backing store type: rdwr
            Backing store path: /dev/sdd
            Backing store flags: 
    Account information:
    ACL information:
</code></pre><ul>
<li>
<p>Explicación:</p>
<ul>
<li><strong>Información sobre el target:</strong> Podemos ver que nos muestra el <code>Target 1</code> y su nombre <code>iqn.2021-02.es.juanan:target1</code>. Está en modo <code>ready</code> (<code>State: ready</code>) y tiene un controlador <code>iscsi</code> (<code>Driver: iscsi</code>)</li>
</ul>
</li>
</ul>
<pre><code>Target 1: iqn.2021-02.es.juanan:target1
    System information:
        Driver: iscsi
        State: ready
    I_T nexus information:
</code></pre><pre><code>* **Información de las LUN:** En este apartado (que es el más extenso), podemos ver que tenemos definidas 4 LUNs (`LUN 0, LUN 1, LUN 2 y LUN 3`), pero nosotros solo hemos definido 3 LUNs, esto se debe a que la `LUN 0` es una LUN de control, esto quiere decir que en esta LUN solo se guarda las características de las LUNs y siempre se define cuando se define un target. En las demás LUNs podemos ver información como el tipo de LUN que es (`Type: disk`), si es un dispositivo extraíble (`Removable media: No`), si esta en modo sólo lectura (`Readonly: No`), si tiene aprovisionamiento ligero (`Thin-provisioning: No`), el dispositivo de bloques que tiene asociado (`Backing store path: /dev/sdb`), el modo en el que se encuentra (`Backing store type: rdwr`), etc...
</code></pre>
<pre><code>LUN: 0
    Type: controller
    SCSI ID: IET     00010000
    SCSI SN: beaf10
    Size: 0 MB, Block size: 1
    Online: Yes
    Removable media: No
    Prevent removal: No
    Readonly: No
    SWP: No
    Thin-provisioning: No
    Backing store type: null
    Backing store path: None
    Backing store flags: 
LUN: 1
    Type: disk
    SCSI ID: IET     00010001
    SCSI SN: beaf11
    Size: 1074 MB, Block size: 512
    Online: Yes
    Removable media: No
    Prevent removal: No
    Readonly: No
    SWP: No
    Thin-provisioning: No
    Backing store type: rdwr
    Backing store path: /dev/sdb
    Backing store flags: 
</code></pre><pre><code>* **Información adicional:** Este comando también nos muestra información sobre la cuenta de acceso y sobre las ACL si las tuvieramos
</code></pre>
<pre><code>Account information:
ACL information:
</code></pre><ul>
<li>
<p>Podemos hacer accesible al target creado desde todas las interfaces de red o desde interfaces de red específicas de nuestra máquina. En este caso la haremos accesible a través de todas las interfaces de red de las que disponga nuestra máquina:</p>
<ul>
<li><strong>&ndash;op bind:</strong> Operación que nos permite especificar por cuáles interfaces de red queremos hacer accesible un objeto</li>
<li><strong>&ndash;I ALL:</strong> Le indicamos las interfaces de red por las que queremos hacer accesible este target, en este caso, le hemos puesto el valor <code>ALL</code> para que este target sea accesible por todas las interfaces de red.</li>
</ul>
</li>
</ul>
<pre><code>sudo tgtadm --lld iscsi --op bind --mode target --tid 1 -I ALL
</code></pre><ul>
<li>Cuando tengamos el target configurado y las interfaces de red por las que es accesible definidas, vamos a pasar a la configuración del cliente, ya que, dicho target, debería ser visible desde el cliente. Para conectar el target al cliente, debemos irnos al cliente e instalar el siguiente paquete</li>
</ul>
<pre><code>sudo apt-get install open-iscsi
</code></pre><pre><code>* Al instalar el paquete, se nos asignará un nombre predeterminado, el cual se puede ver en el fichero `/etc/iscsi/initiatorname.iscsi` (Este fichero no se debe editar, a parte, no es necesario editarlo a no ser que lo necesites)
</code></pre>
<pre><code>sudo tail /etc/iscsi/initiatorname.iscsi

InitiatorName=iqn.1993-08.org.debian:01:7eb51324d021
</code></pre><ul>
<li>Ahora que lo tenemos instalado, podemos ver la información:</li>
</ul>
<pre><code>sudo iscsiadm --mode discovery --type sendtargets --portal server

192.168.1.48:3260,1 iqn.2021-02.es.juanan:target1
</code></pre><ul>
<li>También nos podemos conectar al target:</li>
</ul>
<pre><code>sudo iscsiadm --mode node -T iqn.2021-02.es.juanan:target1 --portal server --login
</code></pre><pre><code>* Estas son las entradas del log del kernel (`journalctl -f -k`) que podemos ver cuando nos conectamos. Si nos damos cuenta, es como si le conectásemos 3 nuevos discos
</code></pre>
<pre><code>Feb 12 20:51:16 initiator kernel: Loading iSCSI transport class v2.0-870.
Feb 12 20:51:16 initiator kernel: iscsi: registered transport (tcp)
Feb 12 20:51:16 initiator kernel: iscsi: registered transport (iser)
Feb 12 22:23:15 initiator kernel: scsi host1: iSCSI Initiator over TCP/IP
Feb 12 22:23:15 initiator kernel: scsi 1:0:0:0: RAID              IET      Controller       0001 PQ: 0 ANSI: 5
Feb 12 22:23:15 initiator kernel: scsi 1:0:0:0: Attached scsi generic sg1 type 12
Feb 12 22:23:15 initiator kernel: scsi 1:0:0:1: Direct-Access     IET      VIRTUAL-DISK     0001 PQ: 0 ANSI: 5
Feb 12 22:23:15 initiator kernel: sd 1:0:0:1: Attached scsi generic sg2 type 0
Feb 12 22:23:15 initiator kernel: sd 1:0:0:1: Power-on or device reset occurred
Feb 12 22:23:15 initiator kernel: scsi 1:0:0:2: Direct-Access     IET      VIRTUAL-DISK     0001 PQ: 0 ANSI: 5
Feb 12 22:23:15 initiator kernel: sd 1:0:0:1: [sdb] 2097152 512-byte logical blocks: (1.07 GB/1.00 GiB)
Feb 12 22:23:15 initiator kernel: sd 1:0:0:2: Attached scsi generic sg3 type 0
Feb 12 22:23:15 initiator kernel: sd 1:0:0:2: Power-on or device reset occurred
Feb 12 22:23:15 initiator kernel: sd 1:0:0:1: [sdb] Write Protect is off
Feb 12 22:23:15 initiator kernel: sd 1:0:0:1: [sdb] Mode Sense: 69 00 10 08
Feb 12 22:23:15 initiator kernel: scsi 1:0:0:3: Direct-Access     IET      VIRTUAL-DISK     0001 PQ: 0 ANSI: 5
Feb 12 22:23:15 initiator kernel: sd 1:0:0:3: Attached scsi generic sg4 type 0
Feb 12 22:23:15 initiator kernel: sd 1:0:0:1: [sdb] Write cache: enabled, read cache: enabled, supports DPO and FUA
Feb 12 22:23:15 initiator kernel: sd 1:0:0:3: Power-on or device reset occurred
Feb 12 22:23:15 initiator kernel: sd 1:0:0:2: [sdc] 2097152 512-byte logical blocks: (1.07 GB/1.00 GiB)
Feb 12 22:23:15 initiator kernel: sd 1:0:0:2: [sdc] Write Protect is off
Feb 12 22:23:15 initiator kernel: sd 1:0:0:2: [sdc] Mode Sense: 69 00 10 08
Feb 12 22:23:15 initiator kernel: sd 1:0:0:2: [sdc] Write cache: enabled, read cache: enabled, supports DPO and FUA
Feb 12 22:23:15 initiator kernel: sd 1:0:0:3: [sdd] 2097152 512-byte logical blocks: (1.07 GB/1.00 GiB)
Feb 12 22:23:15 initiator kernel: sd 1:0:0:3: [sdd] Write Protect is off
Feb 12 22:23:15 initiator kernel: sd 1:0:0:3: [sdd] Mode Sense: 69 00 10 08
Feb 12 22:23:15 initiator kernel: sd 1:0:0:3: [sdd] Write cache: enabled, read cache: enabled, supports DPO and FUA
Feb 12 22:23:15 initiator kernel: sd 1:0:0:2: [sdc] Attached SCSI disk
Feb 12 22:23:15 initiator kernel: sd 1:0:0:1: [sdb] Attached SCSI disk
Feb 12 22:23:15 initiator kernel: sd 1:0:0:3: [sdd] Attached SCSI disk
</code></pre><pre><code>* Esta es la salida del comando `lsblk` antes de conectarnos
</code></pre>
<pre><code>lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    0 19.8G  0 disk 
├─sda1   8:1    0 18.8G  0 part /
├─sda2   8:2    0    1K  0 part 
└─sda5   8:5    0 1021M  0 part [SWAP]
</code></pre><pre><code>* Esta es la salida del comando `lsblk` después de conectarnos
</code></pre>
<pre><code>lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    0 19.8G  0 disk 
├─sda1   8:1    0 18.8G  0 part /
├─sda2   8:2    0    1K  0 part 
└─sda5   8:5    0 1021M  0 part [SWAP]
sdb      8:16   0    1G  0 disk 
sdc      8:32   0    1G  0 disk 
sdd      8:48   0    1G  0 disk
</code></pre><ul>
<li>Ahora que los tenemos conectados remotamente a nuestra máquina, podemos operar sobre ellos, por ejemplo, si queremos montar uno de los dispositivos (<code>/dev/sdb</code>) de bloques le podemos dar formato <code>ext4</code> y montarlo en <code>/mnt</code></li>
</ul>
<pre><code>sudo mkfs.ext4 /dev/sdb

sudo mount /dev/sdb /mnt

lsblk -f

sdb    ext4         86b14bd0-6953-4996-a1da-f82f5d248b51  906.2M     0% /mnt
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Servidor de correos</title>
            <link>https://juanan219.github.io/posts/2021/02/servidor-de-correos/</link>
            <pubDate>Thu, 11 Feb 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/02/servidor-de-correos/</guid>
            <description>En esta entrada vamos a configurar un servidor de correos en un VPS, para ello primero deberemos configurar el nombre del servidor de correos, el cual será mail.iesgn16.es, cuyo nombre aparecerá en el registro MX de nuestro DNS.
Para configurar el mail en nuestro servidor, vamos a instalar postfix
sudo apt-get update sudo apt-get install postfix Durante la instalación se nos pedirá que configuremos el mailname, es decir, el nombre del servidor de correo.</description>
            <content type="html"><![CDATA[<p>En esta entrada vamos a configurar un servidor de correos en un VPS, para ello primero deberemos configurar el nombre del servidor de correos, el cual será <code>mail.iesgn16.es</code>, cuyo nombre aparecerá en el registro MX de nuestro DNS.</p>
<p>Para configurar el mail en nuestro servidor, vamos a instalar postfix</p>
<pre><code>sudo apt-get update

sudo apt-get install postfix
</code></pre><p>Durante la instalación se nos pedirá que configuremos el <em>mailname</em>, es decir, el nombre del servidor de correo. Cuando lo tengamos configurado, lo podremos ver con el comando</p>
<pre><code>cat /etc/mailname

iesgn16.es
</code></pre><p>Creamos el registro MX y SPF en nuestro DNS</p>
<p><img src="/correo/1.png" alt="Captura 1"></p>
<h2 id="gestión-de-correos-desde-el-servidor">Gestión de correos desde el servidor</h2>
<ul>
<li><strong>Tarea 1</strong></li>
</ul>
<p>Vamos a descargarnos la herramienta que nos permita enviar/leer correos que recibamos en nuestro servidor postfix, dicha herramienta se llama <code>mailutils</code> y se instala de la siguiente manera</p>
<pre><code>sudo apt-get install mailutils
</code></pre><p>Ahora que tenemos <code>mailutils</code>, vamos a enviar un correo de prueba</p>
<pre><code>mail -s &quot;Prueba&quot; initiategnat9@gmail.com
Cc: 
Hola, esto es una prueba
</code></pre><p>Cuando enviamos el correo, podemos verlo en el registro de log de postfix</p>
<pre><code>Feb  9 12:24:58 fenix postfix/qmgr[30796]: 9C31561C11: removed
Feb  9 12:31:19 fenix postfix/pickup[30795]: 5285E61C11: uid=1000 from=&lt;debian@fenix.iesgn16.es&gt;
Feb  9 12:31:19 fenix postfix/cleanup[31354]: 5285E61C11: message-id=&lt;20210209123119.5285E61C11@fenix.iesgn16.es&gt;
Feb  9 12:31:19 fenix postfix/qmgr[30796]: 5285E61C11: from=&lt;debian@fenix.iesgn16.es&gt;, size=369, nrcpt=1 (queue active)
Feb  9 12:31:19 fenix postfix/smtp[31356]: 5285E61C11: to=&lt;initiategnat9@gmail.com&gt;, relay=gmail-smtp-in.l.google.com[74.125.140.26]:25, delay=0.54, delays=0.02/0.01/0.31/0.21, dsn=2.0.0, status=sent (250 2.0.0 OK  1612873879 q194si1500502wme.142 - gsmtp)
Feb  9 12:31:19 fenix postfix/qmgr[30796]: 5285E61C11: removed
</code></pre><p>Este es el correo que he recibido en mi gmail</p>
<p><img src="/correo/2.png" alt="Captura 2"></p>
<p>Este es el registro SPF que he tenido que añadir a mi servidor DNS</p>
<p><img src="/correo/3.png" alt="Captura 3"></p>
<ul>
<li>
<p><strong>Tarea 2</strong></p>
<ul>
<li><strong>a)</strong> Documenta una prueba de funcionamiento, en la que envíes un correo desde el exterior (gmail, hotmail, etc&hellip;) a tu servidor local.</li>
</ul>
</li>
</ul>
<p>Vamos a comprobar que podemos recibir correos desde el exterior hacia nuestros servidor, para ello, primero deberemos tener configurado nuestro nombre de dominio en el fichero <code>/etc/mailname</code>, en mi caso, el nopmbre de dominio sería <code>iesgn16.es</code>. Ahora revisamos la configuración del DNS para que el registro MX <code>mail.iesgn16.es</code> apunte a <code>fenix.iesgn16.es</code> (Que es la máquina en la que tengo el servidor de correo).</p>
<p>Cuando todo esté correcto, hacemos una prueba y enviamos un correo a nuestro usuario del servidor</p>
<p><img src="/correo/4.png" alt="Captura 4"></p>
<p>Lo abrimos desde nuestro servidor con el comando <code>mail</code></p>
<pre><code>mail
&quot;/var/mail/debian&quot;: 1 message 1 new
&gt;N   1 juanan veintidieci Tue Feb  9 13:00 101/4632  RE: Prueba
? 1
Return-Path: &lt;initiategnat9@gmail.com&gt;
X-Original-To: debian@fenix.iesgn16.es
Delivered-To: debian@fenix.iesgn16.es
[...]
Content-Type: text/plain; charset=&quot;UTF-8&quot;
Content-Transfer-Encoding: quoted-printable

Correcto, prueba de correo recibida

--=20
*Fdo: Juan Antonio Reifs Ram=C3=ADrez*
</code></pre><p>Podemos ver el log en el cual se ve que hemos recibido el correo</p>
<pre><code>Feb  9 13:00:19 fenix postfix/smtpd[31853]: connect from mail-ej1-f49.google.com[209.85.218.49]
Feb  9 13:00:19 fenix postfix/smtpd[31853]: CF3EB61A7B: client=mail-ej1-f49.google.com[209.85.218.49]
Feb  9 13:00:19 fenix postfix/cleanup[31858]: CF3EB61A7B: message-id=&lt;CAFPV5c77w-0rLEWJGaBfgPXzxtJJ=DZvC9ZjyfCTyaeHGWfeYA@mail.gmail.com&gt;
Feb  9 13:00:19 fenix postfix/qmgr[30796]: CF3EB61A7B: from=&lt;initiategnat9@gmail.com&gt;, size=4614, nrcpt=1 (queue active)
Feb  9 13:00:19 fenix postfix/local[31859]: CF3EB61A7B: to=&lt;debian@fenix.iesgn16.es&gt;, relay=local, delay=0.02, delays=0.01/0.01/0/0, dsn=2.0.0, status=sent (delivered to mailbox)
</code></pre><h2 id="uso-de-alias-y-redirecciones">Uso de alias y redirecciones</h2>
<ul>
<li><strong>Tarea 3:</strong></li>
</ul>
<p>Los procesos del sistema pueden mandar correos para informar sobre su estado. Por ejemplo, cuando se ejecuta una tarea de cron, podemos enviar un correo informando del resultado de la misma. Normalmente estos correos se mandan al usuario root, para hacer esto haremos lo siguiente:</p>
<pre><code>crontab -e

MAILTO = root
</code></pre><p>Podemos poner una tarea en el cron para ver cómo se manda el correo.</p>
<pre><code>debian@fenix:~$ crontab -e

MAILTO = root

8 * * * * sudo apt-get update

sudo su

root@fenix:/home/debian# mail
&quot;/var/mail/root&quot;: 1 message 1 new
&gt;N   1 Cron Daemon        Tue Feb  9 19:08  24/894   Cron &lt;debian@fenix&gt; sudo apt-get update
? 1
Return-Path: &lt;debian@iesgn16.es&gt;
X-Original-To: root
Delivered-To: root@iesgn16.es
Received: by fenix.iesgn16.es (Postfix, from userid 1000)
        id 9E7D561A81; Tue,  9 Feb 2021 19:08:02 +0000 (UTC)
From: root@iesgn16.es (Cron Daemon)
To: root@iesgn16.es
Subject: Cron &lt;debian@fenix&gt; sudo apt-get update
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit
X-Cron-Env: &lt;MAILTO=root&gt;
X-Cron-Env: &lt;SHELL=/bin/sh&gt;
X-Cron-Env: &lt;HOME=/home/debian&gt;
X-Cron-Env: &lt;PATH=/usr/bin:/bin&gt;
X-Cron-Env: &lt;LOGNAME=debian&gt;
Message-Id: &lt;20210209190802.9E7D561A81@fenix.iesgn16.es&gt;
Date: Tue,  9 Feb 2021 19:08:02 +0000 (UTC)

Hit:1 http://security.debian.org/debian-security buster/updates InRelease
Hit:2 http://deb.debian.org/debian buster InRelease
Get:3 http://deb.debian.org/debian buster-updates InRelease [51.9 kB]
Fetched 51.9 kB in 0s (149 kB/s)
Reading package lists...
? q
Saved 1 message in /root/mbox
Held 0 messages in /var/mail/root
</code></pre><p>Posteriormente, usando alias y redirecciones podemos hacer llegar esos correos a nuestro correo personal.</p>
<pre><code>sudo su -

nano .forward

initiategnat9@gmail.com

exit
</code></pre><p><img src="/correo/5.png" alt="Captura 5"></p>
<p>Crea un nuevo alias para que los correos se manden a un usuario sin privilegios y comprueba que llegan a ese usuario.</p>
<pre><code>sudo nano /etc/aliases

postmaster:    root
usuario: debian

sudo newaliases

mail

&gt;N   1 Mail Delivery Syst Tue Feb  9 19:42  80/2679  Undelivered Mail Returned to Sender
</code></pre><h2 id="gestión-de-correos-desde-un-cliente">Gestión de correos desde un cliente</h2>
<ul>
<li><strong>Tarea 8:</strong></li>
</ul>
<p>Ahora vamos a configurar el buzón de correos de cada usuario siendo de tipo <code>Maildir</code>, para ello vamos a modificar el fichero <code>/etc/postfix/main.cf</code> y comprobamos, mandando un correo, que se nos guardan en ese directorio.</p>
<pre><code>sudo nano /etc/postfix/main.cf

[...]
home_mailbox = Maildir/
mailbox_command =

sudo systemctl restart postfix

debian@fenix:~$ ls
Maildir

debian@fenix:~$ ls Maildir/
cur  new  tmp

debian@fenix:~$ ls Maildir/new/
1612941963.V801I20b38M9703.fenix
</code></pre><p><img src="/correo/6.png" alt="Captura 6"></p>
<p>Para abrir los correos de tipo maildir desde la terminal, no podemos hacer con mail, asó que instalaremos la herramienta mutt y editamos el fichero <code>~/.muttrc</code></p>
<pre><code>sudo apt-get install muttrc

debian@fenix:~$ nano ~/.muttrc

set mbox_type=Maildir
set folder=&quot;~/Maildir&quot;
set mask=&quot;!^\\.[^.]&quot;
set mbox=&quot;~/Maildir&quot;
set record=&quot;+.Sent&quot;
set postponed=&quot;+.Drafts&quot;
set spoolfile=&quot;~/Maildir&quot;
mailboxes `echo -n &quot;+ &quot;; find ~/Maildir -maxdepth 1 -type d -name &quot;.*&quot; -printf &quot;+'%f' &quot;`
macro index c &quot;&lt;change-folder&gt;?&lt;toggle-mailboxes&gt;&quot; &quot;open a different folder&quot;
macro pager c &quot;&lt;change-folder&gt;?&lt;toggle-mailboxes&gt;&quot; &quot;open a different folder&quot;
macro index C &quot;&lt;copy-message&gt;?&lt;toggle-mailboxes&gt;&quot; &quot;copy a message to a mailbox&quot;
macro index M &quot;&lt;save-message&gt;?&lt;toggle-mailboxes&gt;&quot; &quot;move a message to a mailbox&quot;

macro compose A &quot;&lt;attach-message&gt;?&lt;toggle-mailboxes&gt;&quot; &quot;attach message(s) to this message&quot;
</code></pre><p>Ahora abrimos el mensaje</p>
<pre><code>mutt

1     Feb 10 juanan veintidi (2.2K) Prueba Maildir

Date: Wed, 10 Feb 2021 08:54:08 +0100
From: juanan veintidiecinueve &lt;initiategnat9@gmail.com&gt;
To: debian@fenix.iesgn16.es
Subject: Prueba Maildir

Este es un correo que se guardará en Maildir

--
*Fdo: Juan Antonio Reifs Ramírez*

[image: Mailtrack]
&lt;https://mailtrack.io?utm_source=gmail&amp;utm_medium=signature&amp;utm_campaign=signaturevirality5&amp;&gt;
Remitente
notificado con
Mailtrack
&lt;https://mailtrack.io?utm_source=gmail&amp;utm_medium=signature&amp;utm_campaign=signaturevirality5&amp;&gt;
10/02/21
08:49:05
</code></pre><ul>
<li><strong>Tarea 9:</strong></li>
</ul>
<p>Ahora vamos a instalar dovecot para poder ofrecer el protocolo IMAP y lo configuraremos para ofrecer autentificación y cifrado.</p>
<pre><code>sudo apt-get install dovecot-imapd
</code></pre><p>Para poder realizar el cifrado de la comunicación, vamos a crear un certificado de LetsEncrypt para el dominio <code>mail.iesgn.es</code>. Para realizarlo instalaremos <code>certbot</code> así que seguimos los siguientes pasos</p>
<pre><code>sudo apt install snapd

sudo snap install core

sudo snap install core; sudo snap refresh core

sudo snap install --classic certbot

sudo ln -s /snap/bin/certbot /usr/bin/certbot
</code></pre><p>Cuando tengamos <code>certbot</code>instalado, generamos nuestro certificado</p>
<pre><code>sudo certbot certonly --standalone
</code></pre><p>Cuando se genere, se guardará en el directorio <code>/etc/letsencrypt/live/mail.iesgn16.es</code>. Ahora que lo tenemos todo listo, vamos a pasar a la configuración de dovecot:</p>
<ol>
<li>Editamos el fichero <code>/etc/dovecot/conf.d/10-auth.conf</code> para habilitar el mecanismo de autentificación</li>
</ol>
<pre><code>sudo nano /etc/dovecot/conf.d/10-auth.conf

disable_plaintext_auth = yes
[...]
auth_mechanisms = plain login
</code></pre><ol start="2">
<li>Configuramos el directorio Maildir y comentamos la configuración mbox que viene predeterminada en dovecot</li>
</ol>
<pre><code>sudo nano /etc/dovecot/conf.d/10-mail.conf

mail_location = maildir:~/Maildir
[...]
#mail_location = mbox:~/mail:INBOX=/var/mail/%u
</code></pre><ol start="3">
<li>Descomentamos las siguientes líneas para habilitar el imaps</li>
</ol>
<pre><code>sudo nano /etc/dovecot/conf.d/10-master.conf

service imap-login {
  inet_listener imap {
    port = 143
  }
  inet_listener imaps {
    port = 993
    ssl = yes
  }
[...]
unix_listener /var/spool/postfix/private/auth {
    mode = 0666
    user = postfix
    group = postfix
}
</code></pre><ol start="4">
<li>Por último configuramos nuestros certificados y reiniciamos dovecot</li>
</ol>
<pre><code>sudo nano /etc/dovecot/conf.d/10-ssl.conf

ssl = required
[...]
ssl_cert = &lt;/etc/letsencrypt/live/mail.iesgn16.es/cert.pem
ssl_key = &lt;/etc/letsencrypt/live/mail.iesgn16.es/privkey.pem

sudo systemctl restart dovecot
</code></pre><p>Podemos verificar la configuración de nuestro dovecot con el comando <code>dovecot -n</code></p>
<p>Ahora vamos a hacer una prueba, para verificar que recibimos mensajes en nuestro Mailbox, para ello vamos a enviar un correo de prueba desde gmail</p>
<p><img src="/correo/7.png" alt="Captura 7"></p>
<pre><code>ls Maildir/new/
1613034771.V801I2154fM907367.fenix

mutt
1 N + Feb 11 juanan veintidi (2.2K) Prueba Maildir

Date: Thu, 11 Feb 2021 10:12:40 +0100
From: juanan veintidiecinueve &lt;initiategnat9@gmail.com&gt;
To: debian@iesgn16.es
Subject: Prueba Maildir

Este mensaje tiene que llegar a tu Maildir

--
*Fdo: Juan Antonio Reifs Ramírez*

[image: Mailtrack]
&lt;https://mailtrack.io?utm_source=gmail&amp;utm_medium=signature&amp;utm_campaign=signaturevirality5&amp;&gt;
Remitente
notificado con
Mailtrack
&lt;https://mailtrack.io?utm_source=gmail&amp;utm_medium=signature&amp;utm_campaign=signaturevirality5&amp;&gt;
11/02/21
10:12:20
</code></pre><p>Por último, vamos a configurar un cliente de correo, en este caso será Thunderbird:</p>
<ol>
<li>Iniciamos sesión</li>
</ol>
<p><img src="/correo/8.png" alt="Captura 8"></p>
<ol start="2">
<li>Configuramos manualmente</li>
</ol>
<p><img src="/correo/9.png" alt="Captura 9"></p>
<p>Como podemos ver, hemos recibido el mensaje que hemos enviado anteriormente</p>
<p><img src="/correo/10.png" alt="Captura 10"></p>
<ul>
<li><strong>Tarea 11:</strong></li>
</ul>
<p>Vamos a configurar postfix para que podamos enviar correos desde los clientes remotos. La conexión entre el cliente y el servidor debe de estar autentificada con SASL y usando dovecot y, además, debede estar cifrada. Para realizar este cifrado usaremos <code>SMTPS</code>, el cual usa el puerto 465.</p>
<p>Primero habilitamos SMTP-AUTH para permitir que los clientes se identifiquen a través del mecanismo de autentificación SASL. También se debe usar TLS para cifrar el proceso de autenticación, para ello ejecutamos las siguientes instrucciones para editar el fichero de configuración de postfix.</p>
<pre><code>sudo postconf -e 'smtpd_sasl_type = dovecot'
sudo postconf -e 'smtpd_sasl_path = private/auth'
sudo postconf -e 'smtpd_sasl_local_domain ='
sudo postconf -e 'smtpd_sasl_security_options = noanonymous'
sudo postconf -e 'broken_sasl_auth_clients = yes'
sudo postconf -e 'smtpd_sasl_auth_enable = yes'
sudo postconf -e 'smtpd_recipient_restrictions = permit_sasl_authenticated,permit_mynetworks,reject_unauth_destination'
sudo postconf -e 'smtp_tls_security_level = may'
sudo postconf -e 'smtpd_tls_security_level = may'
sudo postconf -e 'smtp_tls_note_starttls_offer = yes'
sudo postconf -e 'smtpd_tls_loglevel = 1'
sudo postconf -e 'smtpd_tls_received_header = yes'
</code></pre><p>Ahora editamos el fichero <code>/etc/postfix/master.cf</code> y descomentamos las siguientes líneas</p>
<pre><code>sudo nano /etc/postfix/master.cf
[...]
smtps     inet  n       -       y       -       -       smtpd
  -o syslog_name=postfix/smtps
  -o smtpd_tls_wrappermode=yes
  -o smtpd_sasl_auth_enable=yes
  -o smtpd_reject_unlisted_recipient=no
  -o smtpd_client_restrictions=$mua_client_restrictions
  -o smtpd_helo_restrictions=$mua_helo_restrictions
  -o smtpd_sender_restrictions=$mua_sender_restrictions
  -o smtpd_recipient_restrictions=
  -o smtpd_relay_restrictions=permit_sasl_authenticated,reject
  -o milter_macro_daemon_name=ORIGINATING
[...]
</code></pre><p>Por último añadimos nuestro certificado y nuestra clave privada al fichero <code>/etc/postfix/main.cf</code> y reiniciamos postfix</p>
<pre><code>sudo nano /etc/postfix/main.cf
[...]
smtpd_tls_cert_file=/etc/letsencrypt/live/mail.iesgn16.es/cert.pem
smtpd_tls_key_file=/etc/letsencrypt/live/mail.iesgn16.es/privkey.pem
[...]

sudo systemctl restart postfix
</code></pre><p>Ahora nos dirigimos a Thunderbird y modificamos los valores de SMTP
<img src="/correo/11.png" alt="Captura 11"></p>
<p>Para comprobar que funciona, vamos a enviar un correo desde Thunderbird hacia mi gmail personal
<img src="/correo/12.png" alt="Captura 12"></p>
<p><img src="/correo/13.png" alt="Captura 13"></p>
]]></content>
        </item>
        
        <item>
            <title>Bienvenidos a JuananBlog</title>
            <link>https://juanan219.github.io/posts/2021/02/bienvenidos-a-juananblog/</link>
            <pubDate>Tue, 09 Feb 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/02/bienvenidos-a-juananblog/</guid>
            <description>Bienvenidos a mi nuevo sitio web estático generado con HUGO.</description>
            <content type="html"><![CDATA[<p>Bienvenidos a mi nuevo sitio web estático generado con HUGO.</p>
]]></content>
        </item>
        
        <item>
            <title>Generar Sitios Web estáticos con HUGO y GitHub Pages</title>
            <link>https://juanan219.github.io/posts/2021/02/generar-sitios-web-est%C3%A1ticos-con-hugo-y-github-pages/</link>
            <pubDate>Thu, 04 Feb 2021 00:00:00 +0000</pubDate>
            
            <guid>https://juanan219.github.io/posts/2021/02/generar-sitios-web-est%C3%A1ticos-con-hugo-y-github-pages/</guid>
            <description>En esta práctica vamos a seleccionar una combinación para realizar el depliegue de una web estática y añadir contenido a ella, en mi caso, voy a seleccionar la combinación de HUGO y GitHub Pages.
Para comenzar, vamos a instalar la herramientas necesarias para realizar esta práctica, así que instalaremos git y hugo
sudo apt-get update sudo apt-get install git hugo Cuando tengamos los paquetes descargados, vamos a comenzar a montar nuestro sitio y como vamos a subirlo a github, creamos un nuevo repositorio vacío y lo clonamos a nuestro directorio de trabajo, para más tarde comenzar a crear nuestro sitio</description>
            <content type="html"><![CDATA[<p>En esta práctica vamos a seleccionar una combinación para realizar el depliegue de una web estática y añadir contenido a ella, en mi caso, voy a seleccionar la combinación de HUGO y GitHub Pages.</p>
<p>Para comenzar, vamos a instalar la herramientas necesarias para realizar esta práctica, así que instalaremos git y hugo</p>
<pre><code>sudo apt-get update

sudo apt-get install git hugo
</code></pre><p>Cuando tengamos los paquetes descargados, vamos a comenzar a montar nuestro sitio y como vamos a subirlo a github, creamos un nuevo repositorio vacío y lo clonamos a nuestro directorio de trabajo, para más tarde comenzar a crear nuestro sitio</p>
<pre><code>git clone git@github.com:Juanan219/JuananBlog.git

hugo new site --force JuananBlog/
</code></pre><p>Si queremos, ya podemos hacer el primer commit en github y comenzar a subir los archivos</p>
<pre><code>git add .

git commit -am &quot;Primer commit&quot;

git push
</code></pre><p>Ahora vamos a añadir un tema de los <a href="https://themes.gohugo.io/">temas de hugo</a>, para ello vamos a clonar el repositorio de uno de ellos en el directorio themes</p>
<pre><code>git clone git@github.com:rhazdon/hugo-theme-hello-friend-ng.git
</code></pre><p>En esta práctica no me voy a parar a adaptar el tema entero, así que cogeré el tema de ejemplo que viene en el directorio que hemos clonado y vamos a adaptarlo para que funcione</p>
<pre><code>cd ..

cp -r themes/hugo-theme-hello-friend-ng/exampleSite/* .
</code></pre><p>Cuando tengamos todos los archivos de ejemplo copiados al directorio principal de nuestro sitio, vamos a editar el config.toml para poner nuestros enlaces y nuestro nombre junto a la fecha actual</p>
<pre><code>nano config.toml
baseURL = &quot;https://juanan219.github.io&quot;
title   = &quot;JuananBlog&quot;
[...]
[author]
  name = &quot;Juan antonio Reifs&quot;
[...]
[params]
  dateform        = &quot;Feb 4, 2021&quot;
  dateformShort   = &quot;Feb 4&quot;
  dateformNum     = &quot;2021-02-04&quot;
  dateformNumTime = &quot;2021-02-04 11:35&quot;
[...]
description = &quot;Blog de Informática&quot;
[...]
homeSubtitle = &quot;Blog de Informática&quot;
[...]
[[params.social]]
    name = &quot;twitter&quot;
    url  = &quot;https://twitter.com/juanan219&quot;

  [[params.social]]
    name = &quot;email&quot;
    url  = &quot;mailto:initiategnat9@gmail.com&quot;

  [[params.social]]
    name = &quot;github&quot;
    url  = &quot;https://github.com/juanan219&quot;

  [[params.social]]
    name = &quot;linkedin&quot;
    url  = &quot;https://www.linkedin.com/in/juan-antonio-reifs-ram%C3%ADrez-b78b40162/&quot;

#  [[params.social]]
#    name = &quot;stackoverflow&quot;
#    url  = &quot;https://www.stackoverflow.com/&quot;
</code></pre><p>Ahora vamos a eliminar los posts de ejemplo y vamos a crear uno, pero al ejecutar el comando para crear un nuevo usuario me salía el siguiente error <code>Error: module &quot;hello-friend-ng&quot; not found;...</code> y para solucionarlo simplemente tuve que cambiar el nombre del tema y ya pude agregar un nuevo post.</p>
<pre><code>mv themes/hugo-theme-hello-friend-ng/ themes/hello-friend-ng

hugo new posts/Bienvenida.md

cd content/posts/

rm creating-a-new-theme.md  goisforlovers.fr.md  goisforlovers.md  hugoisforlovers.fr.md  migrate-from-jekyll.fr.md
</code></pre><p>Creamos un archivo <code>gitignore</code> para no subir la carpeta public que vamos a generar con el contenido html</p>
<pre><code>nano .gitignore

public/
</code></pre><p>Ahora que tenemos todo listo, vamos a crear un repositorio de github para github pages llamado juanan219.github.io y vamos a clonar dicho repositorio en nuestra máquina y vamos a generar dentro de él los archivos estáticos de hugo</p>
<pre><code>git clone git@github.com:Juanan219/juanan219.github.io.git

cd JuananBlog/

hugo -d ../juanan219.github.io/
</code></pre><p>Cuando hayamos generado todos los archivos vamos a subirlos al nuevo repositorio</p>
<pre><code>cd ../juanan219.github.io/

git add --all

git commit -am &quot;Archivos estáticos HUGO&quot;

git push
</code></pre><p>Por último, si nos dirigimos a la configuración de nuestro nuevo repositorio de GitHub, si bajamos, podremos ver un apartado llamado GitHub Pages, en el cual, si todo ha salido bien, nos dirá que nuestra página está subida a <a href="https://juanan219.github.io/">la url que le hemos configurado</a></p>
<p><img src="/web_estatica/1.PNG" alt="Captura 1"></p>
]]></content>
        </item>
        
    </channel>
</rss>
